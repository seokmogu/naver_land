#!/usr/bin/env python3
"""
í˜„ì¬ Supabase ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë¶„ì„ ë„êµ¬
ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°, ì»¬ëŸ¼, ì¸ë±ìŠ¤, ë°ì´í„° ë¶„í¬ë¥¼ ë¶„ì„
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

try:
    from collectors.db.supabase_client import SupabaseHelper
except ImportError as e:
    print(f"âŒ Import ì˜¤ë¥˜: {e}")
    print("collectors/db/supabase_client.py íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

class SchemaAnalyzer:
    def __init__(self):
        """ìŠ¤í‚¤ë§ˆ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        try:
            self.helper = SupabaseHelper()
            print("âœ… Supabase ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
            sys.exit(1)
    
    def analyze_table_structure(self):
        """í…Œì´ë¸” êµ¬ì¡° ë¶„ì„"""
        print("\nğŸ” í…Œì´ë¸” êµ¬ì¡° ë¶„ì„ ì¤‘...")
        
        # PostgreSQL ì‹œìŠ¤í…œ í…Œì´ë¸”ì„ í†µí•œ ìŠ¤í‚¤ë§ˆ ë¶„ì„
        schema_query = """
        SELECT 
            table_name,
            column_name,
            data_type,
            is_nullable,
            column_default,
            character_maximum_length
        FROM information_schema.columns 
        WHERE table_schema = 'public' 
        ORDER BY table_name, ordinal_position
        """
        
        try:
            # Raw SQL ì¿¼ë¦¬ ì‹¤í–‰
            result = self.helper.client.rpc('get_schema_info', {'query': schema_query}).execute()
            
            if result.data:
                return self._organize_schema_data(result.data)
            else:
                print("âš ï¸ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ì ‘ í…Œì´ë¸” ì¡°íšŒë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
                return self._analyze_known_tables()
                
        except Exception as e:
            print(f"âš ï¸ ì‹œìŠ¤í…œ í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return self._analyze_known_tables()
    
    def _analyze_known_tables(self):
        """ì•Œë ¤ì§„ í…Œì´ë¸”ë“¤ ì§ì ‘ ë¶„ì„"""
        print("ğŸ“‹ ì•Œë ¤ì§„ í…Œì´ë¸” ì§ì ‘ ë¶„ì„ ì¤‘...")
        
        known_tables = ['properties', 'areas', 'price_history', 'deletion_history', 'daily_stats', 'collection_logs']
        schema_info = {}
        
        for table_name in known_tables:
            try:
                # ê° í…Œì´ë¸”ì—ì„œ 1ê°œ ë ˆì½”ë“œë§Œ ì¡°íšŒí•˜ì—¬ êµ¬ì¡° íŒŒì•…
                result = self.helper.client.table(table_name).select('*').limit(1).execute()
                
                if result.data and len(result.data) > 0:
                    sample_record = result.data[0]
                    schema_info[table_name] = {
                        'columns': list(sample_record.keys()),
                        'sample_data': sample_record,
                        'record_count': self._get_table_count(table_name)
                    }
                    print(f"âœ… {table_name}: {len(sample_record.keys())}ê°œ ì»¬ëŸ¼, {schema_info[table_name]['record_count']:,}ê°œ ë ˆì½”ë“œ")
                else:
                    schema_info[table_name] = {
                        'columns': [],
                        'sample_data': None,
                        'record_count': 0
                    }
                    print(f"ğŸ“‹ {table_name}: ë¹ˆ í…Œì´ë¸”")
                    
            except Exception as e:
                print(f"âŒ {table_name} ë¶„ì„ ì‹¤íŒ¨: {e}")
                schema_info[table_name] = {'error': str(e)}
        
        return schema_info
    
    def _get_table_count(self, table_name):
        """í…Œì´ë¸” ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ"""
        try:
            result = self.helper.client.table(table_name).select('*', count='exact').limit(1).execute()
            return result.count or 0
        except:
            return 0
    
    def analyze_properties_table_details(self):
        """properties í…Œì´ë¸” ìƒì„¸ ë¶„ì„"""
        print("\nğŸ¢ properties í…Œì´ë¸” ìƒì„¸ ë¶„ì„...")
        
        try:
            # ê¸°ë³¸ í†µê³„
            total_count = self._get_table_count('properties')
            active_count = self.helper.client.table('properties').select('*', count='exact').eq('is_active', True).limit(1).execute().count or 0
            
            # ë‚ ì§œë³„ ë¶„í¬
            date_distribution = self.helper.client.table('properties').select('collected_date').execute()
            
            # ì§€ì—­ë³„ ë¶„í¬
            region_distribution = self.helper.client.table('properties').select('cortar_no').limit(100).execute()
            
            # ê°€ê²© ë¶„í¬ (ìƒìœ„ 100ê°œë§Œ)
            price_sample = self.helper.client.table('properties').select('price, rent_price').limit(100).execute()
            
            # details ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„
            details_sample = self.helper.client.table('properties').select('details').limit(10).execute()
            
            analysis = {
                'total_records': total_count,
                'active_records': active_count,
                'inactive_records': total_count - active_count,
                'date_range': self._analyze_date_range(date_distribution.data) if date_distribution.data else None,
                'region_sample': self._analyze_region_distribution(region_distribution.data) if region_distribution.data else None,
                'price_analysis': self._analyze_price_distribution(price_sample.data) if price_sample.data else None,
                'details_structure': self._analyze_details_structure(details_sample.data) if details_sample.data else None
            }
            
            return analysis
            
        except Exception as e:
            print(f"âŒ properties í…Œì´ë¸” ìƒì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _analyze_date_range(self, date_data):
        """ë‚ ì§œ ë²”ìœ„ ë¶„ì„"""
        if not date_data:
            return None
            
        dates = [item.get('collected_date') for item in date_data if item.get('collected_date')]
        if dates:
            return {
                'earliest': min(dates),
                'latest': max(dates),
                'total_days': len(set(dates))
            }
        return None
    
    def _analyze_region_distribution(self, region_data):
        """ì§€ì—­ ë¶„í¬ ë¶„ì„"""
        if not region_data:
            return None
            
        regions = {}
        for item in region_data:
            cortar_no = item.get('cortar_no')
            if cortar_no:
                regions[cortar_no] = regions.get(cortar_no, 0) + 1
        
        return {
            'total_regions': len(regions),
            'top_regions': sorted(regions.items(), key=lambda x: x[1], reverse=True)[:10]
        }
    
    def _analyze_price_distribution(self, price_data):
        """ê°€ê²© ë¶„í¬ ë¶„ì„"""
        if not price_data:
            return None
        
        prices = [item.get('price', 0) for item in price_data if isinstance(item.get('price'), (int, float)) and item.get('price') > 0]
        rent_prices = [item.get('rent_price', 0) for item in price_data if isinstance(item.get('rent_price'), (int, float)) and item.get('rent_price') > 0]
        
        analysis = {}
        
        if prices:
            analysis['sale_prices'] = {
                'min': min(prices),
                'max': max(prices),
                'avg': sum(prices) / len(prices),
                'count': len(prices)
            }
        
        if rent_prices:
            analysis['rent_prices'] = {
                'min': min(rent_prices),
                'max': max(rent_prices),
                'avg': sum(rent_prices) / len(rent_prices),
                'count': len(rent_prices)
            }
        
        return analysis
    
    def _analyze_details_structure(self, details_data):
        """details JSONB ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„"""
        if not details_data:
            return None
        
        all_keys = set()
        structure_examples = {}
        
        for item in details_data:
            details = item.get('details', {})
            if isinstance(details, dict):
                for key in details.keys():
                    all_keys.add(key)
                    if key not in structure_examples:
                        structure_examples[key] = details[key]
        
        return {
            'total_unique_keys': len(all_keys),
            'all_keys': list(all_keys),
            'structure_examples': structure_examples
        }
    
    def analyze_data_quality(self):
        """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        print("\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì¤‘...")
        
        try:
            # í•„ìˆ˜ í•„ë“œ ëˆ„ë½ ë¶„ì„
            quality_issues = {}
            
            # NULL ê°’ ë¶„ì„
            properties_sample = self.helper.client.table('properties').select('*').limit(1000).execute()
            
            if properties_sample.data:
                quality_issues['null_analysis'] = self._analyze_null_values(properties_sample.data)
                quality_issues['duplicate_analysis'] = self._check_duplicates()
                quality_issues['data_consistency'] = self._check_data_consistency(properties_sample.data)
            
            return quality_issues
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _analyze_null_values(self, data):
        """NULL ê°’ ë¶„ì„"""
        if not data:
            return None
            
        null_counts = {}
        total_records = len(data)
        
        # ì²« ë²ˆì§¸ ë ˆì½”ë“œì—ì„œ ì»¬ëŸ¼ ëª©ë¡ ì¶”ì¶œ
        if data:
            columns = data[0].keys()
            
            for col in columns:
                null_count = sum(1 for record in data if record.get(col) is None or record.get(col) == '')
                if null_count > 0:
                    null_counts[col] = {
                        'null_count': null_count,
                        'null_percentage': (null_count / total_records) * 100
                    }
        
        return null_counts
    
    def _check_duplicates(self):
        """ì¤‘ë³µ ë°ì´í„° í™•ì¸"""
        try:
            # article_no ì¤‘ë³µ í™•ì¸
            duplicates = self.helper.client.rpc('check_article_duplicates').execute()
            return duplicates.data if duplicates.data else "ì¤‘ë³µ ê²€ì‚¬ í•¨ìˆ˜ ì—†ìŒ"
        except:
            return "ì¤‘ë³µ ê²€ì‚¬ ë¶ˆê°€"
    
    def _check_data_consistency(self, data):
        """ë°ì´í„° ì¼ê´€ì„± í™•ì¸"""
        issues = []
        
        for record in data[:100]:  # ìƒìœ„ 100ê°œë§Œ ê²€ì‚¬
            # ê°€ê²© ì¼ê´€ì„± (ìŒìˆ˜ ê°’ í™•ì¸)
            price = record.get('price', 0)
            rent_price = record.get('rent_price', 0)
            
            if isinstance(price, (int, float)) and price < 0:
                issues.append(f"ìŒìˆ˜ ë§¤ë§¤ê°€: {record.get('article_no')}")
            
            if isinstance(rent_price, (int, float)) and rent_price < 0:
                issues.append(f"ìŒìˆ˜ ì›”ì„¸: {record.get('article_no')}")
            
            # ë‚ ì§œ ì¼ê´€ì„± í™•ì¸
            collected_date = record.get('collected_date')
            last_seen_date = record.get('last_seen_date')
            
            if collected_date and last_seen_date:
                if collected_date > last_seen_date:
                    issues.append(f"ë‚ ì§œ ë¶ˆì¼ì¹˜: {record.get('article_no')}")
        
        return issues[:20]  # ìƒìœ„ 20ê°œ ì´ìŠˆë§Œ ë°˜í™˜
    
    def generate_report(self):
        """ì „ì²´ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        print("ğŸ“‹ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        report = {
            'analysis_timestamp': datetime.now().isoformat(),
            'schema_structure': self.analyze_table_structure(),
            'properties_details': self.analyze_properties_table_details(),
            'data_quality': self.analyze_data_quality()
        }
        
        # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
        report_file = current_dir / f"current_database_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ë¶„ì„ ë³´ê³ ì„œ ì €ì¥: {report_file}")
        
        return report
    
    def print_summary(self, report):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š ë„¤ì´ë²„ ë¶€ë™ì‚° DB ìŠ¤í‚¤ë§ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        
        # í…Œì´ë¸” êµ¬ì¡° ìš”ì•½
        schema = report.get('schema_structure', {})
        print(f"\nğŸ—ï¸ í…Œì´ë¸” êµ¬ì¡°:")
        for table_name, info in schema.items():
            if isinstance(info, dict) and 'columns' in info:
                print(f"  ğŸ“‹ {table_name}: {len(info['columns'])}ê°œ ì»¬ëŸ¼, {info['record_count']:,}ê°œ ë ˆì½”ë“œ")
                if table_name == 'properties':
                    print(f"     ì£¼ìš” ì»¬ëŸ¼: {', '.join(info['columns'][:10])}...")
        
        # properties í…Œì´ë¸” ìƒì„¸
        properties = report.get('properties_details', {})
        if properties and 'total_records' in properties:
            print(f"\nğŸ¢ properties í…Œì´ë¸” ìƒì„¸:")
            print(f"  ğŸ“Š ì „ì²´ ë§¤ë¬¼: {properties['total_records']:,}ê°œ")
            print(f"  âœ… í™œì„± ë§¤ë¬¼: {properties['active_records']:,}ê°œ")
            print(f"  âŒ ë¹„í™œì„± ë§¤ë¬¼: {properties['inactive_records']:,}ê°œ")
            
            if properties.get('date_range'):
                date_info = properties['date_range']
                print(f"  ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {date_info['earliest']} ~ {date_info['latest']} ({date_info['total_days']}ì¼)")
            
            if properties.get('region_sample', {}).get('total_regions'):
                print(f"  ğŸ—ºï¸ ìˆ˜ì§‘ ì§€ì—­: {properties['region_sample']['total_regions']}ê°œ ì§€ì—­")
            
            if properties.get('details_structure'):
                details_info = properties['details_structure']
                print(f"  ğŸ“ ìƒì„¸ì •ë³´ í‚¤: {details_info['total_unique_keys']}ê°œ ê³ ìœ  í‚¤")
        
        # ë°ì´í„° í’ˆì§ˆ
        quality = report.get('data_quality', {})
        if quality and 'null_analysis' in quality:
            print(f"\nğŸ” ë°ì´í„° í’ˆì§ˆ:")
            null_analysis = quality['null_analysis']
            if null_analysis:
                print(f"  âš ï¸ NULL ê°’ì´ ìˆëŠ” ì»¬ëŸ¼: {len(null_analysis)}ê°œ")
                high_null_cols = [col for col, info in null_analysis.items() if info['null_percentage'] > 10]
                if high_null_cols:
                    print(f"  âŒ ë†’ì€ NULL ë¹„ìœ¨ ì»¬ëŸ¼: {', '.join(high_null_cols)}")
            
            consistency_issues = quality.get('data_consistency', [])
            if consistency_issues:
                print(f"  ğŸš¨ ì¼ê´€ì„± ë¬¸ì œ: {len(consistency_issues)}ê°œ ë°œê²¬")
        
        print("\n" + "="*80)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” ë„¤ì´ë²„ ë¶€ë™ì‚° DB ìŠ¤í‚¤ë§ˆ ë¶„ì„ê¸°")
    print("="*50)
    
    analyzer = SchemaAnalyzer()
    
    try:
        # ì „ì²´ ë¶„ì„ ì‹¤í–‰
        report = analyzer.generate_report()
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        analyzer.print_summary(report)
        
        print("\nâœ… ë¶„ì„ ì™„ë£Œ! ìƒì„¸ ê²°ê³¼ëŠ” JSON íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()