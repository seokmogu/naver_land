#!/usr/bin/env python3
"""
ë°ì´í„°ë² ì´ìŠ¤ NULL ê°’ ë¶„ì„ ë° ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
- enhanced_data_collector.pyì™€ ì •ê·œí™”ëœ ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ë¶„ì„
- NULL ê°’ ë°œìƒ ì›ì¸ ë° íŒ¨í„´ ì‹ë³„
- ë°ì´í„° í’ˆì§ˆ ê°œì„  ë°©ì•ˆ ì œì‹œ
"""

import os
import sys
import json
from datetime import datetime, date
from pathlib import Path
from typing import Dict, List, Optional, Any
from collections import defaultdict, Counter

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from supabase import create_client

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
os.environ['SUPABASE_URL'] = 'https://eslhavjipwbyvbbknixv.supabase.co'
os.environ['SUPABASE_KEY'] = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImVzbGhhdmppcHdieXZiYmtuaXh2Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NDI5OTUxMSwiZXhwIjoyMDY5ODc1NTExfQ.p6JB5xrdLi_yBJTuHg2mF9TZFQiwA4Tqd0hc-7FxFqE'

class NullValueAnalyzer:
    def __init__(self):
        """NULL ê°’ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        try:
            self.client = create_client(
                os.environ['SUPABASE_URL'], 
                os.environ['SUPABASE_KEY']
            )
            print("âœ… Supabase ì—°ê²° ì„±ê³µ")
            
            self.analysis_results = {}
            self.null_patterns = defaultdict(int)
            self.data_quality_issues = []
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            sys.exit(1)
    
    def analyze_legacy_properties_table(self):
        """ê¸°ì¡´ properties í…Œì´ë¸” NULL ê°’ ë¶„ì„"""
        print("\nğŸ” ê¸°ì¡´ properties í…Œì´ë¸” NULL ê°’ ë¶„ì„...")
        
        try:
            # ì „ì²´ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
            count_result = self.client.table('properties').select('*', count='exact').limit(1).execute()
            total_count = count_result.count or 0
            
            if total_count == 0:
                print("âš ï¸ properties í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return
            
            print(f"ğŸ“Š ì „ì²´ ë ˆì½”ë“œ: {total_count:,}ê°œ")
            
            # ìƒ˜í”Œ ë°ì´í„°ë¡œ NULL íŒ¨í„´ ë¶„ì„
            sample_size = min(1000, total_count)
            sample_result = self.client.table('properties').select('*').limit(sample_size).execute()
            sample_data = sample_result.data
            
            print(f"ğŸ“ˆ ë¶„ì„ ìƒ˜í”Œ: {len(sample_data):,}ê°œ")
            
            # ì»¬ëŸ¼ë³„ NULL í†µê³„
            null_stats = {}
            column_names = list(sample_data[0].keys()) if sample_data else []
            
            for column in column_names:
                null_count = sum(1 for record in sample_data if record.get(column) is None or record.get(column) == '' or record.get(column) == '-')
                null_percentage = (null_count / len(sample_data)) * 100
                
                null_stats[column] = {
                    'null_count': null_count,
                    'total_count': len(sample_data),
                    'null_percentage': null_percentage,
                    'data_type': self._detect_data_type(sample_data, column)
                }
            
            # NULLì´ ë§ì€ ì»¬ëŸ¼ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_nulls = sorted(null_stats.items(), key=lambda x: x[1]['null_percentage'], reverse=True)
            
            print(f"\nğŸ“‹ ì»¬ëŸ¼ë³„ NULL ê°’ í†µê³„ (ìƒìœ„ 20ê°œ):")
            print(f"{'ì»¬ëŸ¼ëª…':<25} {'NULL ë¹„ìœ¨':<10} {'NULL ê°œìˆ˜':<8} {'ì „ì²´':<8} {'ë°ì´í„° íƒ€ì…':<15}")
            print("-" * 75)
            
            for column, stats in sorted_nulls[:20]:
                print(f"{column:<25} {stats['null_percentage']:>6.1f}% {stats['null_count']:>8,} {stats['total_count']:>8,} {stats['data_type']:<15}")
            
            self.analysis_results['legacy_properties'] = {
                'total_records': total_count,
                'sample_size': len(sample_data),
                'null_statistics': null_stats,
                'high_null_columns': [col for col, stats in sorted_nulls if stats['null_percentage'] > 50]
            }
            
            return null_stats
            
        except Exception as e:
            print(f"âŒ properties í…Œì´ë¸” ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    def analyze_normalized_tables(self):
        """ì •ê·œí™”ëœ í…Œì´ë¸”ë“¤ì˜ NULL ê°’ ë¶„ì„"""
        print("\nğŸ” ì •ê·œí™”ëœ í…Œì´ë¸”ë“¤ NULL ê°’ ë¶„ì„...")
        
        normalized_tables = [
            'properties_new', 'property_locations', 'property_physical', 
            'property_prices', 'property_images', 'property_facilities',
            'realtors', 'property_realtors'
        ]
        
        normalized_results = {}
        
        for table_name in normalized_tables:
            try:
                print(f"\nğŸ“‹ {table_name} í…Œì´ë¸” ë¶„ì„...")
                
                # í…Œì´ë¸” ì¡´ì¬ ë° ë ˆì½”ë“œ ìˆ˜ í™•ì¸
                count_result = self.client.table(table_name).select('*', count='exact').limit(1).execute()
                record_count = count_result.count or 0
                
                if record_count == 0:
                    print(f"   ğŸ“‹ ë¹ˆ í…Œì´ë¸” (0ê°œ ë ˆì½”ë“œ)")
                    normalized_results[table_name] = {'status': 'empty', 'record_count': 0}
                    continue
                
                # ìƒ˜í”Œ ë°ì´í„°ë¡œ NULL ë¶„ì„
                sample_size = min(500, record_count)
                sample_result = self.client.table(table_name).select('*').limit(sample_size).execute()
                sample_data = sample_result.data
                
                if not sample_data:
                    continue
                
                # ì»¬ëŸ¼ë³„ NULL í†µê³„
                columns = list(sample_data[0].keys())
                table_null_stats = {}
                
                for column in columns:
                    null_count = sum(1 for record in sample_data if record.get(column) is None)
                    null_percentage = (null_count / len(sample_data)) * 100
                    
                    table_null_stats[column] = {
                        'null_count': null_count,
                        'null_percentage': null_percentage,
                        'sample_values': [record.get(column) for record in sample_data[:5] if record.get(column) is not None][:3]
                    }
                
                # ë¬¸ì œê°€ ìˆëŠ” ì»¬ëŸ¼ë“¤ ì‹ë³„
                critical_nulls = [(col, stats) for col, stats in table_null_stats.items() 
                                if stats['null_percentage'] > 30 and col not in ['id', 'created_at', 'updated_at']]
                
                if critical_nulls:
                    print(f"   âš ï¸ ë†’ì€ NULL ë¹„ìœ¨ ì»¬ëŸ¼ë“¤:")
                    for col, stats in critical_nulls:
                        print(f"     - {col}: {stats['null_percentage']:.1f}% NULL")
                
                print(f"   âœ… {record_count:,}ê°œ ë ˆì½”ë“œ, {len(columns)}ê°œ ì»¬ëŸ¼")
                
                normalized_results[table_name] = {
                    'record_count': record_count,
                    'sample_size': len(sample_data),
                    'null_statistics': table_null_stats,
                    'critical_null_columns': [col for col, stats in critical_nulls]
                }
                
            except Exception as e:
                print(f"   âŒ {table_name} ë¶„ì„ ì‹¤íŒ¨: {e}")
                normalized_results[table_name] = {'status': 'error', 'error': str(e)}
        
        self.analysis_results['normalized_tables'] = normalized_results
        return normalized_results
    
    def analyze_foreign_key_issues(self):
        """ì™¸ë˜í‚¤ ê´€ë ¨ NULL ê°’ ë¬¸ì œ ë¶„ì„"""
        print("\nğŸ” ì™¸ë˜í‚¤ ê´€ë ¨ NULL ê°’ ë¬¸ì œ ë¶„ì„...")
        
        foreign_key_issues = {}
        
        try:
            # properties_new í…Œì´ë¸”ì˜ ì™¸ë˜í‚¤ í•„ë“œ ë¶„ì„
            if 'properties_new' in self.analysis_results.get('normalized_tables', {}):
                props_result = self.client.table('properties_new').select('*').limit(200).execute()
                props_data = props_result.data
                
                if props_data:
                    fk_fields = ['real_estate_type_id', 'trade_type_id', 'region_id']
                    fk_analysis = {}
                    
                    for fk_field in fk_fields:
                        null_count = sum(1 for record in props_data if record.get(fk_field) is None)
                        null_percentage = (null_count / len(props_data)) * 100
                        
                        fk_analysis[fk_field] = {
                            'null_count': null_count,
                            'null_percentage': null_percentage,
                            'total_records': len(props_data)
                        }
                        
                        if null_percentage > 10:
                            print(f"   âš ï¸ {fk_field}: {null_percentage:.1f}% NULL ({null_count}ê°œ)")
                    
                    foreign_key_issues['properties_new'] = fk_analysis
            
            # ì°¸ì¡° í…Œì´ë¸”ë“¤ì˜ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            reference_tables = ['real_estate_types', 'trade_types', 'regions']
            ref_status = {}
            
            for ref_table in reference_tables:
                try:
                    count_result = self.client.table(ref_table).select('*', count='exact').limit(1).execute()
                    record_count = count_result.count or 0
                    ref_status[ref_table] = record_count
                    print(f"   ğŸ“Š {ref_table}: {record_count:,}ê°œ ë ˆì½”ë“œ")
                except Exception as e:
                    ref_status[ref_table] = f"ì˜¤ë¥˜: {e}"
                    print(f"   âŒ {ref_table}: {e}")
            
            foreign_key_issues['reference_table_status'] = ref_status
            
        except Exception as e:
            print(f"âŒ ì™¸ë˜í‚¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        self.analysis_results['foreign_key_issues'] = foreign_key_issues
        return foreign_key_issues
    
    def analyze_enhanced_collector_null_handling(self):
        """enhanced_data_collector.pyì˜ NULL ì²˜ë¦¬ ë¡œì§ ë¶„ì„"""
        print("\nğŸ” enhanced_data_collector.py NULL ì²˜ë¦¬ ë¡œì§ ë¶„ì„...")
        
        collector_analysis = {
            'safe_functions': {},
            'null_handling_patterns': {},
            'potential_issues': []
        }
        
        try:
            # enhanced_data_collector.py íŒŒì¼ ì½ê¸°
            collector_file = current_dir / 'enhanced_data_collector.py'
            if collector_file.exists():
                with open(collector_file, 'r', encoding='utf-8') as f:
                    collector_code = f.read()
                
                # safe_* í•¨ìˆ˜ë“¤ ë¶„ì„
                safe_functions = [
                    'safe_coordinate', 'safe_int', 'safe_float', 'safe_price', 
                    'safe_int_for_image'
                ]
                
                for func_name in safe_functions:
                    if func_name in collector_code:
                        collector_analysis['safe_functions'][func_name] = 'found'
                        print(f"   âœ… {func_name} í•¨ìˆ˜ ë°œê²¬")
                    else:
                        collector_analysis['safe_functions'][func_name] = 'missing'
                        print(f"   âŒ {func_name} í•¨ìˆ˜ ëˆ„ë½")
                
                # ê¸°ë³¸ê°’ ì„¤ì • íŒ¨í„´ ë¶„ì„
                default_value_patterns = [
                    ('area_exclusive = 10.0', 'ìµœì†Œ ë©´ì  ê¸°ë³¸ê°’'),
                    ('cortar_no = "1168010100"', 'ê¸°ë³¸ ì§€ì—­ ì„¤ì •'),
                    ('real_estate_type = "ì•Œ ìˆ˜ ì—†ìŒ"', 'ê¸°ë³¸ ë¶€ë™ì‚° ìœ í˜•'),
                    ('trade_type = "ì•Œ ìˆ˜ ì—†ìŒ"', 'ê¸°ë³¸ ê±°ë˜ ìœ í˜•')
                ]
                
                for pattern, description in default_value_patterns:
                    if pattern in collector_code:
                        collector_analysis['null_handling_patterns'][description] = 'implemented'
                        print(f"   âœ… {description}: êµ¬í˜„ë¨")
                    else:
                        collector_analysis['null_handling_patterns'][description] = 'missing'
                        print(f"   âš ï¸ {description}: ëˆ„ë½")
                        collector_analysis['potential_issues'].append(f"{description} íŒ¨í„´ì´ ëˆ„ë½ë¨")
            
            else:
                print("   âŒ enhanced_data_collector.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                collector_analysis['potential_issues'].append("enhanced_data_collector.py íŒŒì¼ ì—†ìŒ")
        
        except Exception as e:
            print(f"   âŒ ì½”ë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            collector_analysis['potential_issues'].append(f"ì½”ë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        self.analysis_results['collector_analysis'] = collector_analysis
        return collector_analysis
    
    def identify_null_root_causes(self):
        """NULL ê°’ ë°œìƒ ì›ì¸ ë¶„ì„"""
        print("\nğŸ” NULL ê°’ ë°œìƒ ì›ì¸ ë¶„ì„...")
        
        root_causes = {
            'api_response_missing_fields': [],
            'parsing_failures': [],
            'validation_failures': [],
            'foreign_key_resolution_failures': [],
            'data_transformation_issues': []
        }
        
        # 1. API ì‘ë‹µ ëˆ„ë½ í•„ë“œ ë¶„ì„
        legacy_stats = self.analysis_results.get('legacy_properties', {}).get('null_statistics', {})
        
        high_null_fields = []
        for field, stats in legacy_stats.items():
            if stats['null_percentage'] > 70:
                high_null_fields.append((field, stats['null_percentage']))
        
        if high_null_fields:
            print(f"   ğŸ“Š API ì‘ë‹µì—ì„œ ìì£¼ ëˆ„ë½ë˜ëŠ” í•„ë“œë“¤:")
            for field, percentage in sorted(high_null_fields, key=lambda x: x[1], reverse=True)[:10]:
                print(f"     - {field}: {percentage:.1f}% NULL")
                root_causes['api_response_missing_fields'].append({
                    'field': field,
                    'null_percentage': percentage,
                    'likely_cause': self._analyze_field_null_cause(field)
                })
        
        # 2. ì™¸ë˜í‚¤ í•´ê²° ì‹¤íŒ¨ ë¶„ì„
        fk_issues = self.analysis_results.get('foreign_key_issues', {})
        if fk_issues.get('properties_new'):
            print(f"   ğŸ”— ì™¸ë˜í‚¤ í•´ê²° ì‹¤íŒ¨:")
            for fk_field, stats in fk_issues['properties_new'].items():
                if stats['null_percentage'] > 5:
                    print(f"     - {fk_field}: {stats['null_percentage']:.1f}% NULL")
                    root_causes['foreign_key_resolution_failures'].append({
                        'field': fk_field,
                        'null_percentage': stats['null_percentage'],
                        'recommended_fix': self._get_fk_fix_recommendation(fk_field)
                    })
        
        # 3. ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨ ë¶„ì„
        normalized_tables = self.analysis_results.get('normalized_tables', {})
        for table_name, table_data in normalized_tables.items():
            if table_data.get('critical_null_columns'):
                for column in table_data['critical_null_columns']:
                    root_causes['validation_failures'].append({
                        'table': table_name,
                        'column': column,
                        'issue': 'High NULL percentage',
                        'recommended_fix': self._get_validation_fix(table_name, column)
                    })
        
        self.analysis_results['root_causes'] = root_causes
        return root_causes
    
    def generate_data_quality_recommendations(self):
        """ë°ì´í„° í’ˆì§ˆ ê°œì„  ë°©ì•ˆ ìƒì„±"""
        print("\nğŸ’¡ ë°ì´í„° í’ˆì§ˆ ê°œì„  ë°©ì•ˆ ìƒì„±...")
        
        recommendations = {
            'immediate_fixes': [],
            'collector_improvements': [],
            'schema_adjustments': [],
            'monitoring_enhancements': []
        }
        
        # 1. ì¦‰ì‹œ ìˆ˜ì • ê°€ëŠ¥í•œ ë¬¸ì œë“¤
        root_causes = self.analysis_results.get('root_causes', {})
        
        for fk_failure in root_causes.get('foreign_key_resolution_failures', []):
            if fk_failure['null_percentage'] > 20:
                recommendations['immediate_fixes'].append({
                    'priority': 'HIGH',
                    'issue': f"{fk_failure['field']} ì™¸ë˜í‚¤ {fk_failure['null_percentage']:.1f}% NULL",
                    'fix': fk_failure['recommended_fix'],
                    'code_example': self._generate_fix_code(fk_failure['field'])
                })
        
        # 2. ìˆ˜ì§‘ê¸° ê°œì„  ì‚¬í•­
        collector_issues = self.analysis_results.get('collector_analysis', {}).get('potential_issues', [])
        for issue in collector_issues:
            recommendations['collector_improvements'].append({
                'issue': issue,
                'fix': self._get_collector_improvement(issue)
            })
        
        # 3. ìŠ¤í‚¤ë§ˆ ì¡°ì • ì‚¬í•­
        for table_name, table_data in self.analysis_results.get('normalized_tables', {}).items():
            if table_data.get('critical_null_columns'):
                for column in table_data['critical_null_columns']:
                    recommendations['schema_adjustments'].append({
                        'table': table_name,
                        'column': column,
                        'suggestion': f"{column} ì»¬ëŸ¼ì— ê¸°ë³¸ê°’ ë˜ëŠ” NOT NULL ì œì•½ì¡°ê±´ ì¶”ê°€ ê²€í† "
                    })
        
        # 4. ëª¨ë‹ˆí„°ë§ ê°•í™”
        recommendations['monitoring_enhancements'] = [
            "ì‹¤ì‹œê°„ NULL ê°’ ë¹„ìœ¨ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•",
            "ì™¸ë˜í‚¤ í•´ê²° ì‹¤íŒ¨ìœ¨ ì•Œë¦¼ ì‹œìŠ¤í…œ",
            "API ì‘ë‹µ í•„ë“œ ëˆ„ë½ íŒ¨í„´ ì¶”ì ",
            "ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ìë™ ê³„ì‚° ë° ë¦¬í¬íŠ¸"
        ]
        
        self.analysis_results['recommendations'] = recommendations
        return recommendations
    
    def _detect_data_type(self, sample_data, column):
        """ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì… ì¶”ì •"""
        non_null_values = [record.get(column) for record in sample_data 
                          if record.get(column) is not None and record.get(column) != '']
        
        if not non_null_values:
            return 'unknown'
        
        sample_value = non_null_values[0]
        
        if isinstance(sample_value, bool):
            return 'boolean'
        elif isinstance(sample_value, int):
            return 'integer'
        elif isinstance(sample_value, float):
            return 'float'
        elif isinstance(sample_value, dict):
            return 'json'
        elif isinstance(sample_value, list):
            return 'array'
        else:
            return 'text'
    
    def _analyze_field_null_cause(self, field):
        """í•„ë“œë³„ NULL ì›ì¸ ë¶„ì„"""
        cause_mapping = {
            'price': 'APIì—ì„œ ê°€ê²© ì •ë³´ ë¯¸ì œê³µ (ë¹„ê³µê°œ ë§¤ë¬¼)',
            'area1': 'APIì—ì„œ ë©´ì  ì •ë³´ ëˆ„ë½',
            'area2': 'APIì—ì„œ ê³µê¸‰ë©´ì  ì •ë³´ ëˆ„ë½',
            'floor_info': 'APIì—ì„œ ì¸µ ì •ë³´ ë¯¸ì œê³µ',
            'description': 'ìƒì„¸ ì„¤ëª… ì‘ì„±í•˜ì§€ ì•Šì€ ë§¤ë¬¼',
            'tag_list': 'íƒœê·¸ ì •ë³´ ì—†ëŠ” ë§¤ë¬¼',
            'details': 'API ì‘ë‹µ êµ¬ì¡° ë³€ê²½ ë˜ëŠ” íŒŒì‹± ì‹¤íŒ¨'
        }
        
        for key, cause in cause_mapping.items():
            if key in field.lower():
                return cause
        
        return 'API ì‘ë‹µ í•„ë“œ ëˆ„ë½ ë˜ëŠ” íŒŒì‹± ì‹¤íŒ¨'
    
    def _get_fk_fix_recommendation(self, fk_field):
        """ì™¸ë˜í‚¤ ìˆ˜ì • ê¶Œì¥ì‚¬í•­"""
        fix_mapping = {
            'real_estate_type_id': 'buildingUse, lawUsage í•„ë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ "ê¸°íƒ€" íƒ€ì…ìœ¼ë¡œ ê¸°ë³¸ê°’ ì„¤ì •',
            'trade_type_id': 'price, rent_price, warrant_price ì¡´ì¬ ì—¬ë¶€ë¡œ ê±°ë˜ ìœ í˜• ì¶”ë¡ ',
            'region_id': 'cortarNoê°€ ì—†ìœ¼ë©´ ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ ì§€ì—­ ì¶”ì • ë˜ëŠ” "ë¯¸ë¶„ë¥˜" ì§€ì—­ ìƒì„±'
        }
        
        return fix_mapping.get(fk_field, 'ê¸°ë³¸ê°’ ì„¤ì • ë¡œì§ ê°•í™” í•„ìš”')
    
    def _get_validation_fix(self, table_name, column):
        """ê²€ì¦ ìˆ˜ì • ê¶Œì¥ì‚¬í•­"""
        return f"{table_name}.{column}ì— ëŒ€í•œ NULL ê²€ì¦ ë¡œì§ ê°•í™” í•„ìš”"
    
    def _generate_fix_code(self, fk_field):
        """ìˆ˜ì • ì½”ë“œ ì˜ˆì‹œ ìƒì„±"""
        code_examples = {
            'real_estate_type_id': '''
def _resolve_real_estate_type_id(self, data: Dict) -> Optional[int]:
    # 1. buildingUse ìš°ì„  í™•ì¸
    type_name = data.get('basic_info', {}).get('building_use')
    
    # 2. raw_sectionsì—ì„œ ì¶”ì¶œ
    if not type_name:
        raw_sections = data.get('raw_sections', {})
        if 'articleDetail' in raw_sections:
            detail = raw_sections['articleDetail']
            type_name = (detail.get('realEstateTypeName') or 
                        detail.get('buildingUse') or
                        detail.get('lawUsage'))
    
    # 3. ê¸°ë³¸ê°’ ì„¤ì • (NULL ë°©ì§€)
    if not type_name:
        type_name = "ê¸°íƒ€"
        
    return self._get_or_create_real_estate_type(type_name)
''',
            'trade_type_id': '''
def _resolve_trade_type_id(self, data: Dict) -> Optional[int]:
    price_info = data.get('price_info', {})
    
    # ê°€ê²© ì •ë³´ ê¸°ë°˜ ê±°ë˜ ìœ í˜• ì¶”ë¡ 
    if price_info.get('deal_price'):
        trade_type = "ë§¤ë§¤"
    elif price_info.get('rent_price'):
        trade_type = "ì›”ì„¸"  
    elif price_info.get('warrant_price'):
        trade_type = "ì „ì„¸"
    else:
        trade_type = "ê¸°íƒ€"  # NULL ë°©ì§€
        
    return self._get_or_create_trade_type(trade_type)
''',
            'region_id': '''
def _resolve_region_id(self, data: Dict) -> Optional[int]:
    # 1. cortarNo ì§ì ‘ ì‚¬ìš©
    cortar_no = data.get('raw_sections', {}).get('articleDetail', {}).get('cortarNo')
    
    # 2. ì¢Œí‘œ ê¸°ë°˜ ì§€ì—­ ì¶”ì •
    if not cortar_no:
        lat = data.get('basic_info', {}).get('latitude')
        lon = data.get('basic_info', {}).get('longitude')
        if lat and lon:
            cortar_no = self._estimate_cortar_from_coordinates(lat, lon)
    
    # 3. ê¸°ë³¸ ì§€ì—­ ì„¤ì • (NULL ë°©ì§€)
    if not cortar_no:
        cortar_no = "9999999999"  # "ë¯¸ë¶„ë¥˜" ì§€ì—­
        
    return self._get_or_create_region(cortar_no)
'''
        }
        
        return code_examples.get(fk_field, '# ìˆ˜ì • ì½”ë“œ ì˜ˆì‹œ ì—†ìŒ')
    
    def _get_collector_improvement(self, issue):
        """ìˆ˜ì§‘ê¸° ê°œì„  ë°©ì•ˆ"""
        improvement_mapping = {
            'ìµœì†Œ ë©´ì  ê¸°ë³¸ê°’ íŒ¨í„´ì´ ëˆ„ë½ë¨': 'safe_float í•¨ìˆ˜ì— ìµœì†Œê°’ ê²€ì¦ ë¡œì§ ì¶”ê°€',
            'ê¸°ë³¸ ì§€ì—­ ì„¤ì • íŒ¨í„´ì´ ëˆ„ë½ë¨': '_resolve_region_idì— ê¸°ë³¸ ì§€ì—­ ì„¤ì • ë¡œì§ ì¶”ê°€',
            'enhanced_data_collector.py íŒŒì¼ ì—†ìŒ': 'ìˆ˜ì§‘ê¸° íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ë³µêµ¬ í•„ìš”'
        }
        
        return improvement_mapping.get(issue, 'ê°œì„  ë°©ì•ˆ ê²€í†  í•„ìš”')
    
    def generate_comprehensive_report(self):
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\nğŸ“Š ì¢…í•© NULL ê°’ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±...")
        
        report = {
            'analysis_timestamp': datetime.now().isoformat(),
            'summary': {},
            'detailed_analysis': self.analysis_results,
            'executive_summary': {},
            'action_plan': {}
        }
        
        # ìš”ì•½ í†µê³„
        legacy_stats = self.analysis_results.get('legacy_properties', {})
        if legacy_stats:
            high_null_count = len(legacy_stats.get('high_null_columns', []))
            report['summary'] = {
                'total_legacy_records': legacy_stats.get('total_records', 0),
                'high_null_columns_count': high_null_count,
                'data_quality_score': max(0, 100 - (high_null_count * 5))  # ê°„ë‹¨í•œ ì ìˆ˜ ê³„ì‚°
            }
        
        # ê²½ì˜ì§„ ìš”ì•½
        recommendations = self.analysis_results.get('recommendations', {})
        high_priority_fixes = len([fix for fix in recommendations.get('immediate_fixes', []) 
                                 if fix.get('priority') == 'HIGH'])
        
        report['executive_summary'] = {
            'critical_issues_found': high_priority_fixes,
            'estimated_data_loss': self._estimate_data_loss(),
            'recommended_actions': len(recommendations.get('immediate_fixes', [])),
            'implementation_priority': 'HIGH' if high_priority_fixes > 0 else 'MEDIUM'
        }
        
        # ì‹¤í–‰ ê³„íš
        report['action_plan'] = {
            'phase_1_immediate': recommendations.get('immediate_fixes', []),
            'phase_2_collector_improvements': recommendations.get('collector_improvements', []),
            'phase_3_schema_optimization': recommendations.get('schema_adjustments', []),
            'phase_4_monitoring': recommendations.get('monitoring_enhancements', [])
        }
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_file = current_dir / f"null_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ’¾ ì¢…í•© ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")
        
        # ìš”ì•½ ì¶œë ¥
        self._print_executive_summary(report)
        
        return report
    
    def _estimate_data_loss(self):
        """ë°ì´í„° ì†ì‹¤ ì¶”ì •"""
        legacy_stats = self.analysis_results.get('legacy_properties', {}).get('null_statistics', {})
        
        critical_fields = ['price', 'area1', 'area2', 'real_estate_type', 'trade_type']
        total_loss_percentage = 0
        
        for field in critical_fields:
            if field in legacy_stats:
                total_loss_percentage += legacy_stats[field]['null_percentage']
        
        average_loss = total_loss_percentage / len(critical_fields) if critical_fields else 0
        return min(average_loss, 100)
    
    def _print_executive_summary(self, report):
        """ê²½ì˜ì§„ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š NULL ê°’ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ - ê²½ì˜ì§„ ìš”ì•½")
        print("="*80)
        
        summary = report['summary']
        exec_summary = report['executive_summary']
        
        print(f"ğŸ“ˆ ì „ì²´ ë ˆì½”ë“œ: {summary.get('total_legacy_records', 0):,}ê°œ")
        print(f"âš ï¸ ë†’ì€ NULL ë¹„ìœ¨ ì»¬ëŸ¼: {summary.get('high_null_columns_count', 0)}ê°œ")
        print(f"ğŸ¯ ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {summary.get('data_quality_score', 0):.1f}/100ì ")
        print(f"ğŸš¨ ì¤‘ìš” ë¬¸ì œ: {exec_summary.get('critical_issues_found', 0)}ê°œ")
        print(f"ğŸ“‰ ì¶”ì • ë°ì´í„° ì†ì‹¤: {exec_summary.get('estimated_data_loss', 0):.1f}%")
        print(f"ğŸ”§ ê¶Œì¥ ì¡°ì¹˜: {exec_summary.get('recommended_actions', 0)}ê°œ")
        print(f"â° ìš°ì„ ìˆœìœ„: {exec_summary.get('implementation_priority', 'UNKNOWN')}")
        
        print(f"\nğŸ’¡ ì£¼ìš” ê¶Œì¥ì‚¬í•­:")
        phase_1 = report['action_plan'].get('phase_1_immediate', [])
        for i, fix in enumerate(phase_1[:3], 1):
            print(f"   {i}. {fix.get('issue', 'Unknown issue')}")
        
        if len(phase_1) > 3:
            print(f"   ... ì™¸ {len(phase_1)-3}ê°œ ì¶”ê°€ ê¶Œì¥ì‚¬í•­")
        
        print("="*80)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë°ì´í„°ë² ì´ìŠ¤ NULL ê°’ ì¢…í•© ë¶„ì„ ì‹œì‘")
    print("="*60)
    
    analyzer = NullValueAnalyzer()
    
    try:
        # 1. ê¸°ì¡´ properties í…Œì´ë¸” ë¶„ì„
        analyzer.analyze_legacy_properties_table()
        
        # 2. ì •ê·œí™”ëœ í…Œì´ë¸”ë“¤ ë¶„ì„
        analyzer.analyze_normalized_tables()
        
        # 3. ì™¸ë˜í‚¤ ê´€ë ¨ ë¬¸ì œ ë¶„ì„
        analyzer.analyze_foreign_key_issues()
        
        # 4. enhanced_data_collector.py ë¶„ì„
        analyzer.analyze_enhanced_collector_null_handling()
        
        # 5. NULL ê°’ ì›ì¸ ë¶„ì„
        analyzer.identify_null_root_causes()
        
        # 6. ê°œì„  ë°©ì•ˆ ìƒì„±
        analyzer.generate_data_quality_recommendations()
        
        # 7. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        report = analyzer.generate_comprehensive_report()
        
        print("\nâœ… ë¶„ì„ ì™„ë£Œ! ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì—¬ ê°œì„  ì‘ì—…ì„ ì§„í–‰í•˜ì„¸ìš”.")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()