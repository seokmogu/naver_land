#!/usr/bin/env python3
"""
ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸”ë“¤ì˜ í™œìš©ë„ ìµœì í™”
- areas í…Œì´ë¸” í™œìš© ê°•í™”
- health_reports í…Œì´ë¸” í™œìš©
- ìƒˆë¡œìš´ ë¶„ì„ í…Œì´ë¸” ì œì•ˆ
- ë°ì´í„° ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ
"""

import json
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional
from supabase_client import SupabaseHelper

class UnusedTablesOptimizer:
    """ë¯¸ì‚¬ìš© í…Œì´ë¸” í™œìš© ìµœì í™”ê¸°"""
    
    def __init__(self):
        self.helper = SupabaseHelper()
    
    def analyze_table_usage(self) -> Dict:
        """í…Œì´ë¸”ë³„ í™œìš©ë„ ë¶„ì„"""
        print("ğŸ“Š í…Œì´ë¸”ë³„ í™œìš©ë„ ë¶„ì„")
        print("=" * 50)
        
        usage_report = {
            'analysis_date': date.today().isoformat(),
            'tables': {}
        }
        
        # ì£¼ìš” í…Œì´ë¸”ë“¤ì˜ í™œìš©ë„ ë¶„ì„
        tables_to_analyze = [
            'properties', 'areas', 'daily_stats', 'collection_logs',
            'price_history', 'deletion_history', 'health_reports'
        ]
        
        for table_name in tables_to_analyze:
            usage_report['tables'][table_name] = self._analyze_single_table(table_name)
        
        self._print_usage_report(usage_report)
        return usage_report
    
    def _analyze_single_table(self, table_name: str) -> Dict:
        """ê°œë³„ í…Œì´ë¸” ë¶„ì„"""
        try:
            # í…Œì´ë¸” ê¸°ë³¸ ì •ë³´
            total_count = self.helper.client.table(table_name)\
                .select('*', count='exact')\
                .execute()
            
            analysis = {
                'total_records': total_count.count or 0,
                'usage_level': 'UNKNOWN',
                'last_activity': None,
                'recommendations': [],
                'potential_uses': []
            }
            
            # í…Œì´ë¸”ë³„ êµ¬ì²´ì  ë¶„ì„
            if table_name == 'areas':
                analysis.update(self._analyze_areas_table())
            elif table_name == 'health_reports':
                analysis.update(self._analyze_health_reports_table())
            elif table_name == 'properties':
                analysis.update(self._analyze_properties_table())
            elif table_name == 'daily_stats':
                analysis.update(self._analyze_daily_stats_table())
            
            return analysis
            
        except Exception as e:
            return {
                'error': str(e),
                'usage_level': 'ERROR',
                'recommendations': ['í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í•„ìš”']
            }
    
    def _analyze_areas_table(self) -> Dict:
        """areas í…Œì´ë¸” ë¶„ì„"""
        try:
            # areas í…Œì´ë¸” ë°ì´í„° í™•ì¸
            areas_data = self.helper.client.table('areas')\
                .select('*')\
                .limit(10)\
                .execute()
            
            if not areas_data.data:
                return {
                    'usage_level': 'UNUSED',
                    'recommendations': [
                        'areas í…Œì´ë¸”ì— ì„œìš¸ ê°•ë‚¨êµ¬ ì§€ì—­ ì •ë³´ ì…ë ¥',
                        'ì§€ì—­ë³„ ë©”íƒ€ë°ì´í„°(ì¸êµ¬, í‰ê· ì†Œë“, êµí†µì ìˆ˜ ë“±) ì¶”ê°€'
                    ],
                    'potential_uses': [
                        'ì§€ì—­ë³„ ìˆ˜ì§‘ ìš°ì„ ìˆœìœ„ ìë™ ê³„ì‚°',
                        'ì§€ì—­ íŠ¹ì„± ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸',
                        'ìˆ˜ì§‘ ì„±ê³¼ ì§€ì—­ë³„ ë²¤ì¹˜ë§ˆí‚¹'
                    ]
                }
            else:
                return {
                    'usage_level': 'UNDERUTILIZED',
                    'recommendations': [
                        'areas í…Œì´ë¸”ì„ í™œìš©í•œ ì§€ëŠ¥í˜• ìŠ¤ì¼€ì¤„ë§ êµ¬í˜„',
                        'ì§€ì—­ë³„ ì„±ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ì—°ë™'
                    ],
                    'potential_uses': [
                        'ë™ì  ìˆ˜ì§‘ ìš°ì„ ìˆœìœ„ ì¡°ì •',
                        'ì§€ì—­ë³„ ì„±ê³¼ KPI ì¶”ì '
                    ]
                }
        except:
            return {'usage_level': 'ERROR'}
    
    def _analyze_health_reports_table(self) -> Dict:
        """health_reports í…Œì´ë¸” ë¶„ì„"""
        try:
            # ìµœê·¼ ê±´ê°•ì„± ë³´ê³ ì„œ í™•ì¸
            recent_reports = self.helper.client.table('health_reports')\
                .select('*')\
                .order('created_at', desc=True)\
                .limit(5)\
                .execute()
            
            if not recent_reports.data:
                return {
                    'usage_level': 'UNUSED',
                    'recommendations': [
                        'daily_health_monitor.pyì™€ ì—°ë™í•˜ì—¬ ì •ê¸° ë³´ê³ ì„œ ì €ì¥',
                        'ê±´ê°•ì„± íŠ¸ë Œë“œ ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€'
                    ],
                    'potential_uses': [
                        'ì‹œìŠ¤í…œ ê±´ê°•ì„± íˆìŠ¤í† ë¦¬ ì¶”ì ',
                        'ì„±ëŠ¥ ì €í•˜ íŒ¨í„´ ë¶„ì„',
                        'ì˜ˆì¸¡ì  ìœ ì§€ë³´ìˆ˜ ì•Œë¦¼'
                    ]
                }
            else:
                return {
                    'usage_level': 'ACTIVE',
                    'last_activity': recent_reports.data[0].get('created_at'),
                    'recommendations': [
                        'ê±´ê°•ì„± ë³´ê³ ì„œ ê¸°ë°˜ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•',
                        'íŠ¸ë Œë“œ ë¶„ì„ì„ í†µí•œ ì˜ˆì¸¡ ìœ ì§€ë³´ìˆ˜'
                    ]
                }
        except:
            return {'usage_level': 'ERROR'}
    
    def _analyze_properties_table(self) -> Dict:
        """properties í…Œì´ë¸” ë¶„ì„ (ì°¸ì¡°ìš©)"""
        return {
            'usage_level': 'HIGHLY_ACTIVE',
            'last_activity': datetime.now().isoformat(),
            'recommendations': [
                'ì„±ëŠ¥ ìµœì í™”: ì¸ë±ìŠ¤ ì¶”ê°€ ê²€í† ',
                'íŒŒí‹°ì…”ë‹: ë‚ ì§œë³„ íŒŒí‹°ì…˜ êµ¬ì„± ê³ ë ¤'
            ]
        }
    
    def _analyze_daily_stats_table(self) -> Dict:
        """daily_stats í…Œì´ë¸” ë¶„ì„"""
        try:
            # ìµœê·¼ í†µê³„ í™•ì¸
            recent_stats = self.helper.client.table('daily_stats')\
                .select('*')\
                .order('stat_date', desc=True)\
                .limit(1)\
                .execute()
            
            if recent_stats.data:
                last_date = recent_stats.data[0]['stat_date']
                return {
                    'usage_level': 'ACTIVE',
                    'last_activity': last_date,
                    'recommendations': [
                        'í†µê³„ ê¸°ë°˜ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•',
                        'ì£¼ê°„/ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„ ìë™í™”'
                    ]
                }
            else:
                return {
                    'usage_level': 'UNDERUTILIZED',
                    'recommendations': ['daily_stats ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì ê²€']
                }
        except:
            return {'usage_level': 'ERROR'}
    
    def _print_usage_report(self, report: Dict):
        """ì‚¬ìš© í˜„í™© ë³´ê³ ì„œ ì¶œë ¥"""
        print(f"\nğŸ“‹ í…Œì´ë¸” í™œìš©ë„ ë¶„ì„ ê²°ê³¼")
        print(f"ğŸ“… ë¶„ì„ì¼: {report['analysis_date']}")
        print("-" * 50)
        
        usage_levels = {
            'HIGHLY_ACTIVE': 'ğŸŸ¢ ë§¤ìš° í™œë°œ',
            'ACTIVE': 'ğŸ”µ í™œë°œ',  
            'UNDERUTILIZED': 'ğŸŸ¡ ì €í™œìš©',
            'UNUSED': 'ğŸ”´ ë¯¸ì‚¬ìš©',
            'ERROR': 'âšª ì˜¤ë¥˜'
        }
        
        for table_name, analysis in report['tables'].items():
            level = analysis['usage_level']
            level_text = usage_levels.get(level, level)
            record_count = analysis.get('total_records', 0)
            
            print(f"\nğŸ“Š {table_name}")
            print(f"   ìƒíƒœ: {level_text}")
            print(f"   ë ˆì½”ë“œ: {record_count:,}ê°œ")
            
            if 'last_activity' in analysis and analysis['last_activity']:
                print(f"   ìµœê·¼í™œë™: {analysis['last_activity']}")
            
            if analysis.get('recommendations'):
                print(f"   ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
                for rec in analysis['recommendations'][:2]:  # ìµœëŒ€ 2ê°œë§Œ
                    print(f"      â€¢ {rec}")
    
    def setup_areas_table_optimization(self) -> bool:
        """areas í…Œì´ë¸” ìµœì í™” ì„¤ì •"""
        print("ğŸ”§ areas í…Œì´ë¸” ìµœì í™” ì„¤ì •")
        
        try:
            # ê°•ë‚¨êµ¬ ì§€ì—­ ì •ë³´ ë°ì´í„°
            gangnam_areas = [
                {
                    "cortar_no": "1168010100",
                    "area_name": "ì—­ì‚¼ë™",
                    "district": "ê°•ë‚¨êµ¬",
                    "priority_score": 30,
                    "population": 25000,
                    "avg_income_level": "ë†’ìŒ",
                    "transport_score": 95,
                    "commercial_density": "ë§¤ìš°ë†’ìŒ",
                    "collection_frequency": "daily",
                    "target_collection_count": 500,
                    "metadata": {
                        "subway_stations": ["ê°•ë‚¨ì—­", "ì—­ì‚¼ì—­"],
                        "major_landmarks": ["í…Œí—¤ë€ë¡œ", "ê°•ë‚¨íŒŒì´ë‚¸ìŠ¤ì„¼í„°"],
                        "business_district": True
                    }
                },
                {
                    "cortar_no": "1168010500", 
                    "area_name": "ì‚¼ì„±ë™",
                    "district": "ê°•ë‚¨êµ¬",
                    "priority_score": 26,
                    "population": 22000,
                    "avg_income_level": "ë†’ìŒ",
                    "transport_score": 90,
                    "commercial_density": "ë†’ìŒ",
                    "collection_frequency": "daily",
                    "target_collection_count": 400,
                    "metadata": {
                        "subway_stations": ["ì‚¼ì„±ì—­"],
                        "major_landmarks": ["ì½”ì—‘ìŠ¤", "ë¡¯ë°íƒ€ì›Œ"],
                        "business_district": True
                    }
                },
                {
                    "cortar_no": "1168010800",
                    "area_name": "ë…¼í˜„ë™", 
                    "district": "ê°•ë‚¨êµ¬",
                    "priority_score": 23,
                    "population": 20000,
                    "avg_income_level": "ë†’ìŒ",
                    "transport_score": 85,
                    "commercial_density": "ë³´í†µ",
                    "collection_frequency": "daily",
                    "target_collection_count": 300,
                    "metadata": {
                        "subway_stations": ["ë…¼í˜„ì—­"],
                        "major_landmarks": ["í•™ë™ì‚¬ê±°ë¦¬"],
                        "business_district": False
                    }
                }
            ]
            
            # ë°ì´í„° upsert
            result = self.helper.client.table('areas').upsert(gangnam_areas).execute()
            
            print(f"âœ… areas í…Œì´ë¸” ìµœì í™” ì™„ë£Œ: {len(gangnam_areas)}ê°œ ì§€ì—­ ì •ë³´ ì…ë ¥")
            
            # areas ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì¡°íšŒ í•¨ìˆ˜ë„ ìƒì„±
            self._create_area_priority_function()
            
            return True
            
        except Exception as e:
            print(f"âŒ areas í…Œì´ë¸” ìµœì í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _create_area_priority_function(self):
        """ì§€ì—­ë³„ ìš°ì„ ìˆœìœ„ ì¡°íšŒ í•¨ìˆ˜ ìƒì„±"""
        print("ğŸ§  ì§€ì—­ ìš°ì„ ìˆœìœ„ ì¡°íšŒ í•¨ìˆ˜ ìƒì„±")
        
        # areas í…Œì´ë¸” ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì¡°íšŒ ì½”ë“œ ìƒì„±
        priority_code = '''
def get_intelligent_collection_priority():
    """areas í…Œì´ë¸” ê¸°ë°˜ ì§€ëŠ¥í˜• ìˆ˜ì§‘ ìš°ì„ ìˆœìœ„"""
    try:
        areas = helper.client.table('areas')\
            .select('cortar_no, area_name, priority_score, target_collection_count')\
            .order('priority_score', desc=True)\
            .execute()
        
        return {
            area['cortar_no']: {
                'name': area['area_name'],
                'priority': area['priority_score'],
                'target': area['target_collection_count']
            }
            for area in areas.data or []
        }
    except Exception as e:
        print(f"ìš°ì„ ìˆœìœ„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {}
'''
        
        # íŒŒì¼ë¡œ ì €ì¥
        with open('intelligent_priority.py', 'w', encoding='utf-8') as f:
            f.write(priority_code)
        
        print("âœ… intelligent_priority.py íŒŒì¼ ìƒì„± ì™„ë£Œ")
    
    def create_analytics_tables_proposal(self) -> Dict:
        """ìƒˆë¡œìš´ ë¶„ì„ í…Œì´ë¸” ì œì•ˆ"""
        print("ğŸ’¡ ìƒˆë¡œìš´ ë¶„ì„ í…Œì´ë¸” ì œì•ˆ")
        
        proposals = {
            "performance_metrics": {
                "purpose": "ìˆ˜ì§‘ê¸° ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥",
                "columns": {
                    "id": "Primary Key",
                    "timestamp": "ì¸¡ì • ì‹œê°„",
                    "metric_name": "ë©”íŠ¸ë¦­ ì´ë¦„",
                    "metric_value": "ê°’",
                    "unit": "ë‹¨ìœ„", 
                    "cortar_no": "ì§€ì—­ ì½”ë“œ",
                    "collection_session_id": "ìˆ˜ì§‘ ì„¸ì…˜ ID"
                },
                "benefits": [
                    "ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
                    "ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„",
                    "ì§€ì—­ë³„ ìˆ˜ì§‘ íš¨ìœ¨ì„± ë¹„êµ"
                ]
            },
            
            "market_insights": {
                "purpose": "ë¶€ë™ì‚° ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ì €ì¥",
                "columns": {
                    "id": "Primary Key",
                    "analysis_date": "ë¶„ì„ì¼",
                    "cortar_no": "ì§€ì—­ ì½”ë“œ",
                    "avg_price_trend": "í‰ê·  ê°€ê²© ì¶”ì„¸",
                    "supply_demand_ratio": "ê³µê¸‰ìˆ˜ìš”ë¹„ìœ¨",
                    "price_volatility": "ê°€ê²© ë³€ë™ì„±",
                    "market_sentiment": "ì‹œì¥ ì‹¬ë¦¬",
                    "insights": "JSON ì¸ì‚¬ì´íŠ¸ ë°ì´í„°"
                },
                "benefits": [
                    "ì‹œì¥ íŠ¸ë Œë“œ ìë™ ë¶„ì„",
                    "íˆ¬ì ê¸°íšŒ ë°œêµ´", 
                    "ì‹œì¥ ì˜ˆì¸¡ ëª¨ë¸ë§"
                ]
            },
            
            "data_quality_history": {
                "purpose": "ë°ì´í„° í’ˆì§ˆ ì´ë ¥ ê´€ë¦¬",
                "columns": {
                    "id": "Primary Key",
                    "check_date": "ê²€ì‚¬ì¼",
                    "quality_score": "í’ˆì§ˆ ì ìˆ˜",
                    "completeness_rate": "ì™„ì„±ë„",
                    "accuracy_rate": "ì •í™•ë„",
                    "timeliness_score": "ì ì‹œì„±",
                    "issues_detected": "ê°ì§€ëœ ë¬¸ì œë“¤",
                    "fix_actions": "ìˆ˜ì • ì¡°ì¹˜ì‚¬í•­"
                },
                "benefits": [
                    "í’ˆì§ˆ íŠ¸ë Œë“œ ì¶”ì ",
                    "ë¬¸ì œ íŒ¨í„´ ì‹ë³„",
                    "í’ˆì§ˆ ê°œì„  íš¨ê³¼ ì¸¡ì •"
                ]
            }
        }
        
        print("\nğŸ“Š ì œì•ˆëœ ë¶„ì„ í…Œì´ë¸”ë“¤:")
        for table_name, info in proposals.items():
            print(f"\nğŸ—‚ï¸ {table_name}")
            print(f"   ëª©ì : {info['purpose']}")
            print(f"   ê¸°ëŒ€íš¨ê³¼:")
            for benefit in info['benefits']:
                print(f"     â€¢ {benefit}")
        
        return proposals
    
    def setup_data_archiving_system(self) -> Dict:
        """ë°ì´í„° ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ ì„¤ê³„"""
        print("ğŸ—„ï¸ ë°ì´í„° ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ ì„¤ê³„")
        
        archiving_plan = {
            "archive_properties_old": {
                "source_table": "properties",
                "archive_criteria": "is_active = false AND updated_at < (í˜„ì¬ - 6ê°œì›”)",
                "retention_policy": "2ë…„ ë³´ê´€ í›„ ì‚­ì œ",
                "compression": "gzip ì••ì¶• ì ìš©",
                "access_pattern": "ë¶„ì„ ëª©ì ìœ¼ë¡œ ì›” 1íšŒ ë¯¸ë§Œ ì ‘ê·¼"
            },
            
            "archive_collection_logs_old": {
                "source_table": "collection_logs", 
                "archive_criteria": "created_at < (í˜„ì¬ - 3ê°œì›”)",
                "retention_policy": "1ë…„ ë³´ê´€ í›„ ì‚­ì œ",
                "compression": "gzip ì••ì¶• ì ìš©",
                "access_pattern": "ë¬¸ì œ ì¶”ì  ëª©ì ìœ¼ë¡œ ê°€ë” ì ‘ê·¼"
            },
            
            "archive_price_history_summary": {
                "source_table": "price_history",
                "archive_criteria": "ì›”ë³„ ìš”ì•½ ë°ì´í„°ë¡œ ë³€í™˜ í›„ ì›ë³¸ ì‚­ì œ",
                "retention_policy": "ìš”ì•½ ë°ì´í„°ëŠ” ì˜êµ¬ ë³´ê´€",
                "compression": "ì§‘ê³„ ë°ì´í„°ë¡œ í¬ê¸° ìµœì í™”",
                "access_pattern": "íŠ¸ë Œë“œ ë¶„ì„ìš©ìœ¼ë¡œ ì •ê¸° ì ‘ê·¼"
            }
        }
        
        # ì•„ì¹´ì´ë¹™ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        archive_script = self._generate_archive_script(archiving_plan)
        
        print("âœ… ì•„ì¹´ì´ë¹™ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ")
        print(f"ğŸ’¾ ì˜ˆìƒ ìŠ¤í† ë¦¬ì§€ ì ˆì•½: 60-80%")
        print(f"âš¡ ì¿¼ë¦¬ ì„±ëŠ¥ ê°œì„ : 30-50%")
        
        return {
            "archiving_plan": archiving_plan,
            "archive_script": archive_script
        }
    
    def _generate_archive_script(self, plan: Dict) -> str:
        """ì•„ì¹´ì´ë¹™ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        
        script = '''#!/usr/bin/env python3
"""
ìë™ ë°ì´í„° ì•„ì¹´ì´ë¹™ ìŠ¤í¬ë¦½íŠ¸
6ê°œì›” ì´ìƒ ëœ ë¹„í™œì„± ë°ì´í„°ë¥¼ ì•„ì¹´ì´ë¸Œ í…Œì´ë¸”ë¡œ ì´ë™
"""

from datetime import datetime, timedelta
from supabase_client import SupabaseHelper

def archive_old_properties():
    """ë¹„í™œì„± ë§¤ë¬¼ ì•„ì¹´ì´ë¹™"""
    helper = SupabaseHelper()
    cutoff_date = (datetime.now() - timedelta(days=180)).isoformat()
    
    # ì•„ì¹´ì´ë¹™ ëŒ€ìƒ ì¡°íšŒ
    old_properties = helper.client.table('properties')\
        .select('*')\
        .eq('is_active', False)\
        .lt('updated_at', cutoff_date)\
        .execute()
    
    if old_properties.data:
        # ì•„ì¹´ì´ë¸Œ í…Œì´ë¸”ë¡œ ì´ë™
        helper.client.table('archived_properties')\
            .insert(old_properties.data)\
            .execute()
        
        # ì›ë³¸ì—ì„œ ì‚­ì œ
        article_nos = [p['article_no'] for p in old_properties.data]
        for article_no in article_nos:
            helper.client.table('properties')\
                .delete()\
                .eq('article_no', article_no)\
                .execute()
        
        print(f"âœ… {len(old_properties.data)}ê°œ ë§¤ë¬¼ ì•„ì¹´ì´ë¹™ ì™„ë£Œ")

if __name__ == "__main__":
    archive_old_properties()
'''
        
        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        with open('data_archiving_script.py', 'w', encoding='utf-8') as f:
            f.write(script)
        
        return script

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ë¯¸ì‚¬ìš© í…Œì´ë¸” í™œìš© ìµœì í™”')
    parser.add_argument('--analyze', action='store_true', help='í…Œì´ë¸” í™œìš©ë„ ë¶„ì„')
    parser.add_argument('--optimize-areas', action='store_true', help='areas í…Œì´ë¸” ìµœì í™”')
    parser.add_argument('--propose-tables', action='store_true', help='ìƒˆë¡œìš´ í…Œì´ë¸” ì œì•ˆ')
    parser.add_argument('--setup-archiving', action='store_true', help='ì•„ì¹´ì´ë¹™ ì‹œìŠ¤í…œ ì„¤ê³„')
    parser.add_argument('--all', action='store_true', help='ëª¨ë“  ìµœì í™” ì‹¤í–‰')
    
    args = parser.parse_args()
    
    optimizer = UnusedTablesOptimizer()
    
    print("ğŸ”§ ë¯¸ì‚¬ìš© í…Œì´ë¸” í™œìš© ìµœì í™” ì‹œìŠ¤í…œ v1.0")
    print("=" * 60)
    
    if args.analyze or args.all:
        usage_report = optimizer.analyze_table_usage()
        
        # ê²°ê³¼ ì €ì¥
        with open('table_usage_report.json', 'w', encoding='utf-8') as f:
            json.dump(usage_report, f, ensure_ascii=False, indent=2)
        print("ğŸ“„ ë¶„ì„ ê²°ê³¼ ì €ì¥: table_usage_report.json")
    
    if args.optimize_areas or args.all:
        optimizer.setup_areas_table_optimization()
    
    if args.propose_tables or args.all:
        proposals = optimizer.create_analytics_tables_proposal()
        
        # ì œì•ˆì„œ ì €ì¥
        with open('new_tables_proposal.json', 'w', encoding='utf-8') as f:
            json.dump(proposals, f, ensure_ascii=False, indent=2)
        print("ğŸ“„ í…Œì´ë¸” ì œì•ˆì„œ ì €ì¥: new_tables_proposal.json")
    
    if args.setup_archiving or args.all:
        archiving_system = optimizer.setup_data_archiving_system()
        
        # ì•„ì¹´ì´ë¹™ ê³„íš ì €ì¥
        with open('data_archiving_plan.json', 'w', encoding='utf-8') as f:
            json.dump(archiving_system['archiving_plan'], f, ensure_ascii=False, indent=2)
        print("ğŸ“„ ì•„ì¹´ì´ë¹™ ê³„íš ì €ì¥: data_archiving_plan.json")
        print("ğŸ“„ ì•„ì¹´ì´ë¹™ ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: data_archiving_script.py")

if __name__ == "__main__":
    main()