#!/usr/bin/env python3
"""
ë°°ì¹˜ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬
ì™„ì „ì„± ìš°ì„  ê³„íšì— ë”°ë¼ ì‹œê°„ì°¨ë¥¼ ë‘ê³  ì•ˆì „í•˜ê²Œ ìˆ˜ì§‘
"""

import json
import time
import os
from datetime import datetime
from typing import Dict
from fixed_naver_collector import FixedNaverCollector

class BatchCollectionScheduler:
    def __init__(self, token: str, config_file: str = "gu_config.json", use_address_converter: bool = True):
        self.token = token
        self.collector = FixedNaverCollector(token, use_address_converter=use_address_converter)
        
        # ì„¤ì • ë¡œë“œ
        with open(config_file, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
    
    def execute_collection_plan(self, plan_file: str) -> Dict:
        """ìˆ˜ì§‘ ê³„íš íŒŒì¼ì„ ì½ì–´ì„œ ë°°ì¹˜ë³„ë¡œ ì‹¤í–‰"""
        print(f"ğŸ“‹ ìˆ˜ì§‘ ê³„íš ë¡œë“œ: {plan_file}")
        
        with open(plan_file, 'r', encoding='utf-8') as f:
            collection_plan = json.load(f)
        
        gu_name = collection_plan['gu_name']
        batches = collection_plan['collection_batches']
        
        print(f"ğŸš€ {gu_name} ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘!")
        print(f"ì´ {len(batches)}ê°œ ë°°ì¹˜ ì˜ˆì •")
        
        execution_results = {
            "gu_name": gu_name,
            "execution_start": datetime.now().isoformat(),
            "batch_results": {},
            "total_collected": 0,
            "total_errors": 0
        }
        
        # ë°°ì¹˜ë³„ ìˆœì°¨ ì‹¤í–‰
        for batch_name, batch_info in batches.items():
            print(f"\n{'='*60}")
            print(f"ğŸ“¦ {batch_name} ì‹¤í–‰ ì¤‘...")
            print(f"   ì„¤ëª…: {batch_info['description']}")
            print(f"   ëŒ€ìƒ ì§€ì—­: {batch_info['total_areas']}ê°œ")
            print(f"   ì˜ˆìƒ ë§¤ë¬¼: {batch_info['total_properties']}ê°œ")
            
            # ë¹ˆ ë°°ì¹˜ëŠ” ê±´ë„ˆë›°ê¸°
            if batch_info['total_areas'] == 0:
                print("â­ï¸ ë¹ˆ ë°°ì¹˜ - ê±´ë„ˆë›°ê¸°")
                execution_results['batch_results'][batch_name] = {
                    "start_time": datetime.now().isoformat(),
                    "total_areas": 0,
                    "processed_areas": 0,
                    "collected_properties": 0,
                    "error_count": 0,
                    "area_results": [],
                    "end_time": datetime.now().isoformat(),
                    "skipped": True
                }
                continue
            
            # ì§€ì—° ì‹œê°„ ì ìš© (ë¹ˆ ë°°ì¹˜ê°€ ì•„ë‹ ë•Œë§Œ)
            if 'delay_minutes' in batch_info and batch_info['delay_minutes'] > 0:
                delay_minutes = batch_info['delay_minutes']
                print(f"â° {delay_minutes}ë¶„ ëŒ€ê¸° ì¤‘...")
                time.sleep(delay_minutes * 60)
            
            # ë°°ì¹˜ ì‹¤í–‰
            batch_result = self._execute_single_batch(batch_info, gu_name)
            execution_results['batch_results'][batch_name] = batch_result
            
            # ê²°ê³¼ ëˆ„ì 
            execution_results['total_collected'] += batch_result['collected_properties']
            execution_results['total_errors'] += batch_result['error_count']
            
            print(f"âœ… {batch_name} ì™„ë£Œ: {batch_result['collected_properties']}ê°œ ë§¤ë¬¼ ìˆ˜ì§‘")
            
            # ë°°ì¹˜ ê°„ íœ´ì‹ (ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ì•„ë‹Œ ê²½ìš°)
            batch_list = list(batches.keys())
            if batch_name != batch_list[-1]:
                rest_minutes = self.config['global_settings']['batch_rest_minutes']
                print(f"ğŸ˜´ ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ {rest_minutes}ë¶„ íœ´ì‹...")
                time.sleep(rest_minutes * 60)
        
        execution_results['execution_end'] = datetime.now().isoformat()
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        self._save_execution_results(execution_results)
        
        print(f"\nğŸ‰ {gu_name} ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ì´ ìˆ˜ì§‘ ë§¤ë¬¼: {execution_results['total_collected']}ê°œ")
        print(f"ì´ ì˜¤ë¥˜ ìˆ˜: {execution_results['total_errors']}ê°œ")
        
        return execution_results
    
    def _execute_single_batch(self, batch_info: Dict, gu_name: str) -> Dict:
        """ë‹¨ì¼ ë°°ì¹˜ ì‹¤í–‰"""
        areas = batch_info['areas']
        batch_result = {
            "start_time": datetime.now().isoformat(),
            "total_areas": len(areas),
            "processed_areas": 0,
            "collected_properties": 0,
            "error_count": 0,
            "area_results": []
        }
        
        for i, area in enumerate(areas):
            cortar_no = area['cortar_no']
            expected_count = area['property_count']
            
            print(f"   ğŸ”„ ì§€ì—­ {i+1}/{len(areas)}: {cortar_no} (ì˜ˆìƒ: {expected_count}ê°œ)")
            
            try:
                # ê°œë³„ ì§€ì—­ ìˆ˜ì§‘
                area_result = self._collect_single_area(cortar_no, gu_name)
                
                batch_result['area_results'].append({
                    "cortar_no": cortar_no,
                    "expected_properties": expected_count,
                    "actual_collected": area_result['collected_count'],
                    "success": area_result['success'],
                    "collection_time": area_result['collection_time'],
                    "output_file": area_result.get('output_file')
                })
                
                if area_result['success']:
                    batch_result['collected_properties'] += area_result['collected_count']
                else:
                    batch_result['error_count'] += 1
                
                batch_result['processed_areas'] += 1
                
                # ì§€ì—­ ê°„ ë”œë ˆì´
                delay = self.config['global_settings']['collection_delay_seconds']
                time.sleep(delay)
                
            except Exception as e:
                print(f"   âŒ ì§€ì—­ {cortar_no} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                batch_result['error_count'] += 1
                
                batch_result['area_results'].append({
                    "cortar_no": cortar_no,
                    "expected_properties": expected_count,
                    "actual_collected": 0,
                    "success": False,
                    "error": str(e),
                    "collection_time": 0
                })
        
        batch_result['end_time'] = datetime.now().isoformat()
        return batch_result
    
    def _collect_single_area(self, cortar_no: str, gu_name: str) -> Dict:
        """ê°œë³„ ì§€ì—­ ìˆ˜ì§‘ (ê¸°ì¡´ collector í™œìš©)"""
        start_time = time.time()
        
        try:
            # ì„ì‹œ URL ìƒì„± (cortar ê¸°ë°˜)
            temp_url = self._create_temp_url_for_cortar(cortar_no)
            
            # ìˆ˜ì§‘ ì‹¤í–‰ (ê²°ê³¼ í´ë”ì— ì €ì¥)
            results_dir = os.path.join(os.path.dirname(__file__), 'results')
            os.makedirs(results_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"area_{gu_name}_{cortar_no}_{timestamp}.json"
            output_filepath = os.path.join(results_dir, output_filename)
            
            with open(output_filepath, 'w', encoding='utf-8') as f:
                # ë©”íƒ€ë°ì´í„° ì‘ì„±
                metadata = {
                    "ìˆ˜ì§‘ì •ë³´": {
                        "ìˆ˜ì§‘ì‹œê°„": timestamp,
                        "êµ¬ì´ë¦„": gu_name,
                        "ì§€ì—­ì½”ë“œ": cortar_no,
                        "ìˆ˜ì§‘ë°©ì‹": "ë°°ì¹˜_ì™„ì „ì„±_ìš°ì„ "
                    }
                }
                json.dump(metadata, f, ensure_ascii=False, indent=2)
                f.write(',\n')
                
                # ìˆ˜ì§‘ ì‹¤í–‰
                collected_count = self.collector.collect_articles(
                    cortar_no=cortar_no,
                    parsed_url={"cortar_based": True},
                    max_pages=21,
                    include_details=True,
                    output_file=f
                )
            
            collection_time = time.time() - start_time
            
            return {
                "success": True,
                "collected_count": collected_count,
                "collection_time": collection_time,
                "output_file": output_filepath
            }
            
        except Exception as e:
            collection_time = time.time() - start_time
            return {
                "success": False,
                "collected_count": 0,
                "collection_time": collection_time,
                "error": str(e)
            }
    
    def _create_temp_url_for_cortar(self, cortar_no: str) -> str:
        """cortar ê¸°ë°˜ ì„ì‹œ URL ìƒì„±"""
        # ì‹¤ì œë¡œëŠ” cortar_noë¡œ ì§ì ‘ ìˆ˜ì§‘í•˜ë¯€ë¡œ URLì€ ì°¸ê³ ìš©
        return f"https://new.land.naver.com/offices?cortarNo={cortar_no}"
    
    def _save_execution_results(self, results: Dict):
        """ì‹¤í–‰ ê²°ê³¼ ì €ì¥"""
        results_dir = os.path.join(os.path.dirname(__file__), 'results')
        os.makedirs(results_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        gu_name = results['gu_name']
        filename = f"batch_execution_result_{gu_name}_{timestamp}.json"
        filepath = os.path.join(results_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì‹¤í–‰ ê²°ê³¼ ì €ì¥: {filepath}")
    
    def create_collection_summary(self, execution_results: Dict) -> Dict:
        """ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        gu_name = execution_results['gu_name']
        batch_results = execution_results['batch_results']
        
        summary = {
            "gu_name": gu_name,
            "execution_summary": {
                "total_collected_properties": execution_results['total_collected'],
                "total_processed_areas": sum(batch['processed_areas'] for batch in batch_results.values()),
                "total_errors": execution_results['total_errors'],
                "success_rate": 0,
                "execution_duration": None
            },
            "batch_summary": {},
            "top_productive_areas": [],
            "problematic_areas": []
        }
        
        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        start_time = datetime.fromisoformat(execution_results['execution_start'])
        end_time = datetime.fromisoformat(execution_results['execution_end'])
        duration = end_time - start_time
        summary['execution_summary']['execution_duration'] = str(duration)
        
        # ì„±ê³µë¥  ê³„ì‚°
        total_areas = sum(batch['total_areas'] for batch in batch_results.values())
        if total_areas > 0:
            successful_areas = total_areas - execution_results['total_errors']
            summary['execution_summary']['success_rate'] = successful_areas / total_areas
        
        # ë°°ì¹˜ë³„ ìš”ì•½
        for batch_name, batch_result in batch_results.items():
            summary['batch_summary'][batch_name] = {
                "processed_areas": batch_result['processed_areas'],
                "collected_properties": batch_result['collected_properties'],
                "error_count": batch_result['error_count'],
                "avg_properties_per_area": (
                    batch_result['collected_properties'] / batch_result['processed_areas']
                    if batch_result['processed_areas'] > 0 else 0
                )
            }
        
        # ìƒì‚°ì„± ë†’ì€ ì§€ì—­ TOP 10
        all_area_results = []
        for batch_result in batch_results.values():
            all_area_results.extend(batch_result['area_results'])
        
        productive_areas = sorted(
            [area for area in all_area_results if area['success']],
            key=lambda x: x['actual_collected'],
            reverse=True
        )[:10]
        
        summary['top_productive_areas'] = productive_areas
        
        # ë¬¸ì œ ì§€ì—­ë“¤
        problematic_areas = [area for area in all_area_results if not area['success']]
        summary['problematic_areas'] = problematic_areas
        
        return summary

def main():
    """ë°°ì¹˜ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python batch_collection_scheduler.py <ìˆ˜ì§‘ê³„íšíŒŒì¼> [í† í°]")
        print("ì˜ˆì‹œ: python batch_collection_scheduler.py collection_plan_ê°•ë‚¨êµ¬_20250804_143000.json")
        return
    
    plan_file = sys.argv[1]
    
    # í† í° ìˆ˜ì§‘
    if len(sys.argv) >= 3:
        token = sys.argv[2]
    else:
        from playwright_token_collector import PlaywrightTokenCollector
        print("ğŸ”‘ í† í° ìˆ˜ì§‘ ì¤‘...")
        token_collector = PlaywrightTokenCollector()
        token = token_collector.get_token_with_playwright()
        
        if not token:
            print("âŒ í† í° íšë“ ì‹¤íŒ¨")
            return
    
    # ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤í–‰
    scheduler = BatchCollectionScheduler(token)
    
    try:
        execution_results = scheduler.execute_collection_plan(plan_file)
        
        # ìš”ì•½ ìƒì„±
        summary = scheduler.create_collection_summary(execution_results)
        
        print("\nğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ ìš”ì•½:")
        print(f"   ì„±ê³µë¥ : {summary['execution_summary']['success_rate']:.1%}")
        print(f"   ì‹¤í–‰ ì‹œê°„: {summary['execution_summary']['execution_duration']}")
        print(f"   ì´ ë§¤ë¬¼: {summary['execution_summary']['total_collected_properties']}ê°œ")
        
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()