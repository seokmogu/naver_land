#!/usr/bin/env python3
"""
ì„±ëŠ¥ ìµœì í™”ëœ Supabase í´ë¼ì´ì–¸íŠ¸
- ì§ì ‘ DB ì €ì¥ ì§€ì›
- ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ìµœì í™”  
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
- íŠ¸ëœì­ì…˜ ê´€ë¦¬ ê°•í™”
"""

import os
import json
import time
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional, Any, Generator, Tuple
from dataclasses import dataclass
from contextlib import contextmanager
from supabase import create_client, Client

@dataclass
class BatchResult:
    """ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼"""
    success: bool = False
    processed: int = 0
    inserted: int = 0
    updated: int = 0
    errors: int = 0
    processing_time: float = 0.0
    error_details: List[str] = None

    def __post_init__(self):
        if self.error_details is None:
            self.error_details = []

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ"""
    total_operations: int = 0
    successful_operations: int = 0
    failed_operations: int = 0
    total_processing_time: float = 0.0
    average_batch_time: float = 0.0
    records_per_second: float = 0.0
    memory_usage_mb: float = 0.0

class EnhancedSupabaseClient:
    """ì„±ëŠ¥ ìµœì í™”ëœ Supabase í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, config_file: str = "config.json", batch_size: int = 50):
        """
        í–¥ìƒëœ Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            config_file: ì„¤ì • íŒŒì¼ ê²½ë¡œ
            batch_size: ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
        """
        self.batch_size = batch_size
        self.client = self._initialize_client(config_file)
        self.performance_metrics = PerformanceMetrics()
        
        # ì—°ê²° í’€ë§ ì„¤ì •
        self._connection_pool_size = 10
        self._connection_timeout = 30
        
        print(f"âœ… ì„±ëŠ¥ ìµœì í™”ëœ Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ë°°ì¹˜ í¬ê¸°: {batch_size})")
    
    def _initialize_client(self, config_file: str) -> Client:
        """Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # ì„¤ì • íŒŒì¼ ë¡œë“œ
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            supabase_config = config.get('supabase', {})
            
            # í™˜ê²½ë³€ìˆ˜ ìš°ì„ , ì„¤ì • íŒŒì¼ ì°¨ìˆœìœ„
            url = os.getenv('SUPABASE_URL', supabase_config.get('url'))
            key = os.getenv('SUPABASE_KEY', supabase_config.get('anon_key'))
            
            if not url or not key:
                raise ValueError("Supabase URLê³¼ Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
            return create_client(url, key)
            
        except Exception as e:
            print(f"âŒ Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    @contextmanager
    def performance_tracking(self, operation_name: str):
        """ì„±ëŠ¥ ì¶”ì  ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        start_time = time.time()
        start_memory = self._get_memory_usage()
        
        try:
            yield
            self.performance_metrics.successful_operations += 1
        except Exception as e:
            self.performance_metrics.failed_operations += 1
            raise
        finally:
            end_time = time.time()
            end_memory = self._get_memory_usage()
            
            processing_time = end_time - start_time
            memory_delta = end_memory - start_memory
            
            self.performance_metrics.total_operations += 1
            self.performance_metrics.total_processing_time += processing_time
            self.performance_metrics.memory_usage_mb = max(
                self.performance_metrics.memory_usage_mb, 
                end_memory
            )
            
            print(f"â±ï¸ {operation_name}: {processing_time:.2f}ì´ˆ, ë©”ëª¨ë¦¬: +{memory_delta:.1f}MB")
    
    def stream_save_properties(
        self, 
        property_generator: Generator[Dict, None, None], 
        cortar_no: str,
        region_name: str = ""
    ) -> Dict:
        """
        ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë§¤ë¬¼ ë°ì´í„°ë¥¼ ì§ì ‘ DBì— ì €ì¥
        
        Args:
            property_generator: ë§¤ë¬¼ ë°ì´í„° ì œë„ˆë ˆì´í„°
            cortar_no: í–‰ì •êµ¬ì—­ ì½”ë“œ
            region_name: ì§€ì—­ëª… (ë¡œê¹…ìš©)
            
        Returns:
            Dict: ì „ì²´ ì €ì¥ ê²°ê³¼
        """
        
        print(f"\nğŸš€ ìŠ¤íŠ¸ë¦¬ë° ì§ì ‘ ì €ì¥ ì‹œì‘: {region_name} ({cortar_no})")
        
        with self.performance_tracking("ìŠ¤íŠ¸ë¦¬ë° ì €ì¥"):
            batch_buffer = []
            batch_count = 0
            total_stats = {
                'total_processed': 0,
                'total_inserted': 0,
                'total_updated': 0,
                'total_errors': 0,
                'batch_results': []
            }
            
            try:
                for property_data in property_generator:
                    batch_buffer.append(property_data)
                    
                    # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì €ì¥
                    if len(batch_buffer) >= self.batch_size:
                        batch_count += 1
                        batch_result = self._process_batch(batch_buffer, cortar_no, batch_count)
                        
                        # í†µê³„ ì—…ë°ì´íŠ¸
                        total_stats['total_processed'] += batch_result.processed
                        total_stats['total_inserted'] += batch_result.inserted
                        total_stats['total_updated'] += batch_result.updated
                        total_stats['total_errors'] += batch_result.errors
                        total_stats['batch_results'].append(batch_result)
                        
                        # ë°°ì¹˜ ë²„í¼ ì´ˆê¸°í™”
                        batch_buffer.clear()
                        
                        # ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ì ê¹ ëŒ€ê¸°
                        if batch_count % 10 == 0:
                            self._memory_cleanup()
                        
                        time.sleep(0.1)  # API ì œí•œ ì¤€ìˆ˜
                
                # ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
                if batch_buffer:
                    batch_count += 1
                    batch_result = self._process_batch(batch_buffer, cortar_no, batch_count)
                    
                    total_stats['total_processed'] += batch_result.processed
                    total_stats['total_inserted'] += batch_result.inserted
                    total_stats['total_updated'] += batch_result.updated
                    total_stats['total_errors'] += batch_result.errors
                    total_stats['batch_results'].append(batch_result)
                
                # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
                if total_stats['total_processed'] > 0:
                    self.performance_metrics.records_per_second = (
                        total_stats['total_processed'] / 
                        self.performance_metrics.total_processing_time
                    )
                
                print(f"âœ… ìŠ¤íŠ¸ë¦¬ë° ì €ì¥ ì™„ë£Œ!")
                print(f"   ì´ ë°°ì¹˜: {batch_count}ê°œ")
                print(f"   ì²˜ë¦¬: {total_stats['total_processed']:,}ê°œ")
                print(f"   ì‹ ê·œ: {total_stats['total_inserted']:,}ê°œ")
                print(f"   ì—…ë°ì´íŠ¸: {total_stats['total_updated']:,}ê°œ")
                print(f"   ì˜¤ë¥˜: {total_stats['total_errors']:,}ê°œ")
                print(f"   ì²˜ë¦¬ ì†ë„: {self.performance_metrics.records_per_second:.1f} ë ˆì½”ë“œ/ì´ˆ")
                
                return {
                    'success': True,
                    'region_name': region_name,
                    'cortar_no': cortar_no,
                    'batch_count': batch_count,
                    'stats': total_stats,
                    'performance': self._get_performance_summary()
                }
                
            except Exception as e:
                print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì €ì¥ ì˜¤ë¥˜: {e}")
                return {
                    'success': False,
                    'error': str(e),
                    'stats': total_stats,
                    'performance': self._get_performance_summary()
                }
    
    def _process_batch(self, batch_data: List[Dict], cortar_no: str, batch_num: int) -> BatchResult:
        """
        ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬
        
        Args:
            batch_data: ë°°ì¹˜ ë°ì´í„°
            cortar_no: í–‰ì •êµ¬ì—­ ì½”ë“œ
            batch_num: ë°°ì¹˜ ë²ˆí˜¸
            
        Returns:
            BatchResult: ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
        """
        
        start_time = time.time()
        result = BatchResult()
        
        print(f"   ğŸ“¦ ë°°ì¹˜ {batch_num}: {len(batch_data)}ê°œ ì²˜ë¦¬ ì¤‘...")
        
        try:
            # 1. ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ë° ì „ì²˜ë¦¬
            valid_data = []
            for item in batch_data:
                if self._validate_property_data(item):
                    # í•„ìˆ˜ í•„ë“œ ë³´ê°•
                    item = self._enrich_property_data(item, cortar_no)
                    valid_data.append(item)
                else:
                    result.errors += 1
                    result.error_details.append(f"ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨: {item.get('article_no', 'Unknown')}")
            
            if not valid_data:
                result.processing_time = time.time() - start_time
                return result
            
            # 2. ê¸°ì¡´ ë°ì´í„°ì™€ì˜ ì¤‘ë³µ ì²´í¬ ë° ì—…ë°ì´íŠ¸ ì²˜ë¦¬
            existing_properties = self._get_existing_properties(
                [item['article_no'] for item in valid_data], 
                cortar_no
            )
            
            insert_data = []
            update_data = []
            
            for item in valid_data:
                article_no = item['article_no']
                existing = existing_properties.get(article_no)
                
                if existing:
                    # ê¸°ì¡´ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ ì—…ë°ì´íŠ¸ í•„ìš” ì—¬ë¶€ í™•ì¸
                    if self._needs_update(existing, item):
                        item['updated_at'] = datetime.now().isoformat()
                        update_data.append(item)
                    # ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš”í•œ ê²½ìš° last_seen_dateë§Œ ê°±ì‹ 
                    else:
                        self._update_last_seen_date(article_no)
                else:
                    insert_data.append(item)
            
            # 3. ë°°ì¹˜ INSERT
            if insert_data:
                insert_result = self.client.table('properties').upsert(
                    insert_data, 
                    on_conflict='article_no'
                ).execute()
                
                result.inserted = len(insert_data)
                print(f"      âœ… ì‹ ê·œ ì €ì¥: {result.inserted}ê°œ")
            
            # 4. ë°°ì¹˜ UPDATE
            if update_data:
                # ê°œë³„ ì—…ë°ì´íŠ¸ (Supabase ë°°ì¹˜ ì—…ë°ì´íŠ¸ í•œê³„ë¡œ ì¸í•´)
                updated_count = 0
                for item in update_data:
                    try:
                        self.client.table('properties')\
                            .update(item)\
                            .eq('article_no', item['article_no'])\
                            .execute()
                        updated_count += 1
                    except Exception as e:
                        result.errors += 1
                        result.error_details.append(f"ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({item['article_no']}): {e}")
                
                result.updated = updated_count
                print(f"      ğŸ“ ì—…ë°ì´íŠ¸: {result.updated}ê°œ")
            
            result.processed = len(valid_data)
            result.success = True
            
        except Exception as e:
            print(f"      âŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            result.errors += len(batch_data)
            result.error_details.append(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        result.processing_time = time.time() - start_time
        return result
    
    def _validate_property_data(self, data: Dict) -> bool:
        """ë§¤ë¬¼ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
        required_fields = ['article_no', 'cortar_no']
        return all(data.get(field) for field in required_fields)
    
    def _enrich_property_data(self, data: Dict, cortar_no: str) -> Dict:
        """ë§¤ë¬¼ ë°ì´í„° ë³´ê°•"""
        now = datetime.now()
        today = date.today()
        
        # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’ ì„¤ì •
        data.setdefault('cortar_no', cortar_no)
        data.setdefault('collected_date', today.isoformat())
        data.setdefault('last_seen_date', today.isoformat())
        data.setdefault('is_active', True)
        data.setdefault('created_at', now.isoformat())
        data.setdefault('updated_at', now.isoformat())
        
        # ê°€ê²© ë°ì´í„° ì •ê·œí™”
        data['price'] = self._normalize_price(data.get('price', 0))
        data['rent_price'] = self._normalize_price(data.get('rent_price', 0))
        
        return data
    
    def _get_existing_properties(self, article_nos: List[str], cortar_no: str) -> Dict:
        """ê¸°ì¡´ ë§¤ë¬¼ ì¡°íšŒ"""
        try:
            if not article_nos:
                return {}
            
            # ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì¡°íšŒ (IN ì ˆ í•œê³„ ê³ ë ¤)
            existing_map = {}
            batch_size = 100
            
            for i in range(0, len(article_nos), batch_size):
                batch_ids = article_nos[i:i+batch_size]
                
                result = self.client.table('properties')\
                    .select('article_no, price, rent_price, trade_type, updated_at')\
                    .in_('article_no', batch_ids)\
                    .eq('cortar_no', cortar_no)\
                    .eq('is_active', True)\
                    .execute()
                
                for item in result.data:
                    existing_map[item['article_no']] = item
            
            return existing_map
            
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ ë§¤ë¬¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def _needs_update(self, existing: Dict, new_data: Dict) -> bool:
        """ì—…ë°ì´íŠ¸ í•„ìš” ì—¬ë¶€ í™•ì¸"""
        
        # ê°€ê²© ë³€ë™ ì²´í¬
        if existing.get('price') != new_data.get('price'):
            return True
        
        if existing.get('rent_price') != new_data.get('rent_price'):
            return True
        
        # ê¸°íƒ€ ì£¼ìš” í•„ë“œ ë³€ë™ ì²´í¬
        check_fields = ['trade_type', 'floor_info', 'direction']
        for field in check_fields:
            if existing.get(field) != new_data.get(field):
                return True
        
        return False
    
    def _update_last_seen_date(self, article_no: str):
        """ë§ˆì§€ë§‰ ë°œê²¬ ë‚ ì§œë§Œ ì—…ë°ì´íŠ¸"""
        try:
            self.client.table('properties')\
                .update({
                    'last_seen_date': date.today().isoformat(),
                    'updated_at': datetime.now().isoformat()
                })\
                .eq('article_no', article_no)\
                .execute()
        except Exception as e:
            print(f"âš ï¸ last_seen_date ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({article_no}): {e}")
    
    def _normalize_price(self, price_value: Any) -> int:
        """ê°€ê²© ë°ì´í„° ì •ê·œí™”"""
        if isinstance(price_value, (int, float)):
            return int(price_value)
        
        if isinstance(price_value, str):
            # "5ì–µ 3,000ë§Œ" í˜•ì‹ ì²˜ë¦¬
            price_str = price_value.replace(',', '').replace('ì–µ', '0000').replace('ë§Œ', '')
            try:
                return int(price_str)
            except:
                return 0
        
        return 0
    
    def _get_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ (MB)"""
        try:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
        except ImportError:
            return 0.0
    
    def _memory_cleanup(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        import gc
        gc.collect()
        print("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
    
    def _get_performance_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        return {
            'total_operations': self.performance_metrics.total_operations,
            'successful_operations': self.performance_metrics.successful_operations,
            'failed_operations': self.performance_metrics.failed_operations,
            'success_rate': (
                self.performance_metrics.successful_operations / 
                max(self.performance_metrics.total_operations, 1) * 100
            ),
            'total_processing_time': self.performance_metrics.total_processing_time,
            'records_per_second': self.performance_metrics.records_per_second,
            'memory_usage_mb': self.performance_metrics.memory_usage_mb
        }
    
    def get_region_statistics(self, cortar_no: str) -> Dict:
        """ì§€ì—­ë³„ í†µê³„ ì¡°íšŒ"""
        try:
            with self.performance_tracking("ì§€ì—­ í†µê³„ ì¡°íšŒ"):
                # í™œì„± ë§¤ë¬¼ ìˆ˜
                active_count = self.client.table('properties')\
                    .select('id', count='exact')\
                    .eq('cortar_no', cortar_no)\
                    .eq('is_active', True)\
                    .execute()
                
                # ê°€ê²© í†µê³„
                price_stats = self.client.table('properties')\
                    .select('price, rent_price, trade_type')\
                    .eq('cortar_no', cortar_no)\
                    .eq('is_active', True)\
                    .execute()
                
                prices = [item['price'] for item in price_stats.data if item['price']]
                
                statistics = {
                    'cortar_no': cortar_no,
                    'active_properties': active_count.count or 0,
                    'avg_price': sum(prices) / len(prices) if prices else 0,
                    'min_price': min(prices) if prices else 0,
                    'max_price': max(prices) if prices else 0,
                    'trade_type_distribution': self._calculate_trade_type_distribution(price_stats.data),
                    'last_updated': datetime.now().isoformat()
                }
                
                return statistics
                
        except Exception as e:
            print(f"âŒ ì§€ì—­ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _calculate_trade_type_distribution(self, data: List[Dict]) -> Dict:
        """ê±°ë˜ íƒ€ì…ë³„ ë¶„í¬ ê³„ì‚°"""
        distribution = {}
        for item in data:
            trade_type = item.get('trade_type', 'ê¸°íƒ€')
            distribution[trade_type] = distribution.get(trade_type, 0) + 1
        return distribution

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_enhanced_client():
    """ì„±ëŠ¥ ìµœì í™”ëœ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ§ª ì„±ëŠ¥ ìµœì í™”ëœ Supabase í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        client = EnhancedSupabaseClient(batch_size=25)
        
        # ì§€ì—­ í†µê³„ ì¡°íšŒ í…ŒìŠ¤íŠ¸
        test_cortar_no = "1168010100"
        stats = client.get_region_statistics(test_cortar_no)
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"   ì§€ì—­ í†µê³„: {stats}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    test_enhanced_client()