# ë„¤ì´ë²„ ë¶€ë™ì‚° ìˆ˜ì§‘ê¸° API ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“– ê°œìš”

ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìˆ˜ì§‘ê¸°ì˜ ì™„ì „í•œ API ì‚¬ìš©ë²•, ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ, ê·¸ë¦¬ê³  ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ìƒì„¸ ë¬¸ì„œì…ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ê¸°ì¡´ ë°©ì‹ (JSON â†’ DB)

```python
from unified_collector import UnifiedCollector

# í†µí•© ìˆ˜ì§‘ê¸° (JSON íŒŒì¼ ê²½ìœ )
collector = UnifiedCollector()

# ì§€ì—­ ìˆ˜ì§‘ ë° ì €ì¥
result = collector.collect_and_save("1168010100", "ì—­ì‚¼ë™")

if result['success']:
    print(f"ìˆ˜ì§‘ ì™„ë£Œ: {result['collected_properties']}ê°œ")
else:
    print(f"ì˜¤ë¥˜: {result['error']}")
```

### 2. ìƒˆë¡œìš´ ìµœì í™” ë°©ì‹ (Direct DB)

```python
from optimized_direct_collector import OptimizedDirectCollector

# ìµœì í™”ëœ ì§ì ‘ ìˆ˜ì§‘ê¸°
collector = OptimizedDirectCollector(batch_size=50)

# ì§ì ‘ DB ì €ì¥ ìˆ˜ì§‘
result = collector.collect_region_direct("1168010100", "ì—­ì‚¼ë™")

if result['success']:
    stats = result['collection_stats']
    print(f"ì²˜ë¦¬ ì‹œê°„: {result['session_info']['processing_time']:.1f}ì´ˆ")
    print(f"ìˆ˜ì§‘: {stats['collected_properties']:,}ê°œ")
    print(f"ì‹ ê·œ: {stats['new_properties']:,}ê°œ")
    print(f"ì—…ë°ì´íŠ¸: {stats['updated_properties']:,}ê°œ")
```

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### ì²˜ë¦¬ ë°©ì‹ ë¹„êµ

| ë°©ì‹ | ë‹¨ê³„ | ë©”ëª¨ë¦¬ ì‚¬ìš© | ì²˜ë¦¬ ì‹œê°„ | I/O ì‘ì—… |
|------|------|------------|-----------|----------|
| **ê¸°ì¡´ (JSON)** | ìˆ˜ì§‘ â†’ JSON ì €ì¥ â†’ íŒŒì¼ ë¡œë“œ â†’ DB ì €ì¥ | ë†’ìŒ | ê¸´ ì‹œê°„ | ë§ìŒ |
| **ìƒˆë¡œìš´ (Direct)** | ìˆ˜ì§‘ â†’ ì‹¤ì‹œê°„ ë³€í™˜ â†’ ìŠ¤íŠ¸ë¦¬ë° DB ì €ì¥ | ë‚®ìŒ | ì§§ì€ ì‹œê°„ | ì ìŒ |

### ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

- **ì²˜ë¦¬ ì‹œê°„**: 50-60% ë‹¨ì¶•
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: 30-40% ê°ì†Œ
- **I/O ì‘ì—…**: 40-50% ê°ì†Œ
- **ë””ìŠ¤í¬ ê³µê°„**: JSON íŒŒì¼ ë¶ˆí•„ìš”

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë¹„êµ

### ê¸°ì¡´ ì•„í‚¤í…ì²˜
```
[ë„¤ì´ë²„ API] â†’ [JSON íŒŒì¼] â†’ [íŒŒì¼ ë¡œë“œ] â†’ [ë³€í™˜] â†’ [DB ì €ì¥]
    â†“              â†“            â†“          â†“         â†“
  í† í° ê´€ë¦¬     ë””ìŠ¤í¬ I/O    ë©”ëª¨ë¦¬ ë¡œë“œ   CPU ì§‘ì•½   DB I/O
```

### ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜  
```
[ë„¤ì´ë²„ API] â†’ [ìŠ¤íŠ¸ë¦¬ë° ë³€í™˜] â†’ [ë°°ì¹˜ DB ì €ì¥]
    â†“              â†“                â†“
  í† í° ì¬ì‚¬ìš©    ì‹¤ì‹œê°„ ì²˜ë¦¬      ìµœì í™”ëœ ë°°ì¹˜
```

## ğŸ”§ í´ë˜ìŠ¤ë³„ ìƒì„¸ API

### 1. OptimizedDirectCollector

**ì´ˆê¸°í™”**:
```python
collector = OptimizedDirectCollector(
    batch_size=50,                    # ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 50)
    use_address_converter=True        # ì£¼ì†Œ ë³€í™˜ ì‚¬ìš© (ê¸°ë³¸: True)
)
```

**ì£¼ìš” ë©”ì†Œë“œ**:

#### `collect_region_direct(cortar_no, region_name="")`
ì§€ì—­ ë§¤ë¬¼ì„ ì§ì ‘ DBì— ì €ì¥í•˜ë©´ì„œ ìˆ˜ì§‘

**ë§¤ê°œë³€ìˆ˜**:
- `cortar_no` (str): í–‰ì •êµ¬ì—­ ì½”ë“œ (ì˜ˆ: "1168010100")
- `region_name` (str): ì§€ì—­ëª… (ë¡œê¹…ìš©)

**ë°˜í™˜ê°’**:
```python
{
    'success': bool,
    'region_name': str,
    'cortar_no': str,
    'session_info': {
        'start_time': str,          # ISO í˜•ì‹
        'end_time': str,
        'processing_time': float,   # ì´ˆ ë‹¨ìœ„
        'total_pages': int,
        'total_properties': int
    },
    'collection_stats': {
        'existing_properties': int,
        'collected_properties': int,
        'final_properties': int,
        'new_properties': int,
        'updated_properties': int,
        'failed_properties': int
    },
    'performance': {
        'records_per_second': float,
        'memory_usage_mb': float,
        'success_rate': float
    },
    'batch_count': int
}
```

### 2. EnhancedSupabaseClient

**ì´ˆê¸°í™”**:
```python
from enhanced_supabase_client import EnhancedSupabaseClient

client = EnhancedSupabaseClient(
    config_file="config.json",        # ì„¤ì • íŒŒì¼ (ê¸°ë³¸)
    batch_size=50                     # ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 50)
)
```

**ì£¼ìš” ë©”ì†Œë“œ**:

#### `stream_save_properties(property_generator, cortar_no, region_name="")`
ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë§¤ë¬¼ ë°ì´í„°ë¥¼ ì§ì ‘ DBì— ì €ì¥

**ë§¤ê°œë³€ìˆ˜**:
- `property_generator`: ë§¤ë¬¼ ë°ì´í„° ì œë„ˆë ˆì´í„°
- `cortar_no` (str): í–‰ì •êµ¬ì—­ ì½”ë“œ
- `region_name` (str): ì§€ì—­ëª…

#### `get_region_statistics(cortar_no)`
ì§€ì—­ë³„ í†µê³„ ì¡°íšŒ

**ë°˜í™˜ê°’**:
```python
{
    'cortar_no': str,
    'active_properties': int,
    'avg_price': float,
    'min_price': int,
    'max_price': int,
    'trade_type_distribution': dict,
    'last_updated': str
}
```

## ğŸ“‹ ì„¤ì • íŒŒì¼ (config.json)

```json
{
    "supabase": {
        "url": "https://your-project.supabase.co",
        "anon_key": "your-anon-key"
    },
    "kakao": {
        "api_key": "your-kakao-api-key"
    },
    "collection": {
        "batch_size": 50,
        "retry_count": 3,
        "timeout": 30
    }
}
```

## âš™ï¸ ì„±ëŠ¥ íŠœë‹ ê°€ì´ë“œ

### 1. ë°°ì¹˜ í¬ê¸° ìµœì í™”

```python
# ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•œ ê²½ìš° (ê¶Œì¥)
collector = OptimizedDirectCollector(batch_size=100)

# ë©”ëª¨ë¦¬ê°€ ì œí•œì ì¸ ê²½ìš°
collector = OptimizedDirectCollector(batch_size=25)

# ë„¤íŠ¸ì›Œí¬ê°€ ëŠë¦° ê²½ìš°
collector = OptimizedDirectCollector(batch_size=20)
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

**ì¸ë±ìŠ¤ í™•ì¸**:
```sql
-- ì£¼ìš” ì¸ë±ìŠ¤ë“¤
CREATE INDEX IF NOT EXISTS idx_properties_article_no ON properties(article_no);
CREATE INDEX IF NOT EXISTS idx_properties_cortar_active ON properties(cortar_no, is_active);
CREATE INDEX IF NOT EXISTS idx_properties_last_seen ON properties(last_seen_date);
```

**ì—°ê²° í’€ë§ ì„¤ì •**:
```python
# Supabase í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìë™ ê´€ë¦¬
# ë³„ë„ ì„¤ì • ë¶ˆí•„ìš”
```

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
import gc

# ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬ (ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨)
# 10ê°œ ë°°ì¹˜ë§ˆë‹¤ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
if batch_count % 10 == 0:
    gc.collect()
```

## ğŸ” ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 1. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì 

```python
# ìˆ˜ì§‘ ì™„ë£Œ í›„ ì„±ëŠ¥ í™•ì¸
result = collector.collect_region_direct("1168010100", "ì—­ì‚¼ë™")

performance = result['performance']
print(f"ì²˜ë¦¬ ì†ë„: {performance['records_per_second']:.1f} ë ˆì½”ë“œ/ì´ˆ")
print(f"ì„±ê³µë¥ : {performance['success_rate']:.1f}%")
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©: {performance['memory_usage_mb']:.1f}MB")
```

### 2. ë¡œê·¸ ë ˆë²¨ ì„¤ì •

```python
import logging

# ë””ë²„ê¹…ìš© ìƒì„¸ ë¡œê·¸
logging.basicConfig(level=logging.DEBUG)

# ìš´ì˜ìš© ê¸°ë³¸ ë¡œê·¸
logging.basicConfig(level=logging.INFO)
```

### 3. ì—ëŸ¬ ì²˜ë¦¬ íŒ¨í„´

```python
try:
    result = collector.collect_region_direct("1168010100", "ì—­ì‚¼ë™")
    
    if not result['success']:
        # ì—ëŸ¬ ì²˜ë¦¬
        error_msg = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
        print(f"ìˆ˜ì§‘ ì‹¤íŒ¨: {error_msg}")
        
        # ì„¸ì…˜ ì •ë³´ í™•ì¸
        if 'session_info' in result:
            session = result['session_info']
            print(f"ì²˜ë¦¬ëœ í˜ì´ì§€: {session.get('total_pages', 0)}")
            print(f"ì—ëŸ¬ ìˆ˜: {session.get('error_count', 0)}")
    
except Exception as e:
    print(f"ì˜ˆì™¸ ë°œìƒ: {e}")
    # ë¡œê·¸ ê¸°ë¡, ì•Œë¦¼ ë°œì†¡ ë“±
```

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### í…ŒìŠ¤íŠ¸ í™˜ê²½
- **CPU**: Intel i7-8750H (6ì½”ì–´)
- **ë©”ëª¨ë¦¬**: 16GB DDR4
- **ë„¤íŠ¸ì›Œí¬**: 100Mbps
- **DB**: Supabase (PostgreSQL)

### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

| ë§¤ë¬¼ ìˆ˜ | ê¸°ì¡´ ë°©ì‹ | ìƒˆë¡œìš´ ë°©ì‹ | ê°œì„ ë¥  |
|---------|-----------|-------------|--------|
| 500ê°œ | 45ì´ˆ | 28ì´ˆ | 38% â†‘ |
| 1,000ê°œ | 95ì´ˆ | 52ì´ˆ | 45% â†‘ |
| 2,000ê°œ | 210ì´ˆ | 115ì´ˆ | 45% â†‘ |

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

| ë‹¨ê³„ | ê¸°ì¡´ ë°©ì‹ | ìƒˆë¡œìš´ ë°©ì‹ | ê°œì„ ë¥  |
|------|-----------|-------------|--------|
| ìˆ˜ì§‘ | 150MB | 80MB | 47% â†“ |
| ë³€í™˜ | 280MB | 95MB | 66% â†“ |
| ì €ì¥ | 320MB | 100MB | 69% â†“ |

## ğŸš¨ ì—ëŸ¬ í•´ê²° ê°€ì´ë“œ

### 1. í† í° ê´€ë ¨ ì˜¤ë¥˜

**ë¬¸ì œ**: `í† í° íšë“ ì‹¤íŒ¨`
```python
# í•´ê²°ì±… 1: í† í° ìºì‹œ ì‚­ì œ
import os
token_file = "cached_token.json"
if os.path.exists(token_file):
    os.remove(token_file)

# í•´ê²°ì±… 2: ìˆ˜ë™ í† í° ê°±ì‹ 
collector._refresh_token()
```

### 2. ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜

**ë¬¸ì œ**: `API í˜¸ì¶œ ì‹¤íŒ¨`
```python
# í•´ê²°ì±… 1: ì¬ì‹œë„ ê°„ê²© ì¦ê°€
time.sleep(2)  # ê¸°ë³¸ê°’ì—ì„œ ì¦ê°€

# í•´ê²°ì±… 2: íƒ€ì„ì•„ì›ƒ ì¦ê°€
requests.get(url, timeout=60)  # ê¸°ë³¸ 30ì´ˆì—ì„œ ì¦ê°€
```

### 3. ë©”ëª¨ë¦¬ ë¶€ì¡±

**ë¬¸ì œ**: `ë©”ëª¨ë¦¬ ë¶€ì¡±`
```python
# í•´ê²°ì±… 1: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
collector = OptimizedDirectCollector(batch_size=20)

# í•´ê²°ì±… 2: ìˆ˜ë™ ë©”ëª¨ë¦¬ ì •ë¦¬
import gc
gc.collect()
```

### 4. ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜

**ë¬¸ì œ**: `DB ì €ì¥ ì‹¤íŒ¨`
```python
# í•´ê²°ì±… 1: ì—°ê²° í™•ì¸
client = EnhancedSupabaseClient()
stats = client.get_region_statistics("1168010100")

# í•´ê²°ì±… 2: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
collector = OptimizedDirectCollector(batch_size=10)
```

## ğŸ¯ ëª¨ë²” ì‚¬ë¡€ (Best Practices)

### 1. ìš´ì˜ í™˜ê²½ ì„¤ì •

```python
# ìš´ì˜ìš© ì„¤ì •
collector = OptimizedDirectCollector(
    batch_size=50,                    # ì•ˆì •ì ì¸ í¬ê¸°
    use_address_converter=True        # ì£¼ì†Œ ì •ë³´ í•„ìˆ˜
)

# ë¡œê¹… ì„¤ì •
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('collector.log'),
        logging.StreamHandler()
    ]
)
```

### 2. ì—ëŸ¬ ë³µêµ¬ ì „ëµ

```python
def robust_collection(cortar_no, region_name, max_retries=3):
    """ê²¬ê³ í•œ ìˆ˜ì§‘ í•¨ìˆ˜"""
    
    for attempt in range(max_retries):
        try:
            collector = OptimizedDirectCollector()
            result = collector.collect_region_direct(cortar_no, region_name)
            
            if result['success']:
                return result
            else:
                print(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {result.get('error')}")
                
        except Exception as e:
            print(f"ì‹œë„ {attempt + 1} ì˜ˆì™¸: {e}")
            
        if attempt < max_retries - 1:
            time.sleep(60)  # 1ë¶„ ëŒ€ê¸° í›„ ì¬ì‹œë„
    
    return {'success': False, 'error': 'Max retries exceeded'}
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
def monitor_collection_performance():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜"""
    
    regions = [
        ("1168010100", "ì—­ì‚¼ë™"),
        ("1168010200", "ì‚¼ì„±ë™"),
        ("1168010300", "ë…¼í˜„ë™")
    ]
    
    total_start = time.time()
    results = []
    
    for cortar_no, region_name in regions:
        start_time = time.time()
        
        result = collector.collect_region_direct(cortar_no, region_name)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        if result['success']:
            stats = result['collection_stats']
            performance = result['performance']
            
            results.append({
                'region': region_name,
                'processing_time': processing_time,
                'properties_collected': stats['collected_properties'],
                'records_per_second': performance['records_per_second'],
                'success_rate': performance['success_rate']
            })
    
    total_time = time.time() - total_start
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê²°ê³¼ (ì´ {total_time:.1f}ì´ˆ)")
    print("-" * 80)
    
    for result in results:
        print(f"{result['region']:10} | "
              f"ì‹œê°„: {result['processing_time']:6.1f}ì´ˆ | "
              f"ë§¤ë¬¼: {result['properties_collected']:4d}ê°œ | "
              f"ì†ë„: {result['records_per_second']:5.1f}/ì´ˆ | "
              f"ì„±ê³µë¥ : {result['success_rate']:5.1f}%")
```

ì´ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì—¬ ë„¤ì´ë²„ ë¶€ë™ì‚° ìˆ˜ì§‘ê¸°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.