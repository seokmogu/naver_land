#!/usr/bin/env python3
"""
ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë„¤ì´ë²„ ë¶€ë™ì‚° ìˆ˜ì§‘ê¸°
- ì‹¤ì‹œê°„ DB ì €ì¥ (JSON íŒŒì¼ ë¶ˆí•„ìš”)
- ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬ (50ê°œì”©)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì†Œí™”
- ì¤‘ë‹¨ì  ë³µêµ¬ ê¸°ëŠ¥
"""

import requests
import json
import time
import os
from datetime import datetime, timedelta
from optimized_supabase_client import OptimizedSupabaseHelper
from kakao_address_converter import KakaoAddressConverter

class MemoryOptimizedCollector:
    def __init__(self, batch_size=50):
        """ë©”ëª¨ë¦¬ ìµœì í™” ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”"""
        self.batch_size = batch_size  # ë°°ì¹˜ í¬ê¸°
        self.token_file = os.path.join(os.path.dirname(__file__), 'cached_token.json')
        self.token = None
        self.cookies = {}
        self.token_expires_at = None
        
        # ìµœì í™”ëœ Supabase í´ë¼ì´ì–¸íŠ¸
        self.db = OptimizedSupabaseHelper()
        
        # ì£¼ì†Œ ë³€í™˜ê¸°
        try:
            self.address_converter = KakaoAddressConverter()
            print("ğŸ—ºï¸ ì¹´ì¹´ì˜¤ ì£¼ì†Œ ë³€í™˜ê¸° í™œì„±í™”")
        except ValueError as e:
            print(f"âš ï¸ ì£¼ì†Œ ë³€í™˜ê¸° ë¹„í™œì„±í™”: {e}")
            self.address_converter = None
        
        # ìºì‹œëœ í† í° ë¡œë“œ
        self.load_cached_token()
    
    def load_cached_token(self):
        """ìºì‹œëœ í† í° ë¡œë“œ"""
        if os.path.exists(self.token_file):
            try:
                with open(self.token_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                
                expires_at = datetime.fromisoformat(cache_data['expires_at'])
                if datetime.now() < expires_at:
                    self.token = cache_data['token']
                    cookies_list = cache_data.get('cookies', [])
                    if isinstance(cookies_list, list):
                        self.cookies = {cookie['name']: cookie['value'] for cookie in cookies_list}
                    else:
                        self.cookies = cookies_list
                    self.token_expires_at = expires_at
                    print(f"âœ… ìºì‹œëœ í† í° ë¡œë“œ ì™„ë£Œ (ë§Œë£Œ: {expires_at.strftime('%Y-%m-%d %H:%M:%S')})")
                    return True
                else:
                    print("â° ìºì‹œëœ í† í°ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
            except Exception as e:
                print(f"âŒ í† í° ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    def setup_headers(self):
        """API ìš”ì²­ í—¤ë” ì„¤ì •"""
        return {
            'authority': 'new.land.naver.com',
            'accept': 'application/json, text/plain, */*',
            'accept-language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'authorization': f'Bearer {self.token}',
            'referer': 'https://new.land.naver.com/offices?ms=37.4986291,127.0359669,16&a=SG:SMS:GJCG:APTHGJ:GM:TJ&e=RETAIL',
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
            'sec-fetch-dest': 'empty',
            'sec-fetch-mode': 'cors',
            'sec-fetch-site': 'same-origin'
        }
    
    def save_batch_to_db(self, properties_batch, cortar_no):
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ DB ì €ì¥"""
        if not properties_batch:
            return 0
        
        try:
            # ì£¼ì†Œ ë³€í™˜ (í•„ìš”ì‹œ) - ê°„ì†Œí™”
            processed_properties = []
            for prop in properties_batch:
                # ì •ê·œí™”ëœ ë°ì´í„° ìƒì„±
                property_data = self.normalize_property_data(prop, cortar_no)
                processed_properties.append(property_data)
            
            # ì¿¼ë¦¬ ìµœì í™”ëœ ë°°ì¹˜ ì €ì¥ ì‚¬ìš©
            result = self.db.save_properties_optimized(processed_properties, cortar_no)
            
            saved_count = result.get('saved_count', 0)
            print(f"ğŸ’¾ ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {saved_count}/{len(properties_batch)}ê°œ")
            return saved_count
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì €ì¥ ì˜¤ë¥˜: {e}")
            return 0
    
    def normalize_property_data(self, raw_data, cortar_no):
        """ë§¤ë¬¼ ë°ì´í„°ë¥¼ ê¸°ì¡´ í˜•ì‹ì— ë§ì¶° ì •ê·œí™”"""
        return {
            'ë§¤ë¬¼ë²ˆí˜¸': raw_data.get('articleNo', ''),
            'ë§¤ë¬¼ëª…': raw_data.get('articleName', ''),
            'ë¶€ë™ì‚°íƒ€ì…': raw_data.get('realEstateTypeName', ''),
            'ê±°ë˜íƒ€ì…': raw_data.get('tradeTypeName', ''),
            'ë§¤ë§¤ê°€ê²©': raw_data.get('dealOrWarrantPrc', ''),
            'ì›”ì„¸': raw_data.get('rentPrc', ''),
            'ì „ìš©ë©´ì ': raw_data.get('area1', 0),
            'ê³µê¸‰ë©´ì ': raw_data.get('area2', 0),
            'ì¸µì •ë³´': raw_data.get('floorInfo', ''),
            'ë°©í–¥': raw_data.get('direction', ''),
            'ìƒì„¸ì£¼ì†Œ': raw_data.get('representativeImgUrl', ''),
            'íƒœê·¸': raw_data.get('tagList', []),
            'ì„¤ëª…': raw_data.get('articleFeatureDesc', ''),
            'ìƒì„¸ì •ë³´': {
                'ìœ„ì¹˜ì •ë³´': {
                    'ì •í™•í•œ_ìœ„ë„': raw_data.get('lat'),
                    'ì •í™•í•œ_ê²½ë„': raw_data.get('lng')
                }
            }
        }
    
    def collect_with_realtime_save(self, cortar_no, dong_name, max_pages=999):
        """ì‹¤ì‹œê°„ DB ì €ì¥ ìˆ˜ì§‘ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        if not self.token:
            print("âŒ ìœ íš¨í•œ í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        url = "https://new.land.naver.com/api/articles"
        headers = self.setup_headers()
        
        base_params = {
            'cortarNo': cortar_no,
            'order': 'rank',
            'realEstateType': 'SG:SMS:GJCG:APTHGJ:GM:TJ',
            'tradeType': '',
            'tag': '::::::::',
            'rentPriceMin': '0',
            'rentPriceMax': '900000000',
            'priceMin': '0',
            'priceMax': '900000000',
            'areaMin': '0',
            'areaMax': '900000000',
            'oldBuildYears': '',
            'recentlyBuildYears': '',
            'minHouseHoldCount': '',
            'maxHouseHoldCount': '',
            'showArticle': 'false',
            'sameAddressGroup': 'false',
            'minMaintenanceCost': '',
            'maxMaintenanceCost': '',
            'priceType': 'RETAIL',
            'directions': '',
            'articleState': ''
        }
        
        total_collected = 0
        batch_buffer = []  # ë©”ëª¨ë¦¬ ìµœì†Œí™”: ë°°ì¹˜ë§Œ ìœ ì§€
        
        print(f"ğŸš€ {dong_name} ì‹¤ì‹œê°„ ìˆ˜ì§‘ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {self.batch_size})")
        
        try:
            for page in range(1, max_pages + 1):
                params = base_params.copy()
                params['page'] = page
                
                print(f"ğŸ“„ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘... (í˜„ì¬ ë°°ì¹˜: {len(batch_buffer)}ê°œ)")
                
                response = requests.get(url, headers=headers, params=params, cookies=self.cookies, timeout=30)
                
                if response.status_code != 200:
                    print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                    print(f"âŒ ì‘ë‹µ ë‚´ìš©: {response.text[:500]}")
                    break
                
                data = response.json()
                # ì‘ë‹µ êµ¬ì¡°ì— ë§ì¶° ìˆ˜ì •
                if 'body' in data:
                    articles = data['body']
                elif 'articleList' in data:
                    articles = data['articleList']
                else:
                    articles = []
                
                print(f"ğŸ“Š API ì‘ë‹µ: status={response.status_code}, articles={len(articles)}")
                if page == 1:  # ì²« í˜ì´ì§€ë§Œ ë””ë²„ê·¸ ì¶œë ¥
                    print(f"ğŸ” ì²« í˜ì´ì§€ ì‘ë‹µ êµ¬ì¡°: {list(data.keys())}")
                
                if not articles:
                    print("ğŸ“­ ë” ì´ìƒ ë§¤ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                # ë°°ì¹˜ ë²„í¼ì— ì¶”ê°€
                batch_buffer.extend(articles)
                total_collected += len(articles)
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì¦‰ì‹œ DB ì €ì¥
                if len(batch_buffer) >= self.batch_size:
                    saved = self.save_batch_to_db(batch_buffer, cortar_no)
                    print(f"âœ… ì‹¤ì‹œê°„ ì €ì¥: {saved}ê°œ (ì´ {total_collected}ê°œ ìˆ˜ì§‘)")
                    batch_buffer.clear()  # ë©”ëª¨ë¦¬ í•´ì œ
                
                # API ì œí•œ ë°©ì§€
                time.sleep(0.1)
            
            # ë§ˆì§€ë§‰ ë‚¨ì€ ë°°ì¹˜ ì €ì¥
            if batch_buffer:
                saved = self.save_batch_to_db(batch_buffer, cortar_no)
                print(f"âœ… ìµœì¢… ì €ì¥: {saved}ê°œ")
                batch_buffer.clear()
        
        except Exception as e:
            print(f"âŒ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ ì‹œë„
            if batch_buffer:
                print("ğŸ”„ ì˜¤ë¥˜ ë°œìƒ, ë§ˆì§€ë§‰ ë°°ì¹˜ ì €ì¥ ì‹œë„...")
                self.save_batch_to_db(batch_buffer, cortar_no)
        
        print(f"ğŸ¯ {dong_name} ìˆ˜ì§‘ ì™„ë£Œ: ì´ {total_collected}ê°œ ë§¤ë¬¼")
        return total_collected

def collect_optimized_by_dong(dong_name, cortar_no, batch_size=50):
    """ë™ë³„ ë©”ëª¨ë¦¬ ìµœì í™” ìˆ˜ì§‘"""
    print(f"ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™” ìˆ˜ì§‘ ì‹œì‘: {dong_name} ({cortar_no})")
    
    try:
        collector = MemoryOptimizedCollector(batch_size=batch_size)
        total = collector.collect_with_realtime_save(cortar_no, dong_name)
        
        return {
            'success': total > 0,
            'dong_name': dong_name,
            'count': total,
            'method': 'ì‹¤ì‹œê°„_DB_ì €ì¥'
        }
    
    except Exception as e:
        print(f"âŒ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        return {
            'success': False,
            'dong_name': dong_name,
            'count': 0,
            'error': str(e)
        }

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸: ì—­ì‚¼ë™ ë©”ëª¨ë¦¬ ìµœì í™” ìˆ˜ì§‘
    result = collect_optimized_by_dong("ì—­ì‚¼ë™", "1168010100", batch_size=50)
    print(f"ğŸ¯ ê²°ê³¼: {result}")