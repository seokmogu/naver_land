#!/usr/bin/env python3
"""
ê°•ë‚¨êµ¬ ì „ì²´ ë™ ë³‘ë ¬ ìë™ ë°°ì¹˜ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•˜ì—¬ ë™ë³„ë¡œ ë³‘ë ¬ ìˆ˜ì§‘
"""

import sys
import time
import json
import signal
import multiprocessing as mp
from datetime import datetime
from typing import List, Dict
from concurrent.futures import ProcessPoolExecutor, as_completed
from supabase_client import SupabaseHelper
from fixed_naver_collector import collect_by_cortar_no

# ì „ì—­ ë³€ìˆ˜ë¡œ ì¢…ë£Œ ìƒíƒœ ê´€ë¦¬
shutdown_requested = False

def signal_handler(signum, frame):
    """Ctrl+C ì²˜ë¦¬"""
    global shutdown_requested
    print(f"\nâš ï¸ ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹  (Ctrl+C). ì•ˆì „í•˜ê²Œ ì¢…ë£Œ ì¤‘...")
    shutdown_requested = True

def get_gangnam_collection_priority() -> List[Dict]:
    """ê°•ë‚¨êµ¬ ë™ë³„ ìˆ˜ì§‘ ìš°ì„ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    helper = SupabaseHelper()
    result = helper.client.table('areas').select('dong_name, cortar_no, center_lat, center_lon').eq('gu_name', 'ê°•ë‚¨êµ¬').execute()
    
    # ìš°ì„ ìˆœìœ„ ì ìˆ˜ ë§¤í•‘
    priority_scores = {
        'ì—­ì‚¼ë™': 30, 'ì‚¼ì„±ë™': 26, 'ë…¼í˜„ë™': 23, 'ëŒ€ì¹˜ë™': 22, 'ì‹ ì‚¬ë™': 22,
        'ì••êµ¬ì •ë™': 20, 'ì²­ë‹´ë™': 18, 'ë„ê³¡ë™': 18, 'ê°œí¬ë™': 17, 'ìˆ˜ì„œë™': 12,
        'ì¼ì›ë™': 11, 'ìê³¡ë™': 8, 'ì„¸ê³¡ë™': 6, 'ìœ¨í˜„ë™': 5
    }
    
    # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    areas = []
    for area in result.data:
        dong_name = area['dong_name']
        score = priority_scores.get(dong_name, 1)
        areas.append({
            'dong_name': dong_name,
            'cortar_no': area['cortar_no'],
            'center_lat': area['center_lat'],
            'center_lon': area['center_lon'],
            'priority_score': score
        })
    
    # ìš°ì„ ìˆœìœ„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    return sorted(areas, key=lambda x: x['priority_score'], reverse=True)

def collect_single_dong(area_info: Dict, include_details: bool = False) -> Dict:
    """ë‹¨ì¼ ë™ ìˆ˜ì§‘ (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
    dong_name = area_info['dong_name']
    cortar_no = area_info['cortar_no']
    
    print(f"ğŸ¯ [{mp.current_process().name}] {dong_name} ({cortar_no}) ìˆ˜ì§‘ ì‹œì‘")
    
    collection_start = datetime.now()
    
    # ìˆ˜ì§‘ ë¡œê·¸ ì‹œì‘ (ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ ì‹œì—ë„ ìˆ˜ì§‘ ê³„ì†)
    log_data = None
    try:
        helper = SupabaseHelper()
        log_data = {
            'gu_name': 'ê°•ë‚¨êµ¬',
            'dong_name': dong_name,
            'cortar_no': cortar_no,
            'collection_type': f'parallel_collection_{mp.current_process().name}',
            'status': 'started',
            'started_at': collection_start.isoformat()
        }
        helper.log_collection(log_data)
    except Exception as e:
        print(f"âš ï¸ [{mp.current_process().name}] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨, ìˆ˜ì§‘ì€ ê³„ì†: {e}")
        log_data = None
    
    try:
        # ë§¤ë¬¼ ë°ì´í„° ìˆ˜ì§‘ (ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ í† í° ìƒì„±)
        collect_result = collect_by_cortar_no(cortar_no, include_details, max_pages=999)
        
        if collect_result['success']:
            collection_end = datetime.now()
            duration = (collection_end - collection_start).total_seconds()
            collected_count = collect_result['count']
            json_filepath = collect_result['filepath']
            
            print(f"âœ… [{mp.current_process().name}] {dong_name} ìˆ˜ì§‘ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ, {collected_count}ê°œ ë§¤ë¬¼)")
            
            # JSON íŒŒì¼ì„ Supabaseì— ì €ì¥
            print(f"ğŸ’¾ [{mp.current_process().name}] Supabase ì €ì¥ ì‹œì‘: {json_filepath}")
            from json_to_supabase import process_json_file
            
            supabase_result = process_json_file(json_filepath, cortar_no)
            
            if supabase_result['success']:
                print(f"âœ… [{mp.current_process().name}] Supabase ì €ì¥ ì™„ë£Œ: {supabase_result['count']}ê°œ ë§¤ë¬¼")
                
                # ì„±ê³µ ë¡œê·¸ ì—…ë°ì´íŠ¸
                if log_data:
                    try:
                        log_data.update({
                            'status': 'completed',
                            'completed_at': collection_end.isoformat(),
                            'total_collected': collected_count
                        })
                        helper.log_collection(log_data)
                    except Exception as e:
                        print(f"âš ï¸ [{mp.current_process().name}] ì„±ê³µ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                
                return {
                    'success': True,
                    'dong_name': dong_name,
                    'duration': duration,
                    'collected_count': collected_count,
                    'supabase_count': supabase_result['count'],
                    'supabase_stats': supabase_result['stats'],
                    'json_filepath': json_filepath,
                    'process_name': mp.current_process().name
                }
            else:
                print(f"âŒ [{mp.current_process().name}] Supabase ì €ì¥ ì‹¤íŒ¨: {supabase_result.get('message', 'Unknown')}")
                
                # ë¶€ë¶„ ì„±ê³µ ë¡œê·¸ (ìˆ˜ì§‘ì€ ì„±ê³µ, DB ì €ì¥ ì‹¤íŒ¨)
                if log_data:
                    try:
                        log_data.update({
                            'status': 'completed',
                            'completed_at': collection_end.isoformat(),
                            'total_collected': collected_count,
                            'error_message': f"Supabase ì €ì¥ ì‹¤íŒ¨: {supabase_result.get('error', 'Unknown')}"
                        })
                        helper.log_collection(log_data)
                    except Exception as e:
                        print(f"âš ï¸ [{mp.current_process().name}] ë¶€ë¶„ì„±ê³µ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                
                return {
                    'success': False,
                    'dong_name': dong_name,
                    'duration': duration,
                    'collected_count': collected_count,
                    'error': f"Supabase ì €ì¥ ì‹¤íŒ¨: {supabase_result.get('error', 'Unknown')}",
                    'json_filepath': json_filepath,
                    'process_name': mp.current_process().name
                }
        else:
            print(f"âŒ [{mp.current_process().name}] {dong_name} ìˆ˜ì§‘ ì‹¤íŒ¨")
            
            # ì‹¤íŒ¨ ë¡œê·¸ ì—…ë°ì´íŠ¸
            if log_data:
                try:
                    log_data.update({
                        'status': 'failed',
                        'completed_at': datetime.now().isoformat(),
                        'error_message': 'ìˆ˜ì§‘ ì‹¤íŒ¨'
                    })
                    helper.log_collection(log_data)
                except Exception as e:
                    print(f"âš ï¸ [{mp.current_process().name}] ì‹¤íŒ¨ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            
            return {
                'success': False,
                'dong_name': dong_name,
                'error': 'ìˆ˜ì§‘ ì‹¤íŒ¨',
                'process_name': mp.current_process().name
            }
            
    except Exception as e:
        print(f"âŒ [{mp.current_process().name}] {dong_name} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ì˜¤ë¥˜ ë¡œê·¸ ì—…ë°ì´íŠ¸
        if log_data:
            try:
                log_data.update({
                    'status': 'failed',
                    'completed_at': datetime.now().isoformat(),
                    'error_message': str(e)
                })
                helper.log_collection(log_data)
            except Exception as log_e:
                print(f"âš ï¸ [{mp.current_process().name}] ì˜¤ë¥˜ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {log_e}")
        
        return {
            'success': False,
            'dong_name': dong_name,
            'error': str(e),
            'process_name': mp.current_process().name
        }

def main():
    """ê°•ë‚¨êµ¬ ì „ì²´ ë™ ë³‘ë ¬ ìˆ˜ì§‘ ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ê°•ë‚¨êµ¬ ì „ì²´ ë™ ë³‘ë ¬ ìë™ ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 80)
    
    # ìˆ˜ì§‘ ì˜µì…˜
    include_details = True  # ìƒì„¸ì •ë³´ í¬í•¨ (ê¸°ë³¸ê°’ ë³€ê²½)
    max_workers = 1  # VM ì„±ëŠ¥ ê³ ë ¤í•˜ì—¬ ìˆœì°¨ ì²˜ë¦¬ (ê¸°ë³¸ê°’: 1ê°œ)
    
    # ëª…ë ¹í–‰ ì¸ì ì²˜ë¦¬
    if len(sys.argv) > 1:
        if sys.argv[1].lower() == 'false':
            include_details = False
            print("âš¡ ê¸°ë³¸ ì •ë³´ë§Œ ìˆ˜ì§‘ ëª¨ë“œ (ì†ë„ ìµœì í™”)")
        elif sys.argv[1].isdigit():
            max_workers = int(sys.argv[1])
            print(f"ğŸ”„ ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤ ìˆ˜: {max_workers}ê°œ")
    
    if len(sys.argv) > 2:
        if sys.argv[2].lower() == 'false':
            include_details = False
            print("âš¡ ê¸°ë³¸ ì •ë³´ë§Œ ìˆ˜ì§‘ ëª¨ë“œ (ì†ë„ ìµœì í™”)")
        elif sys.argv[2].isdigit():
            max_workers = int(sys.argv[2])
            print(f"ğŸ”„ ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤ ìˆ˜: {max_workers}ê°œ")
    
    if include_details:
        print("ğŸ” ìƒì„¸ì •ë³´ í¬í•¨ ìˆ˜ì§‘ ëª¨ë“œ")
    else:
        print("âš¡ ê¸°ë³¸ ì •ë³´ë§Œ ìˆ˜ì§‘ ëª¨ë“œ (ì†ë„ ìµœì í™”)")
    
    # CPU ì½”ì–´ ìˆ˜ í™•ì¸ ë° ì¡°ì •
    cpu_count = mp.cpu_count()
    if max_workers > cpu_count:
        max_workers = cpu_count
        print(f"âš ï¸ CPU ì½”ì–´ ìˆ˜({cpu_count})ì— ë§ì¶° í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì¡°ì •: {max_workers}ê°œ")
    
    # ê°•ë‚¨êµ¬ ë™ë³„ ìš°ì„ ìˆœìœ„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    areas = get_gangnam_collection_priority()
    total_areas = len(areas)
    
    print(f"\nğŸ“‹ ìˆ˜ì§‘ ëŒ€ìƒ: {total_areas}ê°œ ë™")
    print(f"ğŸ”„ ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤: {max_workers}ê°œ")
    print("ğŸ† ìš°ì„ ìˆœìœ„ ìˆœì„œ:")
    for i, area in enumerate(areas, 1):
        print(f"  {i:2d}. {area['dong_name']:8s} (ì ìˆ˜: {area['priority_score']:2d}) - {area['cortar_no']}")
    
    # ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘
    batch_start = datetime.now()
    results = []
    success_count = 0
    
    # Ctrl+C í•¸ë“¤ëŸ¬ ë“±ë¡
    signal.signal(signal.SIGINT, signal_handler)
    
    print(f"\nğŸš€ ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘: {batch_start.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”„ {max_workers}ê°œ í”„ë¡œì„¸ìŠ¤ë¡œ ë™ì‹œ ì‹¤í–‰")
    print("ğŸ’¡ Ctrl+Cë¡œ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ ê°€ëŠ¥")
    print("=" * 80)
    
    # ProcessPoolExecutor ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # ëª¨ë“  ë™ì— ëŒ€í•´ ì‘ì—… ì œì¶œ
        future_to_area = {
            executor.submit(collect_single_dong, area, include_details): area 
            for area in areas
        }
        
        # ì™„ë£Œëœ ì‘ì—…ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
        completed_count = 0
        for future in as_completed(future_to_area):
            # ì¢…ë£Œê°€ ìš”ì²­ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if shutdown_requested:
                print("âš ï¸ ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ì¢…ë£Œ ì¤‘... ì§„í–‰ ì¤‘ì¸ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°")
                executor.shutdown(wait=True)
                break
                
            completed_count += 1
            area = future_to_area[future]
            
            try:
                result = future.result()
                results.append(result)
                
                print(f"\nğŸ“Š ì „ì²´ ì§„í–‰ë¥ : {completed_count}/{total_areas} ({completed_count/total_areas*100:.1f}%)")
                
                if result['success']:
                    success_count += 1
                    print(f"âœ… ì„±ê³µ: {result['dong_name']} ({result.get('duration', 0):.1f}ì´ˆ) - {result.get('process_name', 'Unknown')}")
                else:
                    print(f"âŒ ì‹¤íŒ¨: {result['dong_name']} - {result.get('error', 'Unknown')} - {result.get('process_name', 'Unknown')}")
                    
            except Exception as e:
                print(f"âŒ {area['dong_name']} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                results.append({
                    'success': False,
                    'dong_name': area['dong_name'],
                    'error': f"ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {e}"
                })
    
    # ë³‘ë ¬ ìˆ˜ì§‘ ì™„ë£Œ ìš”ì•½
    batch_end = datetime.now()
    total_duration = (batch_end - batch_start).total_seconds()
    
    print(f"\nğŸ¯ ê°•ë‚¨êµ¬ ì „ì²´ ë³‘ë ¬ ìˆ˜ì§‘ ì™„ë£Œ!")
    print("=" * 80)
    print(f"ğŸ“Š ìˆ˜ì§‘ í†µê³„:")
    print(f"  - ì „ì²´ ë™ ìˆ˜: {total_areas}ê°œ")
    print(f"  - ì„±ê³µí•œ ë™: {success_count}ê°œ")
    print(f"  - ì‹¤íŒ¨í•œ ë™: {total_areas - success_count}ê°œ")
    print(f"  - ì„±ê³µë¥ : {success_count/total_areas*100:.1f}%")
    print(f"  - ì´ ì†Œìš”ì‹œê°„: {total_duration/60:.1f}ë¶„")
    print(f"  - ì‹œì‘ì‹œê°„: {batch_start.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  - ì™„ë£Œì‹œê°„: {batch_end.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  - ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤: {max_workers}ê°œ")
    print(f"  - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_duration/max_workers/60:.1f}ë¶„/í”„ë¡œì„¸ìŠ¤")
    
    # ê²°ê³¼ ì €ì¥
    timestamp = batch_start.strftime("%Y%m%d_%H%M%S")
    result_file = f"results/parallel_collection_gangnam_{timestamp}.json"
    
    batch_summary = {
        'batch_info': {
            'gu_name': 'ê°•ë‚¨êµ¬',
            'start_time': batch_start.isoformat(),
            'end_time': batch_end.isoformat(),
            'total_duration_seconds': total_duration,
            'include_details': include_details,
            'max_workers': max_workers,
            'collection_method': 'parallel'
        },
        'statistics': {
            'total_areas': total_areas,
            'success_count': success_count,
            'failed_count': total_areas - success_count,
            'success_rate': success_count/total_areas*100,
            'avg_processing_time_per_worker': total_duration/max_workers
        },
        'results': results
    }
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(batch_summary, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ë³‘ë ¬ ìˆ˜ì§‘ ê²°ê³¼ ì €ì¥: {result_file}")
    
    if success_count == total_areas:
        print("ğŸ‰ ëª¨ë“  ë™ ìˆ˜ì§‘ ì„±ê³µ!")
        sys.exit(0)
    else:
        print(f"âš ï¸ {total_areas - success_count}ê°œ ë™ ìˆ˜ì§‘ ì‹¤íŒ¨")
        sys.exit(1)

if __name__ == "__main__":
    # ë©€í‹°í”„ë¡œì„¸ì‹±ì—ì„œ í•„ìš”í•œ ì„¤ì •
    mp.set_start_method('spawn', force=True)
    main()