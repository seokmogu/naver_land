#!/usr/bin/env python3
"""
Supabase ë°ì´í„°ë² ì´ìŠ¤ ì¢…í•© ê²€ì¦ ë„êµ¬
- ì‹¤ì œ ë°°í¬ëœ í…Œì´ë¸” ìƒíƒœ í™•ì¸
- ë°ì´í„° í’ˆì§ˆ ê²€ì¦
- API í•„ë“œ ë§¤í•‘ íš¨ê³¼ ë¶„ì„
- ìŠ¤í‚¤ë§ˆ ì •ê·œí™” ì™„ë£Œë„ í‰ê°€
"""

import os
import sys
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from pathlib import Path
from dotenv import load_dotenv

# Supabase í´ë¼ì´ì–¸íŠ¸ import
try:
    from supabase import create_client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("âŒ supabase-py ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤: pip install supabase")
    sys.exit(1)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class ComprehensiveDBVerifier:
    def __init__(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ê¸° ì´ˆê¸°í™”"""
        # Supabase ì—°ê²° ì •ë³´
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_ANON_KEY')
        
        if not self.supabase_url or not self.supabase_key:
            print("âŒ SUPABASE_URLê³¼ SUPABASE_ANON_KEYë¥¼ .env íŒŒì¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            sys.exit(1)
        
        # Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        try:
            self.client = create_client(self.supabase_url, self.supabase_key)
            print("âœ… Supabase ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
            sys.exit(1)
        
        # ê²€ì¦ ê²°ê³¼ ì €ì¥ìš©
        self.verification_results = {
            'timestamp': datetime.now().isoformat(),
            'tables_status': {},
            'data_quality': {},
            'schema_completeness': {},
            'field_mapping_effectiveness': {},
            'overall_assessment': {}
        }
    
    def verify_table_existence_and_structure(self) -> Dict[str, Any]:
        """í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ì™€ êµ¬ì¡° ê²€ì¦"""
        print("\nğŸ” 1. í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ ë° êµ¬ì¡° ê²€ì¦")
        print("=" * 60)
        
        # ì˜ˆìƒë˜ëŠ” í…Œì´ë¸”ë“¤
        expected_tables = {
            # ë©”ì¸ í…Œì´ë¸”ë“¤
            'properties_new': 'Main normalized properties table',
            'property_locations': 'Property location and address data',
            'property_physical': 'Physical property characteristics',
            'property_prices': 'Property pricing information',
            'property_images': 'Property photos and media',
            'property_tax_info': 'Property tax calculation data',
            'property_price_comparison': 'Price comparison analytics',
            'property_facilities': 'Property facilities mapping',
            
            # ì°¸ì¡° í…Œì´ë¸”ë“¤
            'realtors': 'Realtor/broker information',
            'property_realtors': 'Property-realtor relationships',
            'real_estate_types': 'Property types reference',
            'trade_types': 'Transaction types reference',
            'regions': 'Regional data reference',
            
            # ìš´ì˜ í…Œì´ë¸”ë“¤
            'daily_stats': 'Daily collection statistics',
            'collection_logs': 'Collection activity logs',
            'deletion_history': 'Deleted properties tracking',
            'price_history': 'Price change history'
        }
        
        table_status = {}
        
        for table_name, description in expected_tables.items():
            try:
                # í…Œì´ë¸” ì¡´ì¬ í™•ì¸ (1ê°œ ë ˆì½”ë“œë§Œ ì¡°íšŒ)
                result = self.client.table(table_name).select('*').limit(1).execute()
                
                # ë ˆì½”ë“œ ìˆ˜ í™•ì¸
                count_result = self.client.table(table_name).select('*', count='exact').limit(1).execute()
                record_count = count_result.count or 0
                
                # ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸ (ì²« ë²ˆì§¸ ë ˆì½”ë“œê°€ ìˆìœ¼ë©´)
                columns = []
                if result.data and len(result.data) > 0:
                    columns = list(result.data[0].keys())
                
                table_status[table_name] = {
                    'exists': True,
                    'record_count': record_count,
                    'columns': columns,
                    'column_count': len(columns),
                    'description': description,
                    'has_data': record_count > 0
                }
                
                status_icon = "âœ…" if record_count > 0 else "ğŸ“‹"
                print(f"{status_icon} {table_name:<25} | {record_count:>7,}ê°œ ë ˆì½”ë“œ | {len(columns):>2}ê°œ ì»¬ëŸ¼")
                
            except Exception as e:
                table_status[table_name] = {
                    'exists': False,
                    'error': str(e),
                    'description': description,
                    'record_count': 0
                }
                print(f"âŒ {table_name:<25} | í…Œì´ë¸” ì—†ìŒ | {str(e)}")
        
        self.verification_results['tables_status'] = table_status
        return table_status
    
    def analyze_data_quality(self) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        print("\nğŸ“Š 2. ë°ì´í„° í’ˆì§ˆ ë¶„ì„")
        print("=" * 60)
        
        quality_report = {}
        
        # ë©”ì¸ ë°ì´í„° í…Œì´ë¸”ë“¤ ë¶„ì„
        main_tables = ['properties_new', 'property_locations', 'property_physical', 'property_prices']
        
        for table_name in main_tables:
            if self.verification_results['tables_status'].get(table_name, {}).get('exists', False):
                print(f"\nğŸ” {table_name} ë¶„ì„ ì¤‘...")
                quality_report[table_name] = self._analyze_table_quality(table_name)
            else:
                print(f"âŒ {table_name}: í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
                quality_report[table_name] = {'error': 'Table does not exist'}
        
        self.verification_results['data_quality'] = quality_report
        return quality_report
    
    def _analyze_table_quality(self, table_name: str) -> Dict[str, Any]:
        """ê°œë³„ í…Œì´ë¸” ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        try:
            # ìƒ˜í”Œ ë°ì´í„° ìˆ˜ì§‘ (ìµœëŒ€ 1000ê°œ)
            result = self.client.table(table_name).select('*').limit(1000).execute()
            data = result.data
            
            if not data:
                return {'error': 'No data in table'}
            
            total_records = len(data)
            columns = list(data[0].keys()) if data else []
            
            # NULL ê°’ ë¶„ì„
            null_analysis = {}
            for column in columns:
                null_count = sum(1 for row in data if row.get(column) is None or row.get(column) == '')
                null_percentage = (null_count / total_records) * 100 if total_records > 0 else 0
                
                if null_percentage > 0:
                    null_analysis[column] = {
                        'null_count': null_count,
                        'null_percentage': round(null_percentage, 1)
                    }
            
            # ë†’ì€ NULL ë¹„ìœ¨ ì»¬ëŸ¼ ì‹ë³„
            high_null_columns = {k: v for k, v in null_analysis.items() if v['null_percentage'] > 30}
            
            # ë°ì´í„° ì¼ê´€ì„± í™•ì¸
            consistency_issues = self._check_data_consistency(data, table_name)
            
            quality_score = self._calculate_quality_score(null_analysis, consistency_issues, total_records)
            
            print(f"   ğŸ“Š ì´ {total_records:,}ê°œ ë ˆì½”ë“œ, {len(columns)}ê°œ ì»¬ëŸ¼")
            print(f"   âš ï¸ ë†’ì€ NULL ë¹„ìœ¨ ì»¬ëŸ¼: {len(high_null_columns)}ê°œ")
            print(f"   ğŸ¯ ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {quality_score}/100ì ")
            
            return {
                'total_records': total_records,
                'total_columns': len(columns),
                'null_analysis': null_analysis,
                'high_null_columns': high_null_columns,
                'consistency_issues': consistency_issues,
                'quality_score': quality_score
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def _check_data_consistency(self, data: List[Dict], table_name: str) -> List[str]:
        """ë°ì´í„° ì¼ê´€ì„± í™•ì¸"""
        issues = []
        
        for i, record in enumerate(data[:100]):  # ì²˜ìŒ 100ê°œë§Œ í™•ì¸
            try:
                # ê³µí†µ ì¼ê´€ì„± í™•ì¸
                if 'price' in record:
                    price = record.get('price')
                    if isinstance(price, (int, float)) and price < 0:
                        issues.append(f"ìŒìˆ˜ ê°€ê²© ë°œê²¬: ë ˆì½”ë“œ {i}")
                
                # ë‚ ì§œ ì¼ê´€ì„± í™•ì¸
                if 'created_at' in record and 'updated_at' in record:
                    created = record.get('created_at')
                    updated = record.get('updated_at')
                    if created and updated and created > updated:
                        issues.append(f"ë‚ ì§œ ë¶ˆì¼ì¹˜: ë ˆì½”ë“œ {i}")
                
                # í…Œì´ë¸”ë³„ íŠ¹ìˆ˜ í™•ì¸
                if table_name == 'properties_new':
                    if record.get('article_no') and len(str(record['article_no'])) < 5:
                        issues.append(f"ì˜ì‹¬ìŠ¤ëŸ¬ìš´ article_no: ë ˆì½”ë“œ {i}")
                
            except Exception:
                continue
        
        return issues[:10]  # ìµœëŒ€ 10ê°œ ì´ìŠˆë§Œ ë°˜í™˜
    
    def _calculate_quality_score(self, null_analysis: Dict, consistency_issues: List, total_records: int) -> float:
        """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (100ì  ë§Œì )"""
        score = 100.0
        
        # NULL ê°’ í˜ë„í‹°
        high_null_count = sum(1 for info in null_analysis.values() if info['null_percentage'] > 50)
        medium_null_count = sum(1 for info in null_analysis.values() if 20 < info['null_percentage'] <= 50)
        
        score -= (high_null_count * 10)  # ë†’ì€ NULL ë¹„ìœ¨ ì»¬ëŸ¼ë‹¹ 10ì  ê°ì 
        score -= (medium_null_count * 5)  # ì¤‘ê°„ NULL ë¹„ìœ¨ ì»¬ëŸ¼ë‹¹ 5ì  ê°ì 
        
        # ì¼ê´€ì„± ì´ìŠˆ í˜ë„í‹°
        score -= (len(consistency_issues) * 2)  # ì´ìŠˆë‹¹ 2ì  ê°ì 
        
        # ë°ì´í„° ë³¼ë¥¨ ë³´ë„ˆìŠ¤
        if total_records > 1000:
            score += 5
        
        return max(0, min(100, round(score, 1)))
    
    def assess_field_mapping_effectiveness(self) -> Dict[str, Any]:
        """API í•„ë“œ ë§¤í•‘ ìˆ˜ì • íš¨ê³¼ í‰ê°€"""
        print("\nğŸ”§ 3. API í•„ë“œ ë§¤í•‘ íš¨ê³¼ ë¶„ì„")
        print("=" * 60)
        
        mapping_effectiveness = {}
        
        # area1, area2 í•„ë“œëª… ìˆ˜ì • íš¨ê³¼ í™•ì¸
        if self.verification_results['tables_status'].get('property_physical', {}).get('exists', False):
            try:
                result = self.client.table('property_physical').select('area1, area2, area_exclusive, area_supply').limit(100).execute()
                data = result.data
                
                if data:
                    area1_filled = sum(1 for row in data if row.get('area1') is not None)
                    area2_filled = sum(1 for row in data if row.get('area2') is not None)
                    exclusive_filled = sum(1 for row in data if row.get('area_exclusive') is not None)
                    supply_filled = sum(1 for row in data if row.get('area_supply') is not None)
                    
                    total = len(data)
                    
                    mapping_effectiveness['area_fields'] = {
                        'area1_success_rate': round((area1_filled / total) * 100, 1) if total > 0 else 0,
                        'area2_success_rate': round((area2_filled / total) * 100, 1) if total > 0 else 0,
                        'area_exclusive_success_rate': round((exclusive_filled / total) * 100, 1) if total > 0 else 0,
                        'area_supply_success_rate': round((supply_filled / total) * 100, 1) if total > 0 else 0,
                        'sample_size': total
                    }
                    
                    print(f"   ğŸ“ area1 ì„±ê³µë¥ : {mapping_effectiveness['area_fields']['area1_success_rate']}%")
                    print(f"   ğŸ“ area2 ì„±ê³µë¥ : {mapping_effectiveness['area_fields']['area2_success_rate']}%")
                    print(f"   ğŸ“ ì „ìš©ë©´ì  ì„±ê³µë¥ : {mapping_effectiveness['area_fields']['area_exclusive_success_rate']}%")
                    print(f"   ğŸ“ ê³µê¸‰ë©´ì  ì„±ê³µë¥ : {mapping_effectiveness['area_fields']['area_supply_success_rate']}%")
                
            except Exception as e:
                mapping_effectiveness['area_fields'] = {'error': str(e)}
                print(f"   âŒ ë©´ì  í•„ë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # ì¹´ì¹´ì˜¤ ì£¼ì†Œ ë³€í™˜ íš¨ê³¼ í™•ì¸
        if self.verification_results['tables_status'].get('property_locations', {}).get('exists', False):
            try:
                result = self.client.table('property_locations').select('kakao_road_address, kakao_jibun_address, kakao_api_response').limit(100).execute()
                data = result.data
                
                if data:
                    kakao_road_filled = sum(1 for row in data if row.get('kakao_road_address') is not None)
                    kakao_jibun_filled = sum(1 for row in data if row.get('kakao_jibun_address') is not None)
                    kakao_response_filled = sum(1 for row in data if row.get('kakao_api_response') is not None)
                    
                    total = len(data)
                    
                    mapping_effectiveness['kakao_integration'] = {
                        'road_address_success_rate': round((kakao_road_filled / total) * 100, 1) if total > 0 else 0,
                        'jibun_address_success_rate': round((kakao_jibun_filled / total) * 100, 1) if total > 0 else 0,
                        'api_response_success_rate': round((kakao_response_filled / total) * 100, 1) if total > 0 else 0,
                        'sample_size': total
                    }
                    
                    print(f"   ğŸ—ºï¸ ì¹´ì¹´ì˜¤ ë„ë¡œëª…ì£¼ì†Œ ì„±ê³µë¥ : {mapping_effectiveness['kakao_integration']['road_address_success_rate']}%")
                    print(f"   ğŸ—ºï¸ ì¹´ì¹´ì˜¤ ì§€ë²ˆì£¼ì†Œ ì„±ê³µë¥ : {mapping_effectiveness['kakao_integration']['jibun_address_success_rate']}%")
                    print(f"   ğŸ—ºï¸ ì¹´ì¹´ì˜¤ API ì‘ë‹µ ì„±ê³µë¥ : {mapping_effectiveness['kakao_integration']['api_response_success_rate']}%")
                
            except Exception as e:
                mapping_effectiveness['kakao_integration'] = {'error': str(e)}
                print(f"   âŒ ì¹´ì¹´ì˜¤ ì£¼ì†Œ ë³€í™˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        self.verification_results['field_mapping_effectiveness'] = mapping_effectiveness
        return mapping_effectiveness
    
    def evaluate_schema_normalization_completeness(self) -> Dict[str, Any]:
        """ìŠ¤í‚¤ë§ˆ ì •ê·œí™” ì™„ë£Œë„ í‰ê°€"""
        print("\nğŸ—ï¸ 4. ìŠ¤í‚¤ë§ˆ ì •ê·œí™” ì™„ë£Œë„ í‰ê°€")
        print("=" * 60)
        
        # ì •ê·œí™” ìš”ì†Œ ì²´í¬ë¦¬ìŠ¤íŠ¸
        normalization_checklist = {
            'core_tables': {
                'weight': 30,
                'required': ['properties_new', 'property_locations', 'property_physical', 'property_prices'],
                'status': 'checking'
            },
            'reference_tables': {
                'weight': 20,
                'required': ['realtors', 'real_estate_types', 'trade_types', 'regions'],
                'status': 'checking'
            },
            'relationship_tables': {
                'weight': 15,
                'required': ['property_realtors', 'property_facilities'],
                'status': 'checking'
            },
            'operational_tables': {
                'weight': 10,
                'required': ['daily_stats', 'collection_logs', 'price_history'],
                'status': 'checking'
            },
            'advanced_features': {
                'weight': 15,
                'required': ['property_tax_info', 'property_price_comparison', 'property_images'],
                'status': 'checking'
            },
            'data_integrity': {
                'weight': 10,
                'required': ['foreign_keys', 'indexes', 'constraints'],
                'status': 'checking'
            }
        }
        
        total_score = 0
        max_score = sum(item['weight'] for item in normalization_checklist.values())
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ í‰ê°€
        for category, info in normalization_checklist.items():
            category_score = 0
            
            if category == 'data_integrity':
                # ë°ì´í„° ë¬´ê²°ì„±ì€ ë³„ë„ ë¡œì§ìœ¼ë¡œ í‰ê°€
                category_score = info['weight'] * 0.5  # ì„ì‹œë¡œ 50% ì ìˆ˜
                info['score'] = category_score
                info['completion_rate'] = 50.0
                print(f"   ğŸ”— {category}: 50.0% (ë°ì´í„° ë¬´ê²°ì„± ë¶€ë¶„ êµ¬í˜„)")
            else:
                existing_tables = []
                missing_tables = []
                
                for table in info['required']:
                    if self.verification_results['tables_status'].get(table, {}).get('exists', False):
                        existing_tables.append(table)
                    else:
                        missing_tables.append(table)
                
                completion_rate = (len(existing_tables) / len(info['required'])) * 100 if info['required'] else 0
                category_score = (completion_rate / 100) * info['weight']
                
                info['existing_tables'] = existing_tables
                info['missing_tables'] = missing_tables
                info['completion_rate'] = round(completion_rate, 1)
                info['score'] = round(category_score, 1)
                
                status_icon = "âœ…" if completion_rate == 100 else "âš ï¸" if completion_rate >= 50 else "âŒ"
                print(f"   {status_icon} {category}: {completion_rate}% ({len(existing_tables)}/{len(info['required'])})")
                
                if missing_tables:
                    print(f"      ëˆ„ë½: {', '.join(missing_tables)}")
            
            total_score += category_score
        
        overall_completion = round((total_score / max_score) * 100, 1)
        
        print(f"\nğŸ“Š ì „ì²´ ì •ê·œí™” ì™„ë£Œë„: {overall_completion}% ({total_score:.1f}/{max_score}ì )")
        
        completeness_result = {
            'overall_completion_percentage': overall_completion,
            'total_score': round(total_score, 1),
            'max_score': max_score,
            'category_breakdown': normalization_checklist,
            'assessment': self._get_completeness_assessment(overall_completion)
        }
        
        self.verification_results['schema_completeness'] = completeness_result
        return completeness_result
    
    def _get_completeness_assessment(self, completion_percentage: float) -> str:
        """ì™„ë£Œë„ì— ë”°ë¥¸ í‰ê°€ ë©”ì‹œì§€"""
        if completion_percentage >= 90:
            return "EXCELLENT - ì •ê·œí™”ê°€ ê±°ì˜ ì™„ë£Œë¨"
        elif completion_percentage >= 80:
            return "GOOD - ì£¼ìš” êµ¬ì¡°ëŠ” ì™„ë£Œ, ì¼ë¶€ ë³´ì™„ í•„ìš”"
        elif completion_percentage >= 70:
            return "FAIR - ê¸°ë³¸ êµ¬ì¡° ì™„ë£Œ, ì¶”ê°€ ì‘ì—… í•„ìš”"
        elif completion_percentage >= 50:
            return "POOR - ìƒë‹¹í•œ ì‘ì—…ì´ ë‚¨ì•„ìˆìŒ"
        else:
            return "CRITICAL - ëŒ€ë¶€ë¶„ì˜ ì •ê·œí™” ì‘ì—…ì´ í•„ìš”"
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ì¢…í•© ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
        print("\nğŸ“‹ 5. ì¢…í•© ê²€ì¦ ë³´ê³ ì„œ ìƒì„±")
        print("=" * 60)
        
        # ì „ì²´ì ì¸ í‰ê°€
        total_tables = len(self.verification_results['tables_status'])
        existing_tables = sum(1 for table_info in self.verification_results['tables_status'].values() 
                             if table_info.get('exists', False))
        tables_with_data = sum(1 for table_info in self.verification_results['tables_status'].values() 
                              if table_info.get('has_data', False))
        
        # ë°ì´í„° í’ˆì§ˆ ì¢…í•© ì ìˆ˜
        quality_scores = []
        for table_quality in self.verification_results['data_quality'].values():
            if isinstance(table_quality, dict) and 'quality_score' in table_quality:
                quality_scores.append(table_quality['quality_score'])
        
        avg_quality_score = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        
        # ì „ì²´ í‰ê°€
        overall_assessment = {
            'database_health': self._assess_database_health(existing_tables, total_tables, tables_with_data),
            'data_quality_grade': self._get_quality_grade(avg_quality_score),
            'schema_maturity': self._get_schema_maturity(self.verification_results['schema_completeness']['overall_completion_percentage']),
            'recommended_actions': self._get_recommended_actions()
        }
        
        self.verification_results['overall_assessment'] = overall_assessment
        
        # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
        report_filename = f"comprehensive_db_verification_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_path = Path(__file__).parent / report_filename
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.verification_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ ìƒì„¸ ë³´ê³ ì„œ ì €ì¥: {report_path}")
        
        return overall_assessment
    
    def _assess_database_health(self, existing_tables: int, total_tables: int, tables_with_data: int) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ ê±´ê°•ë„ í‰ê°€"""
        existence_rate = (existing_tables / total_tables) * 100 if total_tables > 0 else 0
        data_rate = (tables_with_data / total_tables) * 100 if total_tables > 0 else 0
        
        if existence_rate >= 90 and data_rate >= 70:
            return "HEALTHY"
        elif existence_rate >= 80 and data_rate >= 50:
            return "STABLE"
        elif existence_rate >= 70:
            return "DEVELOPING"
        else:
            return "CRITICAL"
    
    def _get_quality_grade(self, avg_score: float) -> str:
        """í’ˆì§ˆ ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰"""
        if avg_score >= 85:
            return "A"
        elif avg_score >= 70:
            return "B"
        elif avg_score >= 55:
            return "C"
        elif avg_score >= 40:
            return "D"
        else:
            return "F"
    
    def _get_schema_maturity(self, completion_percentage: float) -> str:
        """ìŠ¤í‚¤ë§ˆ ì„±ìˆ™ë„ í‰ê°€"""
        if completion_percentage >= 90:
            return "MATURE"
        elif completion_percentage >= 75:
            return "DEVELOPING"
        elif completion_percentage >= 50:
            return "INITIAL"
        else:
            return "EMBRYONIC"
    
    def _get_recommended_actions(self) -> List[str]:
        """ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­"""
        actions = []
        
        # ëˆ„ë½ëœ í…Œì´ë¸”ë“¤ í™•ì¸
        missing_tables = [name for name, info in self.verification_results['tables_status'].items() 
                         if not info.get('exists', False)]
        
        if missing_tables:
            actions.append(f"ëˆ„ë½ëœ í…Œì´ë¸” ìƒì„± í•„ìš”: {', '.join(missing_tables)}")
        
        # ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ
        for table_name, quality_info in self.verification_results['data_quality'].items():
            if isinstance(quality_info, dict) and 'quality_score' in quality_info:
                if quality_info['quality_score'] < 60:
                    actions.append(f"{table_name} í…Œì´ë¸” ë°ì´í„° í’ˆì§ˆ ê°œì„  í•„ìš”")
        
        # ì •ê·œí™” ì™„ë£Œë„
        completion_pct = self.verification_results['schema_completeness']['overall_completion_percentage']
        if completion_pct < 80:
            actions.append("ìŠ¤í‚¤ë§ˆ ì •ê·œí™” ì™„ì„± ì‘ì—… í•„ìš”")
        
        # í•„ë“œ ë§¤í•‘ íš¨ê³¼
        if 'field_mapping_effectiveness' in self.verification_results:
            area_success = self.verification_results['field_mapping_effectiveness'].get('area_fields', {}).get('area1_success_rate', 0)
            if area_success < 50:
                actions.append("API í•„ë“œ ë§¤í•‘ ë¡œì§ ì¬ê²€í†  í•„ìš”")
        
        if not actions:
            actions.append("í˜„ì¬ ìƒíƒœê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ ê¶Œì¥")
        
        return actions
    
    def print_executive_summary(self):
        """ê²½ì˜ì§„ ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸš€ ë„¤ì´ë²„ ë¶€ë™ì‚° DB ì¢…í•© ê²€ì¦ ê²°ê³¼ - ê²½ì˜ì§„ ìš”ì•½")
        print("="*80)
        
        # ê¸°ë³¸ í†µê³„
        total_tables = len(self.verification_results['tables_status'])
        existing_tables = sum(1 for info in self.verification_results['tables_status'].values() if info.get('exists', False))
        total_records = sum(info.get('record_count', 0) for info in self.verification_results['tables_status'].values() if info.get('exists', False))
        
        print(f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©:")
        print(f"   ğŸ—ï¸ í…Œì´ë¸”: {existing_tables}/{total_tables}ê°œ ì¡´ì¬")
        print(f"   ğŸ“ˆ ì´ ë ˆì½”ë“œ: {total_records:,}ê°œ")
        print(f"   ğŸ¥ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ: {self.verification_results['overall_assessment']['database_health']}")
        print(f"   ğŸ“‹ ìŠ¤í‚¤ë§ˆ ì™„ì„±ë„: {self.verification_results['schema_completeness']['overall_completion_percentage']}%")
        
        # ì£¼ìš” ì„±ê³¼
        print(f"\nğŸ¯ ì£¼ìš” ì„±ê³¼:")
        if total_records > 0:
            print(f"   âœ… {total_records:,}ê°œ ë¶€ë™ì‚° ë§¤ë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ë°ì´í„° í’ˆì§ˆ
        quality_scores = []
        for quality_info in self.verification_results['data_quality'].values():
            if isinstance(quality_info, dict) and 'quality_score' in quality_info:
                quality_scores.append(quality_info['quality_score'])
        
        if quality_scores:
            avg_quality = sum(quality_scores) / len(quality_scores)
            quality_grade = self.verification_results['overall_assessment']['data_quality_grade']
            print(f"   ğŸ“Š ë°ì´í„° í’ˆì§ˆ: {avg_quality:.1f}/100ì  ({quality_grade}ë“±ê¸‰)")
        
        # ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­
        print(f"\nğŸ”§ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­:")
        for i, action in enumerate(self.verification_results['overall_assessment']['recommended_actions'], 1):
            print(f"   {i}. {action}")
        
        print("\n" + "="*80)
        print(f"ğŸ“… ë³´ê³ ì„œ ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” Supabase ë°ì´í„°ë² ì´ìŠ¤ ì¢…í•© ê²€ì¦ ì‹œì‘")
    print("="*70)
    
    try:
        # ê²€ì¦ê¸° ì´ˆê¸°í™”
        verifier = ComprehensiveDBVerifier()
        
        # ìˆœì°¨ì ìœ¼ë¡œ ëª¨ë“  ê²€ì¦ ìˆ˜í–‰
        verifier.verify_table_existence_and_structure()
        verifier.analyze_data_quality()
        verifier.assess_field_mapping_effectiveness()
        verifier.evaluate_schema_normalization_completeness()
        verifier.generate_comprehensive_report()
        
        # ê²½ì˜ì§„ ìš”ì•½ ì¶œë ¥
        verifier.print_executive_summary()
        
        print(f"\nâœ… ì¢…í•© ê²€ì¦ ì™„ë£Œ!")
        print("ğŸ“‹ ìƒì„¸ ê²°ê³¼ëŠ” ìƒì„±ëœ JSON íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        return True
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        print(f"\nâŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)