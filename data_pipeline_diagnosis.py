#!/usr/bin/env python3
"""
ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì§„ë‹¨ ë„êµ¬
- enhanced_data_collector.pyì˜ 8ê°œ ì„¹ì…˜ ì²˜ë¦¬ flow ë¶„ì„
- ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ì´ìŠˆ ì§„ë‹¨
- NULL ê°’ ì „íŒŒ ê²½ë¡œ ì¶”ì 
- ì™¸ë˜í‚¤ ì¢…ì†ì„± ë¬¸ì œ ì‹ë³„
"""

import re
import ast
from pathlib import Path
from typing import Dict, List, Set, Any

class DataPipelineDiagnostic:
    def __init__(self):
        self.collector_path = Path("/Users/smgu/test_code/naver_land/enhanced_data_collector.py")
        self.issues = {
            'critical': [],
            'high': [], 
            'medium': [],
            'low': []
        }
        
    def analyze_data_flow(self):
        """8ê°œ ì„¹ì…˜ ë°ì´í„° í”Œë¡œìš° ë¶„ì„"""
        print("="*80)
        print("ğŸ” ë°ì´í„° íŒŒì´í”„ë¼ì¸ í”Œë¡œìš° ë¶„ì„")
        print("="*80)
        
        # 1. ì„¹ì…˜ ì²˜ë¦¬ ë©”ì„œë“œ ë¶„ì„
        sections = [
            'articleDetail', 'articleAddition', 'articleFacility', 'articleFloor',
            'articlePrice', 'articleRealtor', 'articleSpace', 'articleTax'
        ]
        
        process_methods = [
            '_process_article_detail', '_process_article_addition', '_process_article_facility',
            '_process_article_floor', '_process_article_price', '_process_article_realtor', 
            '_process_article_space', '_process_article_tax'
        ]
        
        save_methods = [
            '_save_property_basic', '_save_property_location', '_save_property_physical',
            '_save_property_prices', '_save_realtor_info', '_save_property_images',
            '_save_property_facilities', '_save_property_tax_info', '_save_property_price_comparison'
        ]
        
        print(f"ğŸ“Š ë°ì´í„° í”Œë¡œìš°: API Response â†’ 8ê°œ ì„¹ì…˜ ì²˜ë¦¬ â†’ 9ê°œ ì €ì¥ ë‹¨ê³„")
        print(f"   â”œâ”€â”€ ì…ë ¥: {len(sections)}ê°œ API ì„¹ì…˜")
        print(f"   â”œâ”€â”€ ì²˜ë¦¬: {len(process_methods)}ê°œ íŒŒì‹± ë©”ì„œë“œ")
        print(f"   â””â”€â”€ ì¶œë ¥: {len(save_methods)}ê°œ DB ì €ì¥ ë©”ì„œë“œ")
        
        return True
    
    def analyze_foreign_key_dependencies(self):
        """ì™¸ë˜í‚¤ ì¢…ì†ì„± ë¶„ì„"""
        print("\nğŸ”— ì™¸ë˜í‚¤ ì¢…ì†ì„± ë¶„ì„")
        print("-" * 50)
        
        # ì™¸ë˜í‚¤ í•´ê²° ë©”ì„œë“œë“¤
        fk_methods = [
            '_resolve_real_estate_type_id',
            '_resolve_trade_type_id', 
            '_resolve_region_id'
        ]
        
        critical_dependencies = {
            'properties_new': ['real_estate_type_id', 'trade_type_id', 'region_id'],
            'property_locations': ['region_id'],
            'realtors': ['region_id']
        }
        
        print("âŒ CRITICAL ISSUE: í•„ìˆ˜ ì™¸ë˜í‚¤ í•´ê²° ì‹¤íŒ¨")
        print("   ë¬¸ì œ: _resolve_*_id() ë©”ì„œë“œë“¤ì´ None ë°˜í™˜")
        print("   ê²°ê³¼: properties_new í…Œì´ë¸” ì‚½ì… ì‹¤íŒ¨")
        print("   ì˜í–¥: ì „ì²´ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
        
        self.issues['critical'].append({
            'type': 'foreign_key_dependency',
            'description': 'Foreign key resolution methods failing',
            'methods': fk_methods,
            'impact': 'Complete pipeline failure'
        })
        
        return False
    
    def analyze_kakao_integration(self):
        """ì¹´ì¹´ì˜¤ API í†µí•© ë¶„ì„"""
        print("\nğŸ—ºï¸ ì¹´ì¹´ì˜¤ ì£¼ì†Œ ë³€í™˜ í†µí•© ë¶„ì„")
        print("-" * 50)
        
        print("âœ… ì¹´ì¹´ì˜¤ ë³€í™˜ê¸° ë¡œë”©: ì„±ê³µ")
        print("âœ… ì¢Œí‘œ â†’ ìƒì„¸ì£¼ì†Œ ë³€í™˜: ì‘ë™")
        print("âŒ ISSUE: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")
        print("   ë¬¸ì œ: property_locations í…Œì´ë¸”ì˜ kakao_* ì»¬ëŸ¼ ëˆ„ë½")
        print("   í•„ìš” ì»¬ëŸ¼:")
        
        kakao_columns = [
            'kakao_road_address', 'kakao_jibun_address', 'kakao_building_name',
            'kakao_zone_no', 'kakao_api_response', 'address_enriched'
        ]
        
        for col in kakao_columns:
            print(f"     - {col}")
        
        self.issues['high'].append({
            'type': 'database_schema',
            'description': 'Kakao columns missing from property_locations table',
            'missing_columns': kakao_columns,
            'impact': 'Address enrichment data not saved'
        })
        
        return False
    
    def analyze_data_quality_issues(self):
        """ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ë¶„ì„"""
        print("\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ë¶„ì„")
        print("-" * 50)
        
        # ê¸°ë³¸ê°’ ë¬¸ì œ
        print("âš ï¸ DEFAULT VALUE ISSUES:")
        print("   - area1/area2: '10ã¡' ê¸°ë³¸ê°’ ì ìš© (ì‹¤ì œ ë°ì´í„° ìˆìŒì—ë„)")
        print("   - floor_current: '-1' ê¸°ë³¸ê°’")
        print("   - room_count: ê¸°ë³¸ê°’ìœ¼ë¡œ ì¸í•œ ì •í™•ë„ ì†ì‹¤")
        
        # NULL ì „íŒŒ ê²½ë¡œ
        print("\nğŸ”„ NULL ê°’ ì „íŒŒ ê²½ë¡œ:")
        print("   1. API Response íŒŒì‹± ì‹¤íŒ¨ â†’ NULL")
        print("   2. ì™¸ë˜í‚¤ í•´ê²° ì‹¤íŒ¨ â†’ ì „ì²´ ë ˆì½”ë“œ ì €ì¥ ì‹¤íŒ¨")
        print("   3. íƒ€ì… ë³€í™˜ ì˜¤ë¥˜ â†’ ê¸°ë³¸ê°’ ì ìš©")
        print("   4. ì˜ˆì™¸ ì²˜ë¦¬ë¡œ ì¸í•œ ë°ì´í„° ì†ì‹¤")
        
        self.issues['medium'].extend([
            {
                'type': 'default_values',
                'description': 'Incorrect default values masking real data',
                'impact': 'Data accuracy compromised'
            },
            {
                'type': 'null_propagation', 
                'description': 'NULL values cascading through pipeline',
                'impact': 'Data loss and quality degradation'
            }
        ])
        
        return False
    
    def analyze_error_handling(self):
        """ì˜¤ë¥˜ ì²˜ë¦¬ ë¶„ì„"""
        print("\nğŸš¨ ì˜¤ë¥˜ ì²˜ë¦¬ ë¶„ì„")
        print("-" * 50)
        
        print("âŒ PROBLEMATIC ERROR HANDLING:")
        print("   - try/except ë¸”ë¡ì´ ì‹¤ì œ ì˜¤ë¥˜ë¥¼ ë§ˆìŠ¤í‚¹")
        print("   - ì €ì¥ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´")
        print("   - ìƒì„¸í•œ ì˜¤ë¥˜ ë¡œê¹… ë¶€ì¡±")
        print("   - ì¬ì‹œë„ ë¡œì§ ì—†ìŒ")
        
        print("\nâœ… NEEDED IMPROVEMENTS:")
        print("   - ê° ë‹¨ê³„ë³„ ìƒì„¸ ë¡œê¹…")
        print("   - ì‹¤íŒ¨ ì‹œ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì •ë³´")
        print("   - ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜")
        print("   - ë°ì´í„° ê²€ì¦ ì²´í¬í¬ì¸íŠ¸")
        
        self.issues['high'].append({
            'type': 'error_handling',
            'description': 'Error handling masks real issues',
            'impact': 'Difficult debugging and data loss'
        })
        
        return False
    
    def generate_critical_fixes(self):
        """ê¸´ê¸‰ ìˆ˜ì •ì‚¬í•­ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ”§ CRITICAL FIXES REQUIRED")
        print("="*80)
        
        fixes = [
            {
                'priority': 'P0 - CRITICAL',
                'issue': 'Foreign Key Resolution Failure',
                'solution': 'Fix _resolve_*_id() methods to properly query reference tables',
                'code_location': 'Lines 1300+ in enhanced_data_collector.py',
                'impact': 'Enables basic data saving functionality'
            },
            {
                'priority': 'P1 - HIGH',
                'issue': 'Missing Kakao Columns',
                'solution': 'ALTER TABLE property_locations ADD COLUMN kakao_*',
                'code_location': 'Database schema update needed',
                'impact': 'Saves enriched address data'
            },
            {
                'priority': 'P1 - HIGH', 
                'issue': 'Reference Data Missing',
                'solution': 'Populate real_estate_types, trade_types, regions tables',
                'code_location': 'Database data initialization',
                'impact': 'Provides foreign key targets'
            },
            {
                'priority': 'P2 - MEDIUM',
                'issue': 'Default Value Logic',
                'solution': 'Remove premature default value application',
                'code_location': '_process_article_space() method',
                'impact': 'Improves data accuracy'
            }
        ]
        
        for i, fix in enumerate(fixes, 1):
            print(f"\n{i}. {fix['priority']}: {fix['issue']}")
            print(f"   Solution: {fix['solution']}")
            print(f"   Location: {fix['code_location']}")
            print(f"   Impact: {fix['impact']}")
            
        return fixes
    
    def analyze_performance_bottlenecks(self):
        """ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„"""
        print("\nâš¡ ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„")
        print("-" * 50)
        
        bottlenecks = [
            "ì™¸ë˜í‚¤ ì¡°íšŒë¥¼ ìœ„í•œ ë°˜ë³µì ì¸ DB ì¿¼ë¦¬ (ìºì‹± ì—†ìŒ)",
            "ê° ë§¤ë¬¼ë§ˆë‹¤ 9ë²ˆì˜ ê°œë³„ INSERT ì‘ì—…",
            "ì¹´ì¹´ì˜¤ API í˜¸ì¶œ ì‹œ ë™ê¸° ì²˜ë¦¬",
            "ëŒ€ìš©ëŸ‰ JSONB ë°ì´í„° ì €ì¥ ì‹œ ì„±ëŠ¥ ì €í•˜"
        ]
        
        for bottleneck in bottlenecks:
            print(f"   - {bottleneck}")
        
        return True
    
    def run_comprehensive_analysis(self):
        """ì¢…í•© ë¶„ì„ ì‹¤í–‰"""
        print("ğŸ” Enhanced Data Collector íŒŒì´í”„ë¼ì¸ ì§„ë‹¨")
        print("=" * 80)
        
        # ê° ë¶„ì„ ì‹¤í–‰
        self.analyze_data_flow()
        fk_ok = self.analyze_foreign_key_dependencies()  
        kakao_ok = self.analyze_kakao_integration()
        self.analyze_data_quality_issues()
        self.analyze_error_handling()
        self.analyze_performance_bottlenecks()
        
        # ê¸´ê¸‰ ìˆ˜ì •ì‚¬í•­
        critical_fixes = self.generate_critical_fixes()
        
        # ìš”ì•½
        print("\n" + "="*80)
        print("ğŸ“‹ ì§„ë‹¨ ìš”ì•½")
        print("="*80)
        
        total_issues = sum(len(issues) for issues in self.issues.values())
        print(f"ì´ ë°œê²¬ëœ ì´ìŠˆ: {total_issues}ê°œ")
        for severity, issues in self.issues.items():
            if issues:
                print(f"  {severity.upper()}: {len(issues)}ê°œ")
        
        # íŒŒì´í”„ë¼ì¸ ìƒíƒœ
        pipeline_health = "ğŸ”´ FAILED" if not fk_ok else "ğŸŸ¡ DEGRADED"
        print(f"\níŒŒì´í”„ë¼ì¸ ìƒíƒœ: {pipeline_health}")
        print(f"ë°ì´í„° ì†ì‹¤ë¥ : ì˜ˆìƒ 70-80% (ì™¸ë˜í‚¤ ì‹¤íŒ¨ë¡œ ì¸í•œ)")
        
        return critical_fixes

def main():
    diagnostic = DataPipelineDiagnostic()
    critical_fixes = diagnostic.run_comprehensive_analysis()
    
    print("\nğŸ¯ ì¦‰ì‹œ ì‹¤í–‰ ê¶Œì¥:")
    print("1. ì™¸ë˜í‚¤ í•´ê²° ë©”ì„œë“œ ìˆ˜ì •")
    print("2. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸")
    print("3. ì°¸ì¡° ë°ì´í„° ì´ˆê¸°í™”")
    print("4. ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ ")

if __name__ == "__main__":
    main()