import requests
import json
import time
import os
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from collections import defaultdict

class ClusterBasedCollector:
    """í´ëŸ¬ìŠ¤í„° APIë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ ë„¤ì´ë²„ ë¶€ë™ì‚° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, token_file="token.txt"):
        self.token_file = token_file
        self.token = None
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "*/*",
            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "Referer": "https://new.land.naver.com/offices"
        }
        self.cluster_url = "https://new.land.naver.com/api/articles/clusters"
        self.article_url = "https://new.land.naver.com/api/articles"
        self.collected_articles = {}  # ì¤‘ë³µ ì œê±°ìš©
        self.save_lock = threading.Lock()  # íŒŒì¼ ì €ì¥ ë™ê¸°í™”
        self.batch_size = 100  # ë°°ì¹˜ ì €ì¥ í¬ê¸°
        self.output_file = None
        
    def load_token(self):
        """ì €ì¥ëœ í† í° ë¡œë“œ"""
        if os.path.exists(self.token_file):
            try:
                with open(self.token_file, 'r') as f:
                    token = f.read().strip()
                    self.token = token
                    self.headers["authorization"] = f"Bearer {token}"
                    print(f"âœ“ í† í° ë¡œë“œ ì„±ê³µ")
                    return True
            except Exception as e:
                print(f"âœ— í† í° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    def get_clusters(self, bounds, zoom=15, real_estate_type="SMS"):
        """íŠ¹ì • ì˜ì—­ì˜ í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¡°íšŒ"""
        params = {
            "z": zoom,
            "lat": (bounds['north'] + bounds['south']) / 2,
            "lon": (bounds['east'] + bounds['west']) / 2,
            "bounds": f"{bounds['west']}:{bounds['south']}:{bounds['east']}:{bounds['north']}",
            "showR0": "true",
            "realEstateType": real_estate_type,
            "tradeType": "",
            "tag": ":::::::::",
            "rentPriceMin": "0",
            "rentPriceMax": "900000000",
            "priceMin": "0", 
            "priceMax": "900000000",
            "areaMin": "0",
            "areaMax": "900000000",
            "includeCortarNo": "false",
            "sameAddressGroup": "false"
        }
        
        try:
            response = requests.get(self.cluster_url, params=params, headers=self.headers)
            response.raise_for_status()
            data = response.json()
            
            clusters = []
            if 'data' in data and 'ARTICLE' in data['data']:
                for cluster in data['data']['ARTICLE']:
                    clusters.append({
                        'lat': cluster.get('lat'),
                        'lng': cluster.get('lgeo'),  
                        'count': cluster.get('count'),
                        'bounds': cluster.get('bounds'),  # í´ëŸ¬ìŠ¤í„° ë²”ìœ„
                        'cortarNo': cluster.get('cortarNo')
                    })
            
            return clusters
            
        except Exception as e:
            print(f"í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def get_articles_in_bounds(self, bounds, real_estate_type="SMS", max_pages=10):
        """íŠ¹ì • ì˜ì—­ ë‚´ ë§¤ë¬¼ ëª©ë¡ ì¡°íšŒ"""
        articles = []
        page = 1
        
        while page <= max_pages:
            params = {
                "order": "rank",
                "page": page,
                "realEstateType": real_estate_type,
                "tradeType": "",
                "tag": ":::::::::",
                "rentPriceMin": "0",
                "rentPriceMax": "900000000",
                "priceMin": "0",
                "priceMax": "900000000",
                "areaMin": "0",
                "areaMax": "900000000",
                "bounds": f"{bounds['west']}:{bounds['south']}:{bounds['east']}:{bounds['north']}",
                "showArticle": "false",
                "sameAddressGroup": "false",
                "showR0": "true"
            }
            
            try:
                response = requests.get(self.article_url, params=params, headers=self.headers)
                if response.status_code != 200:
                    break
                    
                data = response.json()
                page_articles = data.get('articleList', [])
                
                if not page_articles:
                    break
                    
                articles.extend(page_articles)
                
                if not data.get('isMoreData', False):
                    break
                    
                page += 1
                time.sleep(0.1)  # API ë¶€í•˜ ë°©ì§€
                
            except Exception as e:
                print(f"  ë§¤ë¬¼ ì¡°íšŒ ì˜¤ë¥˜ (í˜ì´ì§€ {page}): {e}")
                break
        
        return articles
    
    def save_batch(self, articles, is_final=False):
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ íŒŒì¼ ì €ì¥"""
        if not articles and not is_final:
            return
            
        with self.save_lock:
            # íŒŒì¼ëª… ì„¤ì • (ì²« ì €ì¥ì‹œ)
            if not self.output_file:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                self.output_file = f"cluster_collection_{timestamp}.json"
                
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            existing_data = []
            if os.path.exists(self.output_file):
                try:
                    with open(self.output_file, 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)
                except:
                    existing_data = []
            
            # ìƒˆ ë°ì´í„° ì¶”ê°€
            if articles:
                existing_data.extend(articles)
                
            # íŒŒì¼ ì €ì¥
            with open(self.output_file, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
                
            if articles:
                print(f"    ğŸ’¾ {len(articles)}ê°œ ì €ì¥ (ì „ì²´: {len(existing_data)}ê°œ)")
            
            if is_final:
                print(f"\nğŸ“ ìµœì¢… ì €ì¥ ì™„ë£Œ: {self.output_file}")
                print(f"   ì´ ë§¤ë¬¼: {len(existing_data)}ê°œ")
    
    def collect_cluster_area(self, cluster):
        """ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° ì˜ì—­ ìˆ˜ì§‘"""
        if cluster['count'] == 0:
            return []
            
        # í´ëŸ¬ìŠ¤í„° ë²”ìœ„ ì„¤ì •
        if cluster.get('bounds'):
            bounds = cluster['bounds']
        else:
            # ë²”ìœ„ê°€ ì—†ìœ¼ë©´ ì¤‘ì‹¬ì  ê¸°ì¤€ìœ¼ë¡œ ì‘ì€ ì˜ì—­ ì„¤ì •
            offset = 0.002  # ì•½ 200m
            bounds = {
                'west': cluster['lng'] - offset,
                'east': cluster['lng'] + offset,
                'south': cluster['lat'] - offset,
                'north': cluster['lat'] + offset
            }
        
        print(f"  ğŸ“ í´ëŸ¬ìŠ¤í„° ìˆ˜ì§‘: {cluster['count']}ê°œ ì˜ˆìƒ")
        articles = self.get_articles_in_bounds(bounds)
        
        # ì¤‘ë³µ ì œê±° ë° ìˆ˜ì§‘
        new_articles = []
        for article in articles:
            article_id = article.get('articleNo')
            if article_id and article_id not in self.collected_articles:
                self.collected_articles[article_id] = True
                new_articles.append(article)
        
        return new_articles
    
    def collect_by_clusters(self, center_lat, center_lng, radius_km=5, initial_zoom=13):
        """í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì „ì²´ ìˆ˜ì§‘"""
        print(f"\nğŸ” í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ìˆ˜ì§‘ ì‹œì‘")
        print(f"   ì¤‘ì‹¬: {center_lat}, {center_lng}")
        print(f"   ë°˜ê²½: {radius_km}km")
        
        # ì˜ì—­ ê³„ì‚° (1ë„ = ì•½ 111km)
        lat_offset = radius_km / 111
        lng_offset = radius_km / (111 * 0.8)  # ìœ„ë„ì— ë”°ë¥¸ ë³´ì •
        
        bounds = {
            'north': center_lat + lat_offset,
            'south': center_lat - lat_offset,
            'east': center_lng + lng_offset,
            'west': center_lng - lng_offset
        }
        
        # 1ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° íƒìƒ‰
        print(f"\n1ï¸âƒ£ í´ëŸ¬ìŠ¤í„° íƒìƒ‰ (ì¤Œ ë ˆë²¨ {initial_zoom})")
        clusters = self.get_clusters(bounds, zoom=initial_zoom)
        print(f"   ë°œê²¬ëœ í´ëŸ¬ìŠ¤í„°: {len(clusters)}ê°œ")
        
        if not clusters:
            print("   í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¤Œ ë ˆë²¨ì„ ì¡°ì •í•´ë³´ì„¸ìš”.")
            return
        
        # í´ëŸ¬ìŠ¤í„° í†µê³„
        total_expected = sum(c['count'] for c in clusters)
        print(f"   ì˜ˆìƒ ë§¤ë¬¼ ìˆ˜: {total_expected}ê°œ")
        
        # 2ë‹¨ê³„: ë³‘ë ¬ ìˆ˜ì§‘
        print(f"\n2ï¸âƒ£ ë§¤ë¬¼ ìˆ˜ì§‘ ì‹œì‘ (ë³‘ë ¬ ì²˜ë¦¬)")
        batch_articles = []
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_cluster = {
                executor.submit(self.collect_cluster_area, cluster): cluster 
                for cluster in clusters
            }
            
            completed = 0
            for future in as_completed(future_to_cluster):
                completed += 1
                try:
                    new_articles = future.result()
                    if new_articles:
                        batch_articles.extend(new_articles)
                        
                        # ë°°ì¹˜ ì €ì¥
                        if len(batch_articles) >= self.batch_size:
                            self.save_batch(batch_articles)
                            batch_articles = []
                            
                    print(f"   ì§„í–‰: {completed}/{len(clusters)} í´ëŸ¬ìŠ¤í„°")
                    
                except Exception as e:
                    print(f"   í´ëŸ¬ìŠ¤í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        
        # ë‚¨ì€ ë°ì´í„° ì €ì¥
        if batch_articles:
            self.save_batch(batch_articles)
            
        # ìµœì¢… ì €ì¥
        self.save_batch([], is_final=True)
        
        print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"   ìˆ˜ì§‘ëœ ë§¤ë¬¼: {len(self.collected_articles)}ê°œ")
        print(f"   ì¤‘ë³µ ì œê±°: {total_expected - len(self.collected_articles)}ê°œ")
    
    def collect_by_grid(self, bounds, grid_size=0.005):
        """ê²©ì ë¶„í•  ë°©ì‹ ìˆ˜ì§‘"""
        print(f"\nğŸ”² ê²©ì ë¶„í•  ìˆ˜ì§‘ ì‹œì‘")
        print(f"   ê²©ì í¬ê¸°: {grid_size} (ì•½ {grid_size * 111:.1f}km)")
        
        lat_steps = int((bounds['north'] - bounds['south']) / grid_size)
        lng_steps = int((bounds['east'] - bounds['west']) / grid_size)
        total_grids = lat_steps * lng_steps
        
        print(f"   ê²©ì ìˆ˜: {lat_steps} x {lng_steps} = {total_grids}ê°œ")
        
        batch_articles = []
        grid_count = 0
        
        for lat_idx in range(lat_steps):
            for lng_idx in range(lng_steps):
                grid_count += 1
                
                # ê²©ì ì˜ì—­ ê³„ì‚°
                grid_bounds = {
                    'south': bounds['south'] + lat_idx * grid_size,
                    'north': bounds['south'] + (lat_idx + 1) * grid_size,
                    'west': bounds['west'] + lng_idx * grid_size,
                    'east': bounds['west'] + (lng_idx + 1) * grid_size
                }
                
                print(f"\nê²©ì {grid_count}/{total_grids} ìˆ˜ì§‘ ì¤‘...")
                articles = self.get_articles_in_bounds(grid_bounds, max_pages=5)
                
                # ì¤‘ë³µ ì œê±° ë° ìˆ˜ì§‘
                new_articles = []
                for article in articles:
                    article_id = article.get('articleNo')
                    if article_id and article_id not in self.collected_articles:
                        self.collected_articles[article_id] = True
                        new_articles.append(article)
                        batch_articles.append(article)
                
                print(f"  +{len(new_articles)}ê°œ (ì „ì²´: {len(self.collected_articles)}ê°œ)")
                
                # ë°°ì¹˜ ì €ì¥
                if len(batch_articles) >= self.batch_size:
                    self.save_batch(batch_articles)
                    batch_articles = []
                    
                time.sleep(0.2)  # API ë¶€í•˜ ë°©ì§€
        
        # ë‚¨ì€ ë°ì´í„° ì €ì¥
        if batch_articles:
            self.save_batch(batch_articles)
            
        # ìµœì¢… ì €ì¥
        self.save_batch([], is_final=True)
        
        print(f"\nâœ… ê²©ì ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"   ìˆ˜ì§‘ëœ ë§¤ë¬¼: {len(self.collected_articles)}ê°œ")


def main():
    print("ğŸ¢ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ë„¤ì´ë²„ ë¶€ë™ì‚° ìˆ˜ì§‘ê¸°")
    print("=" * 50)
    
    collector = ClusterBasedCollector()
    
    # í† í° ë¡œë“œ
    if not collector.load_token():
        print("âŒ í† í°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í† í°ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    print("\nìˆ˜ì§‘ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ìˆ˜ì§‘ (ì¶”ì²œ)")
    print("2. ê²©ì ë¶„í•  ìˆ˜ì§‘")
    print("3. íŠ¹ì • ì§€ì—­ ì§‘ì¤‘ ìˆ˜ì§‘")
    
    choice = input("\nì„ íƒ (1-3): ").strip()
    
    if choice == "1":
        # í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ìˆ˜ì§‘ - ê°•ë‚¨ì—­ ì¤‘ì‹¬ ì˜ˆì‹œ
        print("\nì¤‘ì‹¬ ì¢Œí‘œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸: ê°•ë‚¨ì—­)")
        lat = input("ìœ„ë„ (ê¸°ë³¸: 37.498): ").strip() or "37.498"
        lng = input("ê²½ë„ (ê¸°ë³¸: 127.028): ").strip() or "127.028"
        radius = input("ë°˜ê²½(km, ê¸°ë³¸: 3): ").strip() or "3"
        
        collector.collect_by_clusters(
            float(lat), float(lng), 
            radius_km=float(radius),
            initial_zoom=14
        )
        
    elif choice == "2":
        # ê²©ì ë¶„í•  ìˆ˜ì§‘ - ê°•ë‚¨êµ¬ ì „ì²´
        bounds = {
            'north': 37.5326,
            'south': 37.4715,
            'east': 127.0796,
            'west': 127.0164
        }
        collector.collect_by_grid(bounds, grid_size=0.005)
        
    elif choice == "3":
        # íŠ¹ì • ì§€ì—­ ì§‘ì¤‘
        print("\nì˜ì—­ ì¢Œí‘œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
        north = float(input("ë¶ìª½ ìœ„ë„: "))
        south = float(input("ë‚¨ìª½ ìœ„ë„: "))
        east = float(input("ë™ìª½ ê²½ë„: "))
        west = float(input("ì„œìª½ ê²½ë„: "))
        
        bounds = {'north': north, 'south': south, 'east': east, 'west': west}
        articles = collector.get_articles_in_bounds(bounds, max_pages=50)
        
        # ì €ì¥
        collector.collected_articles = {a['articleNo']: True for a in articles}
        collector.save_batch(articles, is_final=True)
        
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()