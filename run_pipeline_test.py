#!/usr/bin/env python3
"""
Run Pipeline Test - Comprehensive NULL data issue debugging
Tests the complete pipeline from API to Database with enhanced processing
"""

import sys
import os
import json
from datetime import datetime, date

# Add collectors path
sys.path.append('/Users/smgu/test_code/naver_land/collectors')

from archived.fixed_naver_collector_v2_optimized import CachedTokenCollector
from db.enhanced_supabase_client import EnhancedSupabaseHelper
from core.enhanced_data_processor import EnhancedDataProcessor

def test_complete_pipeline(cortar_no: str = "1168010100", max_properties: int = 5):
    """Test complete pipeline with enhanced processing"""
    
    print("üöÄ Complete Pipeline Test with Enhanced Processing")
    print("=" * 80)
    print(f"üìç Testing cortar_no: {cortar_no}")
    print(f"üìä Max properties: {max_properties}")
    print(f"‚è∞ Test time: {datetime.now().isoformat()}")
    
    # Phase 1: API Collection
    print("\nüîç Phase 1: API Collection Test")
    print("-" * 40)
    
    try:
        collector = CachedTokenCollector()
        
        if not collector.ensure_valid_token():
            print("‚ùå Token acquisition failed")
            return False
        
        print("‚úÖ Token acquired successfully")
        
        # Test article list API
        articles = test_article_list_api(collector, cortar_no, max_properties)
        if not articles:
            print("‚ùå No articles from API")
            return False
            
        print(f"‚úÖ Got {len(articles)} articles from API")
        
        # Get detailed information for articles
        detailed_articles = []
        for i, article in enumerate(articles):
            article_no = article.get('articleNo')
            if article_no:
                print(f"  üìÑ Getting details for article {i+1}: {article_no}")
                
                # Get detailed API response
                detail_response = collector.get_article_detail(article_no)
                if detail_response:
                    # Extract useful details
                    useful_details = collector.extract_useful_details(detail_response)
                    
                    # Combine article with details
                    combined = article.copy()
                    combined['ÏÉÅÏÑ∏Ï†ïÎ≥¥'] = useful_details
                    detailed_articles.append(combined)
                    
                    print(f"    ‚úÖ Details extracted: {len(str(useful_details))} chars")
                else:
                    print(f"    ‚ùå No details for {article_no}")
                    # Still add article without details
                    detailed_articles.append(article)
        
        print(f"‚úÖ Phase 1 Complete: {len(detailed_articles)} articles with details")
        
    except Exception as e:
        print(f"‚ùå Phase 1 failed: {e}")
        return False
    
    # Phase 2: Enhanced Data Processing
    print("\nüîß Phase 2: Enhanced Data Processing")
    print("-" * 40)
    
    try:
        processor = EnhancedDataProcessor()
        processed_properties = []
        
        for i, article in enumerate(detailed_articles):
            print(f"  üîÑ Processing article {i+1}: {article.get('articleNo')}")
            
            # Convert API format to expected format
            converted_article = convert_api_format(article)
            
            # Process with enhanced processor
            processed_prop = processor.process_collected_property(converted_article, cortar_no)
            
            if processed_prop:
                processed_properties.append(processed_prop)
                print(f"    ‚úÖ Successfully processed")
                
                # Show sample of extracted data
                if i == 0:  # Show details for first property
                    print(f"    üìä Sample data:")
                    print(f"      - ID: {processed_prop['article_no']}")
                    print(f"      - Name: {processed_prop['article_name']}")
                    print(f"      - Type: {processed_prop['real_estate_type']}")
                    print(f"      - Trade: {processed_prop['trade_type']}")
                    print(f"      - Price: {processed_prop['price']}")
                    print(f"      - Area: {processed_prop['area1']}")
                    print(f"      - Address: {processed_prop.get('address_road', 'N/A')}")
            else:
                print(f"    ‚ùå Processing failed")
        
        # Show processing statistics
        stats = processor.get_validation_stats()
        print(f"\nüìä Processing Statistics:")
        print(f"  - Total processed: {stats['total_processed']}")
        print(f"  - Successful: {stats['successful_extractions']}")
        print(f"  - Price parsing failures: {stats['price_parsing_failures']}")
        print(f"  - Area parsing failures: {stats['area_parsing_failures']}")
        
        if stats['field_extraction_failures']:
            print(f"  - Field extraction failures:")
            for field, count in stats['field_extraction_failures'].items():
                print(f"    ‚Ä¢ {field}: {count}")
        
        print(f"‚úÖ Phase 2 Complete: {len(processed_properties)} properties processed")
        
    except Exception as e:
        print(f"‚ùå Phase 2 failed: {e}")
        return False
    
    # Phase 3: Enhanced Database Insertion
    print("\nüíæ Phase 3: Enhanced Database Insertion")
    print("-" * 40)
    
    try:
        enhanced_client = EnhancedSupabaseHelper()
        
        # Use the original detailed articles (not the processed ones)
        # This tests the full enhanced processing pipeline
        result = enhanced_client.save_properties_with_enhanced_processing(
            detailed_articles, cortar_no, debug_mode=True
        )
        
        if result['success']:
            summary = result['summary']
            print(f"‚úÖ Database insertion successful:")
            print(f"  - Raw input: {summary['raw_input']}")
            print(f"  - Successfully processed: {summary['successfully_processed']}")
            print(f"  - Processing failures: {summary['processing_failures']}")
            print(f"  - New properties: {summary['new_properties']}")
            print(f"  - Updated properties: {summary['updated_properties']}")
            print(f"  - Insertion errors: {summary['insertion_errors']}")
            
            if result['processing_errors']:
                print(f"‚ö†Ô∏è Processing errors found:")
                for error in result['processing_errors'][:3]:  # Show first 3
                    print(f"  - {error}")
            
        else:
            print(f"‚ùå Database insertion failed: {result.get('error')}")
            return False
        
        print(f"‚úÖ Phase 3 Complete")
        
    except Exception as e:
        print(f"‚ùå Phase 3 failed: {e}")
        return False
    
    # Phase 4: Data Quality Validation
    print("\nüìä Phase 4: Data Quality Validation")
    print("-" * 40)
    
    try:
        quality_report = enhanced_client.validate_data_quality(cortar_no, days_back=1)
        
        if 'error' not in quality_report:
            print(f"üìà Data Quality Report:")
            print(f"  - Total properties: {quality_report['total_properties']}")
            print(f"  - Data quality score: {quality_report['data_quality_score']}%")
            print(f"  - Date range: {quality_report['date_range']}")
            
            # Show NULL analysis for key fields
            null_analysis = quality_report['null_analysis']
            critical_fields = ['article_no', 'article_name', 'real_estate_type', 'price']
            
            print(f"\nüìã Critical Field Analysis:")
            for field in critical_fields:
                if field in null_analysis:
                    analysis = null_analysis[field]
                    print(f"  - {field}: {analysis['null_percentage']}% NULL ({analysis['null_count']}/{quality_report['total_properties']})")
            
            quality_summary = quality_report['summary']
            if quality_summary['excellent']:
                print(f"üéØ Quality Assessment: EXCELLENT (‚â•95%)")
            elif quality_summary['good']:
                print(f"‚ö†Ô∏è Quality Assessment: GOOD (90-95%)")
            else:
                print(f"‚ùå Quality Assessment: NEEDS IMPROVEMENT (<90%)")
        else:
            print(f"‚ùå Quality validation failed: {quality_report['error']}")
        
        print(f"‚úÖ Phase 4 Complete")
        
    except Exception as e:
        print(f"‚ùå Phase 4 failed: {e}")
        return False
    
    # Summary
    print("\nüéØ PIPELINE TEST SUMMARY")
    print("=" * 80)
    print("‚úÖ All phases completed successfully!")
    print(f"üìä Processed {len(detailed_articles)} articles end-to-end")
    print(f"üíæ Database operations completed with enhanced validation")
    print(f"üîç Data quality analysis completed")
    
    # Save detailed log
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = f"pipeline_test_log_{timestamp}.json"
    
    test_log = {
        'timestamp': timestamp,
        'cortar_no': cortar_no,
        'max_properties': max_properties,
        'phase_1_articles': len(articles),
        'phase_2_processed': len(processed_properties),
        'phase_3_result': result if 'result' in locals() else None,
        'phase_4_quality': quality_report if 'quality_report' in locals() else None
    }
    
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(test_log, f, ensure_ascii=False, indent=2)
    
    print(f"üìù Detailed log saved: {log_file}")
    
    return True

def test_article_list_api(collector, cortar_no: str, max_count: int):
    """Test article list API"""
    import requests
    
    url = "https://new.land.naver.com/api/articles"
    headers = collector.setup_headers()
    
    params = {
        'cortarNo': cortar_no,
        'order': 'rank',
        'realEstateType': 'SG:SMS:GJCG:APTHGJ:GM:TJ',
        'tradeType': '',
        'tag': '::::::::',
        'rentPriceMin': '0',
        'rentPriceMax': '900000000',
        'priceMin': '0',
        'priceMax': '900000000',
        'areaMin': '0',
        'areaMax': '900000000',
        'oldBuildYears': '',
        'recentlyBuildYears': '',
        'minHouseHoldCount': '',
        'maxHouseHoldCount': '',
        'showArticle': 'false',
        'sameAddressGroup': 'false',
        'minMaintenanceCost': '',
        'maxMaintenanceCost': '',
        'priceType': 'RETAIL',
        'directions': '',
        'articleState': '',
        'page': 1
    }
    
    try:
        response = requests.get(url, headers=headers, params=params,
                              cookies=collector.cookies, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            articles = data.get('articleList', [])
            return articles[:max_count]
        else:
            print(f"API failed: {response.status_code}")
            return []
            
    except Exception as e:
        print(f"API error: {e}")
        return []

def convert_api_format(api_article):
    """Convert API format to expected format"""
    return {
        'Îß§Î¨ºÎ≤àÌò∏': api_article.get('articleNo'),
        'Îß§Î¨ºÎ™Ö': api_article.get('articleName'),
        'Î∂ÄÎèôÏÇ∞ÌÉÄÏûÖ': api_article.get('realEstateTypeName'),
        'Í±∞ÎûòÌÉÄÏûÖ': api_article.get('tradeTypeName'),
        'Îß§Îß§Í∞ÄÍ≤©': api_article.get('dealOrWarrantPrc', ''),
        'ÏõîÏÑ∏': api_article.get('rentPrc', ''),
        'Ï†ÑÏö©Î©¥Ï†Å': api_article.get('area1'),
        'Í≥µÍ∏âÎ©¥Ï†Å': api_article.get('area2'),
        'Ï∏µÏ†ïÎ≥¥': api_article.get('floorInfo'),
        'Î∞©Ìñ•': api_article.get('direction'),
        'Ï£ºÏÜå': api_article.get('address', ''),
        'ÏÉÅÏÑ∏Ï£ºÏÜå': api_article.get('buildingName', ''),
        'Îì±Î°ùÏùº': api_article.get('articleConfirmYMD'),
        'ÌÉúÍ∑∏': api_article.get('tagList', []),
        'ÏÑ§Î™Ö': api_article.get('articleFeatureDesc', ''),
        'ÏÉÅÏÑ∏Ï†ïÎ≥¥': api_article.get('ÏÉÅÏÑ∏Ï†ïÎ≥¥', {})
    }

def main():
    """Main test function"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Test complete data pipeline')
    parser.add_argument('--cortar-no', type=str, default='1168010100',
                       help='Cortar number to test (default: Ïó≠ÏÇºÎèô)')
    parser.add_argument('--max-properties', type=int, default=5,
                       help='Maximum properties to test (default: 5)')
    
    args = parser.parse_args()
    
    success = test_complete_pipeline(args.cortar_no, args.max_properties)
    
    if success:
        print("\nüéâ Pipeline test completed successfully!")
        sys.exit(0)
    else:
        print("\nüí• Pipeline test failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()