#!/usr/bin/env python3
"""
ë§¤ë¬¼ ìˆ˜ì§‘ ì„œë¹„ìŠ¤ - ì „ì²´ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì¡°ìœ¨
"""

from typing import List, Dict, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from datetime import datetime
from collectors.naver_api_client import NaverAPIClient
from parsers.article_parser import ArticleParser
from database.optimized_repository import OptimizedPropertyRepository
from services.address_service import AddressService
from config.settings import settings

class CollectionService:
    def __init__(self):
        self.api_client = NaverAPIClient()
        self.parser = ArticleParser()
        self.repository = OptimizedPropertyRepository()
        
        try:
            self.address_service = AddressService()
            self.address_enabled = True
        except ValueError as e:
            print(f"âš ï¸ ì£¼ì†Œ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")
            self.address_enabled = False
        
        self.collection_stats = {
            'total_processed': 0,
            'successful_collections': 0,
            'parsing_failures': 0,
            'save_failures': 0,
            'start_time': None,
            'estimated_completion': None
        }
    
    def collect_single_article(self, article_no: str, quiet: bool = False) -> bool:
        self.collection_stats['total_processed'] += 1
        if not quiet:
            print(f"ğŸ” ë§¤ë¬¼ {article_no} ìƒì„¸ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        
        try:
            raw_data = self.api_client.get_article_detail(article_no)
            if not raw_data:
                print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {article_no}")
                return False
            
            if not quiet:
                print(f"ğŸ“ ë§¤ë¬¼ {article_no} ë°ì´í„° íŒŒì‹± ì¤‘...")
            parsed_data = self.parser.parse_article_detail(raw_data, article_no)
            if not parsed_data:
                if not quiet:
                    print(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {article_no}")
                self.collection_stats['parsing_failures'] += 1
                return False
            
            if self.address_enabled and 'articleDetail' in parsed_data.get('sections', {}):
                self._enrich_with_address_data(parsed_data)
            
            # ë§¤ë¬¼ ê²€ì¦ ë° is_active ì„¤ì •
            self._validate_and_set_active_status(parsed_data, quiet)
            
            if not quiet:
                print(f"ğŸ’¾ ë§¤ë¬¼ {article_no} ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
            success = self.repository.save_property(parsed_data)
            if success:
                self.collection_stats['successful_collections'] += 1
                if not quiet:
                    print(f"âœ… ë§¤ë¬¼ {article_no} ì €ì¥ ì™„ë£Œ!")
                return True
            else:
                self.collection_stats['save_failures'] += 1
                if not quiet:
                    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {article_no}")
                return False
                
        except Exception as e:
            print(f"âŒ Error processing article {article_no}: {e}")
            return False
    
    def collect_area_articles(self, cortar_no: str, max_pages: int = None) -> List[str]:
        collected_articles = []
        page = 1
        
        while True:
            if max_pages and page > max_pages:
                break
                
            print(f"ğŸ” ìˆ˜ì§‘ ì¤‘: ì§€ì—­ {cortar_no}, í˜ì´ì§€ {page}")
            
            response = self.api_client.get_area_articles(cortar_no, page)  # ì‚¬ë¬´ì‹¤ë§Œ ìˆ˜ì§‘ (ìƒê°€ ì œì™¸)
            if not response or 'articleList' not in response:
                print(f"âŒ No more articles found for area {cortar_no}")
                break
            
            articles = response['articleList']
            if not articles:
                print(f"âœ… No more articles on page {page}")
                break
            
            page_articles = []
            for article in articles:
                article_no = article.get('articleNo')
                if article_no:
                    page_articles.append(str(article_no))
            
            if not page_articles:
                break
            
            collected_articles.extend(page_articles)
            print(f"ğŸ“„ í˜ì´ì§€ {page}: {len(page_articles)}ê°œ ë§¤ë¬¼ ë°œê²¬")
            
            page += 1
        
        print(f"ğŸ“Š ì§€ì—­ {cortar_no} ì´ {len(collected_articles)}ê°œ ë§¤ë¬¼ ë°œê²¬")
        return collected_articles
    
    def collect_and_save_area(self, cortar_no: str, max_pages: int = None, max_articles: int = None) -> Dict[str, Any]:
        print(f"ğŸš€ ì§€ì—­ {cortar_no} ìˆ˜ì§‘ ì‹œì‘")
        
        successful_collections = 0
        total_processed = 0
        page = 1
        
        while True:
            if max_pages and page > max_pages:
                break
                
            print(f"ğŸ” ìˆ˜ì§‘ ì¤‘: ì§€ì—­ {cortar_no}, í˜ì´ì§€ {page}")
            
            response = self.api_client.get_area_articles(cortar_no, page)  # ì‚¬ë¬´ì‹¤ë§Œ ìˆ˜ì§‘ (ìƒê°€ ì œì™¸)
            if not response or 'articleList' not in response:
                print(f"âŒ No more articles found for area {cortar_no}")
                break
            
            articles = response['articleList']
            if not articles:
                print(f"âœ… No more articles on page {page}")
                break
            
            page_articles = []
            for article in articles:
                article_no = article.get('articleNo')
                if article_no:
                    page_articles.append(str(article_no))
            
            if not page_articles:
                break
            
            print(f"ğŸ“„ í˜ì´ì§€ {page}: {len(page_articles)}ê°œ ë§¤ë¬¼ ë°œê²¬")
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìƒì„¸ì •ë³´ ìˆ˜ì§‘ ë° ì €ì¥
            articles_to_process = page_articles[:max_articles - total_processed] if max_articles else page_articles
            
            if not self.collection_stats['start_time']:
                self.collection_stats['start_time'] = time.time()
            
            page_successful = self._collect_articles_parallel(articles_to_process, total_processed + 1, max_articles)
            
            successful_collections += page_successful
            total_processed += len(articles_to_process)
            
            # ì§„í–‰ë¥  ë° ETA ì¶œë ¥
            self._print_progress_with_eta(total_processed, successful_collections, max_articles)
            
            if max_articles and total_processed >= max_articles:
                break
                
            page += 1
        
        return {
            'area_code': cortar_no,
            'total_found': total_processed,
            'successful_collections': successful_collections,
            'success_rate': f"{(successful_collections / total_processed * 100):.2f}%" if total_processed else "0%",
            'api_stats': self.api_client.get_request_stats(),
            'parsing_stats': self.parser.get_parsing_stats(),
            'save_stats': self.repository.get_save_stats()
        }
    
    def _enrich_with_address_data(self, parsed_data: Dict):
        article_detail = parsed_data.get('sections', {}).get('articleDetail', {})
        latitude = article_detail.get('latitude')
        longitude = article_detail.get('longitude')
        
        if latitude and longitude:
            try:
                address_info = self.address_service.convert_coordinates_to_address(latitude, longitude)
                if address_info:
                    if 'address_info' not in article_detail:
                        article_detail['address_info'] = {}
                    article_detail['address_info'].update(address_info)
                    print(f"âœ… ì£¼ì†Œ ì •ë³´ ì¶”ê°€ë¨: {address_info.get('primary_address', 'N/A')}")
            except Exception as e:
                print(f"âš ï¸ ì£¼ì†Œ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def _validate_and_set_active_status(self, parsed_data: Dict, quiet: bool = False):
        """ë§¤ë¬¼ ë°ì´í„° ê²€ì¦ í›„ is_active ìƒíƒœ ì„¤ì •"""
        if not settings.validation_rules['validation_enabled']:
            if not quiet:
                print("ğŸ”§ ë§¤ë¬¼ ê²€ì¦ ë¹„í™œì„±í™”ë¨")
            return
        
        is_active = True
        rejection_reasons = []
        
        # articleDetail, articlePrice ì„¹ì…˜ ê°€ì ¸ì˜¤ê¸°
        sections = parsed_data.get('sections', {})
        article_detail = sections.get('articleDetail', {})
        article_price = sections.get('articlePrice', {})
        
        # 1. ê±°ë˜ìœ í˜• ê²€ì¦ (ì „ì„¸/ë§¤ë§¤/ë‹¨ê¸°ì„ëŒ€ ì œì™¸)
        trade_type = article_detail.get('tradeTypeCd')
        if trade_type in settings.validation_rules['excluded_trade_types']:
            is_active = False
            rejection_reasons.append(f"ì œì™¸ëœ ê±°ë˜ìœ í˜•: {trade_type}")
        
        # 2. ë³´ì¦ê¸ˆ ê²€ì¦
        deposit = article_price.get('dealOrWarrantPrc', 0)
        if isinstance(deposit, str):
            deposit = int(deposit) if deposit.isdigit() else 0
        
        deposit_limits = settings.validation_rules['deposit_limits']
        if deposit < deposit_limits['min'] or deposit > deposit_limits['max']:
            is_active = False
            rejection_reasons.append(f"ë³´ì¦ê¸ˆ ë²”ìœ„ ë²—ì–´ë‚¨: {deposit:,}ì›")
        
        # 3. ì›”ì„¸ ê²€ì¦
        rent = article_price.get('rentPrc', 0)
        if isinstance(rent, str):
            rent = int(rent) if rent.isdigit() else 0
        
        rent_limits = settings.validation_rules['monthly_rent_limits']
        if rent < rent_limits['min'] or rent > rent_limits['max']:
            is_active = False
            rejection_reasons.append(f"ì›”ì„¸ ë²”ìœ„ ë²—ì–´ë‚¨: {rent:,}ì›")
        
        # 4. ì—˜ë¦¬ë² ì´í„° ê²€ì¦
        if settings.validation_rules['elevator_required']:
            elevator_count = article_detail.get('elevatorNum')
            if elevator_count is None or elevator_count == 0:
                is_active = False
                rejection_reasons.append("ì—˜ë¦¬ë² ì´í„° ì—†ìŒ")
        
        # is_active ì„¤ì •
        if 'metadata' not in parsed_data:
            parsed_data['metadata'] = {}
        parsed_data['metadata']['is_active'] = is_active
        
        # ë¡œê·¸ ì¶œë ¥
        if not quiet:
            if not is_active:
                print(f"âš ï¸ ë§¤ë¬¼ ë¹„í™œì„±í™”: {', '.join(rejection_reasons)}")
            else:
                print(f"âœ… ë§¤ë¬¼ ê²€ì¦ í†µê³¼")
    
    def _collect_articles_parallel(self, article_nos: List[str], start_idx: int, max_articles: Optional[int]) -> int:
        """ë³‘ë ¬ë¡œ ë§¤ë¬¼ë“¤ì„ ìˆ˜ì§‘í•˜ì—¬ ì„±ê³µí•œ ê°œìˆ˜ ë°˜í™˜"""
        max_workers = settings.collection_settings['parallel_workers']
        successful_count = 0
        
        # ì—°ê²° í’€ ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬
        batch_size = max_workers * 2  # ì›Œì»¤ ìˆ˜ì˜ 2ë°°ì”© ë°°ì¹˜ ì²˜ë¦¬
        
        for i in range(0, len(article_nos), batch_size):
            batch_articles = article_nos[i:i + batch_size]
            batch_successful = self._process_batch(batch_articles, max_workers)
            successful_count += batch_successful
            
            # ë°°ì¹˜ ê°„ ì§§ì€ íœ´ì‹ (ì—°ê²° í’€ ì•ˆì •í™”)
            if i + batch_size < len(article_nos):
                time.sleep(1)
        
        return successful_count
    
    def _process_batch(self, article_nos: List[str], max_workers: int) -> int:
        """ë‹¨ì¼ ë°°ì¹˜ë¥¼ ë³‘ë ¬ ì²˜ë¦¬"""
        successful_count = 0
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ë³‘ë ¬ ì‘ì—… ì œì¶œ
            future_to_article = {
                executor.submit(self.collect_single_article, article_no, quiet=True): article_no 
                for article_no in article_nos
            }
            
            # ì™„ë£Œëœ ì‘ì—…ë“¤ ì²˜ë¦¬
            for future in as_completed(future_to_article):
                article_no = future_to_article[future]
                try:
                    success = future.result()
                    if success:
                        successful_count += 1
                        print(f"âœ… {article_no} ì™„ë£Œ")
                    else:
                        print(f"âŒ {article_no} ì‹¤íŒ¨")
                except Exception as e:
                    # ì—°ê²° í’€ ì—ëŸ¬ íŠ¹ë³„ ì²˜ë¦¬
                    if "Resource temporarily unavailable" in str(e) or "Errno 35" in str(e):
                        print(f"âš ï¸ {article_no} ì—°ê²°í’€ ì—ëŸ¬: ì¬ì‹œë„ ê¶Œì¥")
                    else:
                        print(f"âŒ {article_no} ì˜ˆì™¸: {e}")
        
        return successful_count
    
    def _print_progress_with_eta(self, processed: int, successful: int, total: Optional[int]):
        """ì§„í–‰ë¥ ê³¼ ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ì¶œë ¥"""
        if not self.collection_stats['start_time']:
            return
        
        elapsed_time = time.time() - self.collection_stats['start_time']
        
        print(f"\nğŸ“ˆ ì§„í–‰ í˜„í™©:")
        print(f"   ì²˜ë¦¬ì™„ë£Œ: {processed}ê°œ")
        print(f"   ì„±ê³µ: {successful}ê°œ")
        print(f"   ì„±ê³µë¥ : {(successful/processed*100):.1f}%" if processed > 0 else "0%")
        print(f"   ê²½ê³¼ì‹œê°„: {elapsed_time/60:.1f}ë¶„")
        
        # ETA ê³„ì‚°
        if total and processed > 0:
            remaining = total - processed
            avg_time_per_item = elapsed_time / processed
            eta_seconds = remaining * avg_time_per_item
            eta_minutes = eta_seconds / 60
            
            print(f"   ë‚¨ì€ ë§¤ë¬¼: {remaining}ê°œ")
            print(f"   ì˜ˆìƒ ì™„ë£Œ: {eta_minutes:.1f}ë¶„ í›„")
            
            # ì™„ë£Œ ì˜ˆì • ì‹œê°
            completion_time = datetime.fromtimestamp(time.time() + eta_seconds)
            print(f"   ì™„ë£Œ ì˜ˆì •: {completion_time.strftime('%H:%M')}")
            
        print("=" * 50)
    
    def get_comprehensive_stats(self) -> Dict[str, Any]:
        stats = {
            'collection_stats': self.collection_stats,
            'api_stats': self.api_client.get_request_stats(),
            'parsing_stats': self.parser.get_parsing_stats(),
            'save_stats': self.repository.get_save_stats()
        }
        
        if self.address_enabled:
            stats['address_stats'] = self.address_service.get_usage_stats()
        
        return stats
    
    def print_final_summary(self):
        stats = self.get_comprehensive_stats()
        
        print("\n" + "="*50)
        print("ğŸ“Š ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼")
        print("="*50)
        
        collection = stats['collection_stats']
        print(f"ì´ ì²˜ë¦¬: {collection['total_processed']}ê°œ")
        print(f"ì„±ê³µ: {collection['successful_collections']}ê°œ")
        print(f"íŒŒì‹± ì‹¤íŒ¨: {collection['parsing_failures']}ê°œ")
        print(f"ì €ì¥ ì‹¤íŒ¨: {collection['save_failures']}ê°œ")
        
        if collection['total_processed'] > 0:
            success_rate = (collection['successful_collections'] / collection['total_processed']) * 100
            print(f"ì„±ê³µë¥ : {success_rate:.2f}%")
        
        api = stats['api_stats']
        print(f"\nAPI í˜¸ì¶œ: {api['total_requests']}íšŒ")
        
        if self.address_enabled and 'address_stats' in stats:
            addr = stats['address_stats']
            print(f"\nì£¼ì†Œ ë³€í™˜: {addr['total_requests']}íšŒ")
            print(f"ìºì‹œ íˆíŠ¸: {addr['cache_hits']}ê°œ")
        
        print("="*50)