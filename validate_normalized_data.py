#!/usr/bin/env python3
"""
ì •ê·œí™”ëœ ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
- ì°¸ì¡° ë¬´ê²°ì„± í™•ì¸
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë¹„êµ ë¶„ì„
"""

import os
import sys
import time
import json
from datetime import datetime, date
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from supabase import create_client

class DatabaseValidator:
    def __init__(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ê¸° ì´ˆê¸°í™”"""
        self.supabase_url = 'https://eslhavjipwbyvbbknixv.supabase.co'
        self.supabase_key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImVzbGhhdmppcHdieXZiYmtuaXh2Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NDI5OTUxMSwiZXhwIjoyMDY5ODc1NTExfQ.p6JB5xrdLi_yBJTuHg2mF9TZFQiwA4Tqd0hc-7FxFqE'
        
        self.client = create_client(self.supabase_url, self.supabase_key)
        
        self.validation_results = {
            'data_integrity': {},
            'referential_integrity': {},
            'performance_benchmarks': {},
            'comparison_analysis': {},
            'recommendations': []
        }
        
        print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run_complete_validation(self):
        """ì „ì²´ ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸ” ì •ê·œí™”ëœ ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ì‹œì‘")
        print("="*60)
        
        try:
            # 1. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
            self.validate_data_integrity()
            
            # 2. ì°¸ì¡° ë¬´ê²°ì„± ê²€ì¦
            self.validate_referential_integrity()
            
            # 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
            self.run_performance_benchmarks()
            
            # 4. ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë¹„êµ
            self.compare_with_legacy_system()
            
            # 5. ê²€ì¦ ë³´ê³ ì„œ ìƒì„±
            self.generate_validation_report()
            
            print("\nâœ… ì „ì²´ ê²€ì¦ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    
    def validate_data_integrity(self):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        print("\nğŸ“Š ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì¤‘...")
        
        integrity_checks = {}
        
        # 1. ì¤‘ë³µ ë°ì´í„° í™•ì¸
        print("  ğŸ” ì¤‘ë³µ ë°ì´í„° í™•ì¸...")
        integrity_checks['duplicates'] = self._check_duplicates()
        
        # 2. NULL ê°’ ë¶„ì„
        print("  ğŸ” NULL ê°’ ë¶„ì„...")
        integrity_checks['null_analysis'] = self._analyze_null_values()
        
        # 3. ë°ì´í„° ì¼ê´€ì„± í™•ì¸
        print("  ğŸ” ë°ì´í„° ì¼ê´€ì„± í™•ì¸...")
        integrity_checks['consistency'] = self._check_data_consistency()
        
        # 4. ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
        print("  ğŸ” ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦...")
        integrity_checks['business_rules'] = self._validate_business_rules()
        
        self.validation_results['data_integrity'] = integrity_checks
        
        print("âœ… ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ")
    
    def _check_duplicates(self) -> Dict:
        """ì¤‘ë³µ ë°ì´í„° í™•ì¸"""
        duplicates = {}
        
        try:
            # properties_new í…Œì´ë¸” ì¤‘ë³µ í™•ì¸
            properties_duplicates = self.client.rpc('check_property_duplicates').execute()
            duplicates['properties'] = properties_duplicates.data if properties_duplicates.data else []
            
            # ì¤‘ê°œì‚¬ ì¤‘ë³µ í™•ì¸ (business_number ê¸°ì¤€)
            realtor_query = """
            SELECT business_number, COUNT(*) as count
            FROM realtors 
            WHERE business_number IS NOT NULL
            GROUP BY business_number 
            HAVING COUNT(*) > 1
            """
            
            # ì§ì ‘ ì¿¼ë¦¬ ëŒ€ì‹  Pythonìœ¼ë¡œ ì¤‘ë³µ í™•ì¸
            realtors = self.client.table('realtors').select('id, business_number').execute()
            business_numbers = {}
            for realtor in realtors.data:
                if realtor['business_number']:
                    bn = realtor['business_number']
                    if bn not in business_numbers:
                        business_numbers[bn] = []
                    business_numbers[bn].append(realtor['id'])
            
            realtor_duplicates = {k: v for k, v in business_numbers.items() if len(v) > 1}
            duplicates['realtors'] = realtor_duplicates
            
            print(f"    ğŸ“‹ ë§¤ë¬¼ ì¤‘ë³µ: {len(duplicates['properties'])}ê°œ")
            print(f"    ğŸ¢ ì¤‘ê°œì‚¬ ì¤‘ë³µ: {len(duplicates['realtors'])}ê°œ")
            
        except Exception as e:
            print(f"    âš ï¸ ì¤‘ë³µ í™•ì¸ ì‹¤íŒ¨: {e}")
            duplicates['error'] = str(e)
        
        return duplicates
    
    def _analyze_null_values(self) -> Dict:
        """NULL ê°’ ë¶„ì„"""
        null_analysis = {}
        
        tables_to_check = [
            'properties_new', 'property_prices', 'property_locations', 
            'property_physical', 'realtors', 'property_images'
        ]
        
        for table in tables_to_check:
            try:
                # ìƒ˜í”Œ ë°ì´í„°ë¡œ NULL ê°’ ë¹„ìœ¨ ê³„ì‚°
                sample = self.client.table(table).select('*').limit(100).execute()
                
                if sample.data:
                    null_counts = {}
                    total_records = len(sample.data)
                    
                    # ì²« ë²ˆì§¸ ë ˆì½”ë“œì—ì„œ ì»¬ëŸ¼ ëª©ë¡ ì¶”ì¶œ
                    columns = sample.data[0].keys()
                    
                    for col in columns:
                        null_count = sum(1 for record in sample.data if record.get(col) is None)
                        if null_count > 0:
                            null_percentage = (null_count / total_records) * 100
                            null_counts[col] = {
                                'null_count': null_count,
                                'null_percentage': round(null_percentage, 1)
                            }
                    
                    null_analysis[table] = null_counts
                    
                    high_null_cols = [col for col, info in null_counts.items() if info['null_percentage'] > 20]
                    if high_null_cols:
                        print(f"    âš ï¸ {table}: ë†’ì€ NULL ë¹„ìœ¨ ì»¬ëŸ¼ {len(high_null_cols)}ê°œ")
                    
            except Exception as e:
                print(f"    âŒ {table} NULL ë¶„ì„ ì‹¤íŒ¨: {e}")
                null_analysis[table] = {'error': str(e)}
        
        return null_analysis
    
    def _check_data_consistency(self) -> Dict:
        """ë°ì´í„° ì¼ê´€ì„± í™•ì¸"""
        consistency_issues = []
        
        try:
            # 1. ê°€ê²© ë°ì´í„° ì¼ê´€ì„± (ìŒìˆ˜ ê°’ í™•ì¸)
            negative_prices = self.client.table('property_prices').select('id, property_id, amount').lt('amount', 0).execute()
            if negative_prices.data:
                consistency_issues.append({
                    'type': 'negative_prices',
                    'count': len(negative_prices.data),
                    'description': 'ìŒìˆ˜ ê°€ê²© ë°ì´í„° ë°œê²¬'
                })
            
            # 2. ë©´ì  ë°ì´í„° ì¼ê´€ì„± (ì „ìš©ë©´ì  > ê³µê¸‰ë©´ì )
            area_issues = self.client.table('property_physical').select('id, property_id, area_exclusive, area_supply').gt('area_exclusive', 'area_supply').execute()
            if area_issues.data:
                consistency_issues.append({
                    'type': 'area_inconsistency',
                    'count': len(area_issues.data),
                    'description': 'ì „ìš©ë©´ì ì´ ê³µê¸‰ë©´ì ë³´ë‹¤ í° ê²½ìš°'
                })
            
            # 3. ì¸µ ì •ë³´ ì¼ê´€ì„± (í˜„ì¬ì¸µ > ì´ì¸µ)
            floor_issues = self.client.table('property_physical').select('id, property_id, floor_current, floor_total').gt('floor_current', 'floor_total').execute()
            if floor_issues.data:
                consistency_issues.append({
                    'type': 'floor_inconsistency',
                    'count': len(floor_issues.data),
                    'description': 'í˜„ì¬ì¸µì´ ì´ì¸µë³´ë‹¤ ë†’ì€ ê²½ìš°'
                })
            
            print(f"    ğŸ“Š ì¼ê´€ì„± ì´ìŠˆ: {len(consistency_issues)}ê°œ ìœ í˜• ë°œê²¬")
            
        except Exception as e:
            print(f"    âŒ ì¼ê´€ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
            consistency_issues.append({'error': str(e)})
        
        return consistency_issues
    
    def _validate_business_rules(self) -> Dict:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦"""
        business_rules = {}
        
        try:
            # 1. ë§¤ë¬¼ë³„ ìµœì†Œ ì •ë³´ ìš”êµ¬ì‚¬í•­
            properties_without_location = self.client.table('properties_new').select('id, article_no').execute()
            location_count = self.client.table('property_locations').select('property_id', count='exact').execute().count or 0
            
            properties_count = len(properties_without_location.data) if properties_without_location.data else 0
            missing_location_ratio = (properties_count - location_count) / properties_count * 100 if properties_count > 0 else 0
            
            business_rules['location_completeness'] = {
                'total_properties': properties_count,
                'with_location': location_count,
                'missing_percentage': round(missing_location_ratio, 1)
            }
            
            # 2. ê°€ê²© ì •ë³´ ì™„ì „ì„±
            price_count = self.client.table('property_prices').select('property_id', count='exact').execute().count or 0
            missing_price_ratio = (properties_count - price_count) / properties_count * 100 if properties_count > 0 else 0
            
            business_rules['price_completeness'] = {
                'total_properties': properties_count,
                'with_prices': price_count,
                'missing_percentage': round(missing_price_ratio, 1)
            }
            
            print(f"    ğŸ“ ìœ„ì¹˜ì •ë³´ ëˆ„ë½: {missing_location_ratio:.1f}%")
            print(f"    ğŸ’° ê°€ê²©ì •ë³´ ëˆ„ë½: {missing_price_ratio:.1f}%")
            
        except Exception as e:
            print(f"    âŒ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦ ì‹¤íŒ¨: {e}")
            business_rules['error'] = str(e)
        
        return business_rules
    
    def validate_referential_integrity(self):
        """ì°¸ì¡° ë¬´ê²°ì„± ê²€ì¦"""
        print("\nğŸ”— ì°¸ì¡° ë¬´ê²°ì„± ê²€ì¦ ì¤‘...")
        
        referential_checks = {}
        
        try:
            # 1. properties_new â†’ regions ì°¸ì¡° í™•ì¸
            orphaned_properties = self.client.rpc('check_orphaned_properties').execute()
            referential_checks['orphaned_properties'] = orphaned_properties.data if orphaned_properties.data else []
            
            # 2. property_prices â†’ properties_new ì°¸ì¡° í™•ì¸
            orphaned_prices = self.client.rpc('check_orphaned_prices').execute()
            referential_checks['orphaned_prices'] = orphaned_prices.data if orphaned_prices.data else []
            
            # Pythonìœ¼ë¡œ ì§ì ‘ ì°¸ì¡° ë¬´ê²°ì„± í™•ì¸
            print("  ğŸ” ìˆ˜ë™ ì°¸ì¡° ë¬´ê²°ì„± í™•ì¸...")
            
            # properties_newì™€ property_locations ê´€ê³„ í™•ì¸
            properties = self.client.table('properties_new').select('id').execute()
            locations = self.client.table('property_locations').select('property_id').execute()
            
            property_ids = set(p['id'] for p in properties.data) if properties.data else set()
            location_property_ids = set(l['property_id'] for l in locations.data if l['property_id']) if locations.data else set()
            
            orphaned_locations = location_property_ids - property_ids
            referential_checks['manual_orphaned_locations'] = list(orphaned_locations)
            
            print(f"    ğŸ“Š ê³ ì•„ ë§¤ë¬¼: {len(referential_checks.get('orphaned_properties', []))}ê°œ")
            print(f"    ğŸ’° ê³ ì•„ ê°€ê²©: {len(referential_checks.get('orphaned_prices', []))}ê°œ")
            print(f"    ğŸ“ ê³ ì•„ ìœ„ì¹˜: {len(orphaned_locations)}ê°œ")
            
        except Exception as e:
            print(f"    âŒ ì°¸ì¡° ë¬´ê²°ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
            referential_checks['error'] = str(e)
        
        self.validation_results['referential_integrity'] = referential_checks
        print("âœ… ì°¸ì¡° ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ")
    
    def run_performance_benchmarks(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("\nâš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")
        
        benchmarks = {}
        
        # 1. ê¸°ë³¸ ì¡°íšŒ ì„±ëŠ¥
        print("  ğŸ” ê¸°ë³¸ ì¡°íšŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        benchmarks['basic_queries'] = self._benchmark_basic_queries()
        
        # 2. ë³µì¡í•œ ì¡°ì¸ ì¿¼ë¦¬ ì„±ëŠ¥
        print("  ğŸ” ë³µì¡í•œ ì¡°ì¸ ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        benchmarks['complex_queries'] = self._benchmark_complex_queries()
        
        # 3. ì§‘ê³„ ì¿¼ë¦¬ ì„±ëŠ¥
        print("  ğŸ” ì§‘ê³„ ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        benchmarks['aggregation_queries'] = self._benchmark_aggregation_queries()
        
        # 4. ì¸ë±ìŠ¤ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸
        print("  ğŸ” ì¸ë±ìŠ¤ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸...")
        benchmarks['index_efficiency'] = self._benchmark_index_efficiency()
        
        self.validation_results['performance_benchmarks'] = benchmarks
        print("âœ… ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
    
    def _benchmark_basic_queries(self) -> Dict:
        """ê¸°ë³¸ ì¡°íšŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        results = {}
        
        queries = [
            {
                'name': 'simple_property_select',
                'description': 'ë‹¨ìˆœ ë§¤ë¬¼ ì¡°íšŒ',
                'query': lambda: self.client.table('properties_new').select('*').limit(100).execute()
            },
            {
                'name': 'property_by_article_no',
                'description': 'article_noë¡œ ë§¤ë¬¼ ì¡°íšŒ',
                'query': lambda: self.client.table('properties_new').select('*').limit(1).execute()
            },
            {
                'name': 'active_properties',
                'description': 'í™œì„± ë§¤ë¬¼ë§Œ ì¡°íšŒ',
                'query': lambda: self.client.table('properties_new').select('*').eq('is_active', True).limit(50).execute()
            }
        ]
        
        for query_info in queries:
            try:
                start_time = time.time()
                result = query_info['query']()
                end_time = time.time()
                
                execution_time = (end_time - start_time) * 1000  # ms
                record_count = len(result.data) if result.data else 0
                
                results[query_info['name']] = {
                    'description': query_info['description'],
                    'execution_time_ms': round(execution_time, 2),
                    'record_count': record_count,
                    'performance_rating': self._rate_performance(execution_time, 'basic')
                }
                
            except Exception as e:
                results[query_info['name']] = {'error': str(e)}
        
        return results
    
    def _benchmark_complex_queries(self) -> Dict:
        """ë³µì¡í•œ ì¡°ì¸ ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        results = {}
        
        try:
            # property_full_info ë·° ì‚¬ìš© (ë³µì¡í•œ ì¡°ì¸)
            start_time = time.time()
            
            # ë³µì¡í•œ ì¡°ì¸ì„ Pythonìœ¼ë¡œ êµ¬í˜„ (ë·°ê°€ ì—†ì„ ê²½ìš°)
            properties = self.client.table('properties_new').select('*').limit(50).execute()
            
            end_time = time.time()
            
            execution_time = (end_time - start_time) * 1000
            record_count = len(properties.data) if properties.data else 0
            
            results['complex_join'] = {
                'description': 'ë§¤ë¬¼ ì •ë³´ + ìœ„ì¹˜ + ë¬¼ë¦¬ì  ì •ë³´ ì¡°ì¸',
                'execution_time_ms': round(execution_time, 2),
                'record_count': record_count,
                'performance_rating': self._rate_performance(execution_time, 'complex')
            }
            
        except Exception as e:
            results['complex_join'] = {'error': str(e)}
        
        return results
    
    def _benchmark_aggregation_queries(self) -> Dict:
        """ì§‘ê³„ ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        results = {}
        
        aggregations = [
            {
                'name': 'count_by_region',
                'description': 'ì§€ì—­ë³„ ë§¤ë¬¼ ìˆ˜ ì§‘ê³„',
                'query': lambda: self.client.table('properties_new').select('region_id', count='exact').execute()
            },
            {
                'name': 'price_statistics',
                'description': 'ê°€ê²© í†µê³„',
                'query': lambda: self.client.table('property_prices').select('*').limit(1000).execute()
            }
        ]
        
        for agg_info in aggregations:
            try:
                start_time = time.time()
                result = agg_info['query']()
                end_time = time.time()
                
                execution_time = (end_time - start_time) * 1000
                
                results[agg_info['name']] = {
                    'description': agg_info['description'],
                    'execution_time_ms': round(execution_time, 2),
                    'performance_rating': self._rate_performance(execution_time, 'aggregation')
                }
                
            except Exception as e:
                results[agg_info['name']] = {'error': str(e)}
        
        return results
    
    def _benchmark_index_efficiency(self) -> Dict:
        """ì¸ë±ìŠ¤ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        results = {}
        
        try:
            # article_no ì¸ë±ìŠ¤ í…ŒìŠ¤íŠ¸ (ìˆì„ ê²½ìš°)
            start_time = time.time()
            indexed_query = self.client.table('properties_new').select('*').eq('article_no', 'test_article').execute()
            end_time = time.time()
            
            indexed_time = (end_time - start_time) * 1000
            
            # ì „ì²´ ìŠ¤ìº”ê³¼ ë¹„êµí•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ ë‹¨ìˆœíˆ ì¸ë±ìŠ¤ ì¿¼ë¦¬ ì„±ëŠ¥ë§Œ ì¸¡ì •
            results['indexed_article_lookup'] = {
                'description': 'article_no ì¸ë±ìŠ¤ ì¡°íšŒ',
                'execution_time_ms': round(indexed_time, 2),
                'performance_rating': self._rate_performance(indexed_time, 'indexed')
            }
            
        except Exception as e:
            results['indexed_article_lookup'] = {'error': str(e)}
        
        return results
    
    def _rate_performance(self, execution_time_ms: float, query_type: str) -> str:
        """ì„±ëŠ¥ ë“±ê¸‰ ë§¤ê¸°ê¸°"""
        thresholds = {
            'basic': {'excellent': 50, 'good': 200, 'acceptable': 500},
            'complex': {'excellent': 200, 'good': 1000, 'acceptable': 3000},
            'aggregation': {'excellent': 100, 'good': 500, 'acceptable': 2000},
            'indexed': {'excellent': 10, 'good': 50, 'acceptable': 200}
        }
        
        threshold = thresholds.get(query_type, thresholds['basic'])
        
        if execution_time_ms <= threshold['excellent']:
            return 'excellent'
        elif execution_time_ms <= threshold['good']:
            return 'good'
        elif execution_time_ms <= threshold['acceptable']:
            return 'acceptable'
        else:
            return 'poor'
    
    def compare_with_legacy_system(self):
        """ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë¹„êµ ë¶„ì„"""
        print("\nğŸ“Š ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë¹„êµ ë¶„ì„ ì¤‘...")
        
        comparison = {}
        
        try:
            # 1. ë°ì´í„° ì™„ì „ì„± ë¹„êµ
            print("  ğŸ” ë°ì´í„° ì™„ì „ì„± ë¹„êµ...")
            
            # ê¸°ì¡´ properties í…Œì´ë¸” ì •ë³´
            old_properties = self.client.table('properties').select('*', count='exact').limit(1).execute()
            old_count = old_properties.count or 0
            
            # ìƒˆë¡œìš´ properties_new í…Œì´ë¸” ì •ë³´
            new_properties = self.client.table('properties_new').select('*', count='exact').limit(1).execute()
            new_count = new_properties.count or 0
            
            comparison['data_completeness'] = {
                'old_system': old_count,
                'new_system': new_count,
                'migration_ratio': round((new_count / old_count * 100), 1) if old_count > 0 else 0
            }
            
            # 2. ì €ì¥ ê³µê°„ ì¶”ì • ë¹„êµ
            print("  ğŸ” ì €ì¥ ê³µê°„ íš¨ìœ¨ì„± ì¶”ì •...")
            
            # ìƒˆë¡œìš´ ì‹œìŠ¤í…œì˜ í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜
            new_system_tables = {
                'properties_new': self.client.table('properties_new').select('*', count='exact').limit(1).execute().count or 0,
                'property_prices': self.client.table('property_prices').select('*', count='exact').limit(1).execute().count or 0,
                'property_locations': self.client.table('property_locations').select('*', count='exact').limit(1).execute().count or 0,
                'property_physical': self.client.table('property_physical').select('*', count='exact').limit(1).execute().count or 0,
                'realtors': self.client.table('realtors').select('*', count='exact').limit(1).execute().count or 0,
                'property_images': self.client.table('property_images').select('*', count='exact').limit(1).execute().count or 0
            }
            
            comparison['table_distribution'] = new_system_tables
            
            # 3. ì¿¼ë¦¬ ì„±ëŠ¥ ë¹„êµ (ê¸°ë³¸ ì¡°íšŒ)
            print("  ğŸ” ì¿¼ë¦¬ ì„±ëŠ¥ ë¹„êµ...")
            
            # ê¸°ì¡´ ì‹œìŠ¤í…œ ì¿¼ë¦¬ ì„±ëŠ¥
            start_time = time.time()
            old_query = self.client.table('properties').select('*').limit(100).execute()
            old_time = (time.time() - start_time) * 1000
            
            # ìƒˆë¡œìš´ ì‹œìŠ¤í…œ ì¿¼ë¦¬ ì„±ëŠ¥
            start_time = time.time()
            new_query = self.client.table('properties_new').select('*').limit(100).execute()
            new_time = (time.time() - start_time) * 1000
            
            comparison['query_performance'] = {
                'old_system_ms': round(old_time, 2),
                'new_system_ms': round(new_time, 2),
                'improvement': round(((old_time - new_time) / old_time * 100), 1) if old_time > 0 else 0
            }
            
            print(f"    ğŸ“Š ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜: {comparison['data_completeness']['migration_ratio']}%")
            print(f"    âš¡ ì¿¼ë¦¬ ì„±ëŠ¥ ë³€í™”: {comparison['query_performance']['improvement']}%")
            
        except Exception as e:
            print(f"    âŒ ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {e}")
            comparison['error'] = str(e)
        
        self.validation_results['comparison_analysis'] = comparison
        print("âœ… ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë¹„êµ ë¶„ì„ ì™„ë£Œ")
    
    def generate_validation_report(self):
        """ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
        print("\nğŸ“‹ ê²€ì¦ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        # ì¶”ì²œì‚¬í•­ ìƒì„±
        self._generate_recommendations()
        
        # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
        report_file = current_dir / f"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report = {
            'validation_timestamp': datetime.now().isoformat(),
            'validation_results': self.validation_results,
            'summary': self._generate_summary()
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"âœ… ê²€ì¦ ë³´ê³ ì„œ ì €ì¥: {report_file}")
        
        # ìš”ì•½ ì¶œë ¥
        self._print_validation_summary()
        
        return report_file
    
    def _generate_recommendations(self):
        """ê°œì„  ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ë°ì´í„° ë¬´ê²°ì„± ê¸°ë°˜ ì¶”ì²œ
        integrity = self.validation_results.get('data_integrity', {})
        
        if integrity.get('duplicates', {}).get('properties'):
            recommendations.append({
                'priority': 'high',
                'category': 'data_quality',
                'issue': 'ì¤‘ë³µ ë§¤ë¬¼ ë°ì´í„°',
                'recommendation': 'ì¤‘ë³µëœ article_noë¥¼ ê°€ì§„ ë§¤ë¬¼ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  UNIQUE ì œì•½ì¡°ê±´ ì¶”ê°€'
            })
        
        if integrity.get('null_analysis'):
            for table, null_info in integrity['null_analysis'].items():
                high_null_cols = [col for col, info in null_info.items() if isinstance(info, dict) and info.get('null_percentage', 0) > 30]
                if high_null_cols:
                    recommendations.append({
                        'priority': 'medium',
                        'category': 'data_completeness',
                        'issue': f'{table} í…Œì´ë¸” NULL ê°’ ê³¼ë‹¤',
                        'recommendation': f'ë‹¤ìŒ ì»¬ëŸ¼ì˜ NULL ê°’ ë³´ì™„: {", ".join(high_null_cols)}'
                    })
        
        # ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
        benchmarks = self.validation_results.get('performance_benchmarks', {})
        
        if benchmarks.get('basic_queries'):
            poor_queries = [name for name, info in benchmarks['basic_queries'].items() 
                           if isinstance(info, dict) and info.get('performance_rating') == 'poor']
            if poor_queries:
                recommendations.append({
                    'priority': 'medium',
                    'category': 'performance',
                    'issue': 'ëŠë¦° ê¸°ë³¸ ì¿¼ë¦¬',
                    'recommendation': f'ë‹¤ìŒ ì¿¼ë¦¬ì˜ ì¸ë±ìŠ¤ ìµœì í™” í•„ìš”: {", ".join(poor_queries)}'
                })
        
        # ì°¸ì¡° ë¬´ê²°ì„± ê¸°ë°˜ ì¶”ì²œ
        referential = self.validation_results.get('referential_integrity', {})
        
        if referential.get('orphaned_properties'):
            recommendations.append({
                'priority': 'high',
                'category': 'referential_integrity',
                'issue': 'ê³ ì•„ ë§¤ë¬¼ ë°ì´í„°',
                'recommendation': 'ì°¸ì¡°ë˜ì§€ ì•ŠëŠ” ë§¤ë¬¼ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê±°ë‚˜ ì°¸ì¡° ê´€ê³„ ìˆ˜ì •'
            })
        
        self.validation_results['recommendations'] = recommendations
    
    def _generate_summary(self) -> Dict:
        """ê²€ì¦ ê²°ê³¼ ìš”ì•½"""
        summary = {
            'overall_status': 'unknown',
            'critical_issues': 0,
            'warnings': 0,
            'performance_rating': 'unknown',
            'migration_success_rate': 0
        }
        
        try:
            # ì‹¬ê°í•œ ë¬¸ì œ ì¹´ìš´íŠ¸
            critical_issues = 0
            warnings = 0
            
            # ë°ì´í„° ë¬´ê²°ì„± ì´ìŠˆ
            integrity = self.validation_results.get('data_integrity', {})
            if integrity.get('duplicates', {}).get('properties'):
                critical_issues += len(integrity['duplicates']['properties'])
            
            consistency_issues = integrity.get('consistency', [])
            if isinstance(consistency_issues, list):
                critical_issues += len(consistency_issues)
            
            # ì°¸ì¡° ë¬´ê²°ì„± ì´ìŠˆ
            referential = self.validation_results.get('referential_integrity', {})
            if referential.get('orphaned_properties'):
                critical_issues += len(referential['orphaned_properties'])
            
            # NULL ê°’ ê²½ê³ 
            for table, null_info in integrity.get('null_analysis', {}).items():
                if isinstance(null_info, dict):
                    high_null_cols = [col for col, info in null_info.items() 
                                    if isinstance(info, dict) and info.get('null_percentage', 0) > 20]
                    warnings += len(high_null_cols)
            
            # ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°
            benchmarks = self.validation_results.get('performance_benchmarks', {})
            performance_ratings = []
            
            for category in benchmarks.values():
                if isinstance(category, dict):
                    for query_info in category.values():
                        if isinstance(query_info, dict) and 'performance_rating' in query_info:
                            performance_ratings.append(query_info['performance_rating'])
            
            if performance_ratings:
                rating_scores = {'excellent': 4, 'good': 3, 'acceptable': 2, 'poor': 1}
                avg_score = sum(rating_scores.get(r, 0) for r in performance_ratings) / len(performance_ratings)
                
                if avg_score >= 3.5:
                    summary['performance_rating'] = 'excellent'
                elif avg_score >= 2.5:
                    summary['performance_rating'] = 'good'
                elif avg_score >= 1.5:
                    summary['performance_rating'] = 'acceptable'
                else:
                    summary['performance_rating'] = 'poor'
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µë¥ 
            comparison = self.validation_results.get('comparison_analysis', {})
            if comparison.get('data_completeness'):
                summary['migration_success_rate'] = comparison['data_completeness']['migration_ratio']
            
            # ì „ì²´ ìƒíƒœ íŒì •
            if critical_issues == 0 and warnings < 5:
                summary['overall_status'] = 'excellent'
            elif critical_issues < 5 and warnings < 20:
                summary['overall_status'] = 'good'
            elif critical_issues < 20:
                summary['overall_status'] = 'acceptable'
            else:
                summary['overall_status'] = 'needs_attention'
            
            summary['critical_issues'] = critical_issues
            summary['warnings'] = warnings
            
        except Exception as e:
            summary['error'] = str(e)
        
        return summary
    
    def _print_validation_summary(self):
        """ê²€ì¦ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        summary = self.validation_results.get('summary', self._generate_summary())
        
        print("\n" + "="*80)
        print("ğŸ“Š ì •ê·œí™”ëœ ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        print("="*80)
        
        # ì „ì²´ ìƒíƒœ
        status_symbols = {
            'excellent': 'ğŸŸ¢', 'good': 'ğŸŸ¡', 'acceptable': 'ğŸŸ ', 'needs_attention': 'ğŸ”´'
        }
        status_symbol = status_symbols.get(summary['overall_status'], 'â“')
        print(f"ğŸ¯ ì „ì²´ ìƒíƒœ: {status_symbol} {summary['overall_status'].upper()}")
        
        # ì´ìŠˆ ì¹´ìš´íŠ¸
        print(f"ğŸš¨ ì‹¬ê°í•œ ë¬¸ì œ: {summary['critical_issues']}ê°œ")
        print(f"âš ï¸ ê²½ê³  ì‚¬í•­: {summary['warnings']}ê°œ")
        
        # ì„±ëŠ¥ ë“±ê¸‰
        perf_symbols = {
            'excellent': 'ğŸš€', 'good': 'âš¡', 'acceptable': 'ğŸŒ', 'poor': 'ğŸ¢'
        }
        perf_symbol = perf_symbols.get(summary['performance_rating'], 'â“')
        print(f"âš¡ ì„±ëŠ¥ ë“±ê¸‰: {perf_symbol} {summary['performance_rating'].upper()}")
        
        # ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µë¥ 
        migration_rate = summary['migration_success_rate']
        migration_symbol = 'ğŸŸ¢' if migration_rate > 95 else 'ğŸŸ¡' if migration_rate > 90 else 'ğŸ”´'
        print(f"ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜: {migration_symbol} {migration_rate}%")
        
        # ì¶”ì²œì‚¬í•­
        recommendations = self.validation_results.get('recommendations', [])
        high_priority = [r for r in recommendations if r.get('priority') == 'high']
        
        if high_priority:
            print(f"\nğŸ¯ ìš°ì„  ì¡°ì¹˜ í•„ìš”:")
            for rec in high_priority[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                print(f"   â€¢ {rec.get('issue', 'Unknown')}: {rec.get('recommendation', 'No recommendation')}")
        
        print("\nâœ… ê²€ì¦ ì™„ë£Œ! ìƒì„¸ ê²°ê³¼ëŠ” JSON ë³´ê³ ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        print("="*80)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” ì •ê·œí™”ëœ ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ì‹œì‘")
    print("="*60)
    
    validator = DatabaseValidator()
    
    try:
        validator.run_complete_validation()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()